{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d0102c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pathlib import Path\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import matplotlib as plt\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf15eb1b",
   "metadata": {},
   "source": [
    "AVANT TOUTE CHOSE, IL FAUT VOUS ASSURER D'AVOIR UN DATASET DANS LE FORMAT RENDU PAR Prepare_dataset.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c2bdcbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path(\"../data/final_dataset\")\n",
    "data_dir_noaug = Path(\"../data/final_dataset_noaug2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "164adbd4",
   "metadata": {},
   "source": [
    "### UTILS METHODS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71612919",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(filename: str):\n",
    "    return filename.split(\"_\")[0]\n",
    "\n",
    "\n",
    "def get_uuid(filename: str):\n",
    "    name = Path(filename).stem          \n",
    "    parts = name.split(\"_\")\n",
    "    return \"_\".join(parts[:2])          \n",
    "\n",
    "\n",
    "def build_augmented_path(img_path: Path, base_dir: Path):\n",
    "    img_path = Path(img_path)\n",
    "    filename = img_path.name\n",
    "    label = get_label(filename)\n",
    "    uuid = get_uuid(filename)\n",
    "    pres = \"_\".join(filename.split(\".\")[0].split(\"_\")[1:3])\n",
    "    return base_dir / uuid / pres / filename\n",
    "\n",
    "\n",
    "def make_class_names(dataset):\n",
    "    # dataset.class_to_idx: {label_str: idx}\n",
    "    idx_to_class = {v: k for k, v in dataset.class_to_idx.items()}\n",
    "    return [idx_to_class[i] for i in range(len(idx_to_class))]\n",
    "\n",
    "\n",
    "def count_oov_pct(sequences, oov_id):\n",
    "    total = sum(1 for seq in sequences for tid in seq if tid != 0)\n",
    "    oov = sum(1 for seq in sequences for tid in seq if tid == oov_id)\n",
    "    return oov/total*100 if total > 0 else 0\n",
    "\n",
    "class_to_idx = {\n",
    "    \"ball\":  0,\n",
    "    \"bike\":  1,\n",
    "    \"dog\":   2,\n",
    "    \"water\": 3,\n",
    "}\n",
    "\n",
    "class_names = [\"ball\", \"bike\", \"dog\", \"water\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c91b81a7",
   "metadata": {},
   "source": [
    "### TRANSFORMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3d6e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.Resize((300, 500)),\n",
    "        transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "transform_resnet = transforms.Compose([\n",
    "    transforms.Resize((224, 224)), \n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e765a000",
   "metadata": {},
   "source": [
    "### IMAGE DATASET MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974408d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageCLIPDataset(Dataset):\n",
    "    def __init__(self, imgs, labels, captions,  base_dir: Path, transform):\n",
    "        \n",
    "        self.img_paths = [Path(build_augmented_path(img, base_dir)) for img in imgs]\n",
    "        self.labels = list(labels)\n",
    "        self.captions = list(captions)\n",
    "        self.transform = transform\n",
    "        self.classes = sorted(set(self.labels))                  \n",
    "        self.class_to_idx = {cls: i for i, cls in enumerate(self.classes)}  \n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = Image.open(self.img_paths[idx]).convert(\"RGB\")\n",
    "\n",
    "        label_str = self.labels[idx]\n",
    "        label = self.class_to_idx[label_str]\n",
    "        caption = self.captions[idx] if self.captions is not None else \"-\"\n",
    "\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        return idx, img, label, caption\n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "        return len(self.img_paths)\n",
    "    \n",
    "    def _get_img_path_from_idx(self, idx: int) -> Path:\n",
    "        return self.img_paths[idx]\n",
    "\n",
    "    def _get_caption_from_idx(self, idx: int) -> Path:\n",
    "        return self.captions[idx]\n",
    "    \n",
    "    def _get_label_from_idx(self, idx: int) -> str :\n",
    "        return self.labels[idx]\n",
    "    \n",
    "    def _get_img_size(self, idx: int) -> Tuple[int, int]:\n",
    "        print(self.img_paths[idx])\n",
    "\n",
    "        img = Image.open(self.img_paths[idx]).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            for t in self.transform.transforms:\n",
    "                if isinstance(t, transforms.Resize):\n",
    "                    img = t(img)\n",
    "        return img.height, img.width\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "936f817c",
   "metadata": {},
   "source": [
    "### DATASET LOADING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb39e64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_path = Path(\"../data/final_dataset/metadata.csv\")\n",
    "metadata_path_noaug = Path(\"../data/final_dataset_noaug2/metadata.csv\")\n",
    "\n",
    "df = pd.read_csv(metadata_path)\n",
    "df_noaug= pd.read_csv(metadata_path_noaug)\n",
    "\n",
    "print(df.columns)\n",
    "print(df.iloc[1])\n",
    "\n",
    "X =  df[\"image_path\"]\n",
    "X_noaug = df_noaug[\"image_path\"]\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec14532c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_train, df_temp = train_test_split(df, test_size=0.3, random_state=11)\n",
    "df_test, df_val = train_test_split(df_temp, test_size=0.5, random_state=11)\n",
    "\n",
    "df_train_noaug, df_temp_noaug = train_test_split(df_noaug, test_size=0.3, random_state=11)\n",
    "df_test_noaug, df_val_noaug = train_test_split(df_temp_noaug, test_size=0.5, random_state=11)\n",
    "\n",
    "print(len(df_train), len(df_test), len(df_val))\n",
    "print(df_train[\"label\"].value_counts(normalize=True) * 100)\n",
    "print(df_val[\"label\"].value_counts(normalize=True) * 100)\n",
    "print(df_test[\"label\"].value_counts(normalize=True) * 100)\n",
    "print(\"-----\\n\")\n",
    "\n",
    "print(len(df_train_noaug), len(df_test_noaug), len(df_val_noaug))\n",
    "print(df_train[\"label\"].value_counts(normalize=True) * 100)\n",
    "print(df_val[\"label\"].value_counts(normalize=True) * 100)\n",
    "print(df_test[\"label\"].value_counts(normalize=True) * 100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbca0b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, train_caption = df_train[\"image_path\"], df_train[\"label\"], df_train[\"caption\"]\n",
    "X_val, y_val, val_caption = df_val[\"image_path\"], df_val[\"label\"], df_val[\"caption\"]\n",
    "X_test, y_test, test_caption   = df_test[\"image_path\"], df_test[\"label\"], df_test[\"caption\"]\n",
    "\n",
    "X_train_noaug, y_train_noaug, train_caption_noaug = df_train_noaug[\"image_path\"], df_train_noaug[\"label\"], df_train_noaug[\"caption\"]\n",
    "X_val_noaug, y_val_noaug, val_caption_noaug = df_val_noaug[\"image_path\"], df_val_noaug[\"label\"], df_val_noaug[\"caption\"]\n",
    "X_test_noaug, y_test_noaug, test_caption_noaug   = df_test_noaug[\"image_path\"], df_test_noaug[\"label\"], df_test_noaug[\"caption\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75c23ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reset_index(drop=True)\n",
    "y_train = y_train.reset_index(drop=True)\n",
    "X_val = X_val.reset_index(drop=True)\n",
    "y_val = y_val.reset_index(drop=True)\n",
    "X_test = X_test.reset_index(drop=True)\n",
    "y_test = y_test.reset_index(drop=True)\n",
    "train_caption = train_caption.reset_index(drop=True)\n",
    "test_caption = test_caption.reset_index(drop=True)\n",
    "val_caption = val_caption.reset_index(drop=True)\n",
    "\n",
    "X_train_noaug = X_train_noaug.reset_index(drop=True)\n",
    "y_train_noaug = y_train_noaug.reset_index(drop=True)\n",
    "X_val_noaug = X_val_noaug.reset_index(drop=True)\n",
    "y_val_noaug = y_val_noaug.reset_index(drop=True)\n",
    "X_test_noaug = X_test_noaug.reset_index(drop=True)\n",
    "y_test_noaug = y_test_noaug.reset_index(drop=True)\n",
    "train_caption_noaug = train_caption_noaug.reset_index(drop=True)\n",
    "test_caption_noaug = test_caption_noaug.reset_index(drop=True)\n",
    "val_caption_noaug = val_caption_noaug.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe4b938",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_resnet = ImageCLIPDataset(X_train, y_train, train_caption, data_dir, transform_resnet)\n",
    "val_dataset_resnet   = ImageCLIPDataset(X_val, y_val, val_caption, data_dir, transform_resnet)\n",
    "test_dataset_resnet  = ImageCLIPDataset(X_test, y_test, test_caption,  data_dir, transform_resnet)\n",
    "\n",
    "train_dataset_custom = ImageCLIPDataset(X_train, y_train, train_caption, data_dir, transform)\n",
    "val_dataset_custom   = ImageCLIPDataset(X_val, y_val, val_caption, data_dir, transform)\n",
    "test_dataset_custom  = ImageCLIPDataset(X_test, y_test, test_caption, data_dir, transform)\n",
    "\n",
    "train_dataset_resnet_noaug = ImageCLIPDataset(X_train_noaug, y_train_noaug, train_caption_noaug, data_dir_noaug, transform_resnet)\n",
    "val_dataset_resnet_noaug   = ImageCLIPDataset(X_val_noaug, y_val_noaug, val_caption_noaug, data_dir_noaug, transform_resnet)\n",
    "test_dataset_resnet_noaug  = ImageCLIPDataset(X_test_noaug, y_test_noaug, test_caption_noaug,  data_dir_noaug, transform_resnet)\n",
    "\n",
    "train_dataset_custom_noaug = ImageCLIPDataset(X_train_noaug, y_train_noaug, train_caption_noaug, data_dir, transform)\n",
    "val_dataset_custom_noaug   = ImageCLIPDataset(X_val_noaug, y_val_noaug, val_caption, data_dir_noaug, transform)\n",
    "test_dataset_custom_noaug  = ImageCLIPDataset(X_test_noaug, y_test_noaug, test_caption, data_dir_noaug, transform)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06bb6d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_dataset_resnet._get_img_size(3))\n",
    "print(train_dataset_resnet._get_img_size(13))\n",
    "img = train_dataset_resnet._get_img_path_from_idx(3)\n",
    "lg = Image.open(build_augmented_path(img, data_dir))\n",
    "display(lg)\n",
    "print(train_dataset_resnet.__getitem__(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cec08f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader_resnet = DataLoader(train_dataset_resnet, batch_size=32, shuffle=True)\n",
    "val_loader_resnet   = DataLoader(val_dataset_resnet, batch_size=32, shuffle=False)\n",
    "test_loader_resnet  = DataLoader(test_dataset_resnet, batch_size=32, shuffle=False)\n",
    "\n",
    "train_loader_custom = DataLoader(train_dataset_custom, batch_size=32, shuffle=True)\n",
    "val_loader_custom   = DataLoader(val_dataset_custom, batch_size=32, shuffle=False)\n",
    "test_loader_custom  = DataLoader(test_dataset_custom, batch_size=32, shuffle=False)\n",
    "\n",
    "train_loader_resnet_noaug = DataLoader(train_dataset_resnet_noaug, batch_size=32, shuffle=True)\n",
    "val_loader_resnet_noaug   = DataLoader(val_dataset_resnet_noaug, batch_size=32, shuffle=False)\n",
    "test_loader_resnet_noaug  = DataLoader(test_dataset_resnet_noaug, batch_size=32, shuffle=False)\n",
    "\n",
    "train_loader_custom_noaug = DataLoader(train_dataset_custom_noaug, batch_size=32, shuffle=True)\n",
    "val_loader_custom_noaug   = DataLoader(val_dataset_custom_noaug, batch_size=32, shuffle=False)\n",
    "test_loader_custom_noaug  = DataLoader(test_dataset_custom_noaug, batch_size=32, shuffle=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "344a2399",
   "metadata": {},
   "source": [
    "### CNN MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f0cb90",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNBasic(nn.Module):\n",
    "    def __init__(self, num_classes=4):\n",
    "        super().__init__()\n",
    "\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, 3, padding=1), nn.BatchNorm2d(16), nn.ReLU(), nn.MaxPool2d(2,2),\n",
    "            nn.Conv2d(16, 32, 3, padding=1), nn.BatchNorm2d(32), nn.ReLU(), nn.MaxPool2d(2,2),\n",
    "            nn.Conv2d(32, 64, 3, padding=1), nn.BatchNorm2d(64), nn.ReLU(), nn.MaxPool2d(2,2)\n",
    "        )\n",
    "\n",
    "        self.flattened_size = self._get_flattened_size()\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(self.flattened_size, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "\n",
    "    def _get_flattened_size(self):\n",
    "        with torch.no_grad():\n",
    "            x = torch.randn(1, 3, 300, 500)\n",
    "            x = self.features(x)\n",
    "            return x.view(1, -1).shape[1]\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.classifier(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80ae717",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNBasicV2(nn.Module):\n",
    "    def __init__(self, num_classes=4):\n",
    "        super().__init__()\n",
    "\n",
    "        def block(in_ch, out_ch, pool=True):\n",
    "            layers = [\n",
    "                nn.Conv2d(in_ch, out_ch, kernel_size=3, padding=1, bias=False),\n",
    "                nn.BatchNorm2d(out_ch),\n",
    "                nn.ReLU(inplace=True),\n",
    "            ]\n",
    "            if pool:\n",
    "                layers.append(nn.MaxPool2d(2))\n",
    "            return nn.Sequential(*layers)\n",
    "\n",
    "        self.features = nn.Sequential(\n",
    "            block(3, 32, pool=True),    #300x500 -> 150x250\n",
    "            block(32, 64, pool=True),   #-> 75x125\n",
    "            block(64, 128, pool=True),  #-> 37x62\n",
    "            block(128, 256, pool=False) #pas de pool ici (garde un peu de spatial)\n",
    "        )\n",
    "\n",
    "        #Dropout sur feature maps (souvent meilleur que dropout sur FC pour CNN)\n",
    "        self.dropout = nn.Dropout2d(p=0.2)\n",
    "\n",
    "        #Global Average Pooling => [B, 256, 1, 1]\n",
    "        self.gap = nn.AdaptiveAvgPool2d((1, 1))\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=0.3),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.gap(x).flatten(1)  #[B, 256]\n",
    "        return self.classifier(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3947b065",
   "metadata": {},
   "source": [
    "### RESNET MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e6dbf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import resnet18, ResNet18_Weights\n",
    "class ResNet18EarlyExit(nn.Module):\n",
    "    def __init__(self, num_classes=4, threshold=0.9):\n",
    "        super().__init__()\n",
    "        self.threshold = threshold\n",
    "\n",
    "        base = resnet18(weights=ResNet18_Weights.IMAGENET1K_V1)\n",
    "\n",
    "        self.stem = nn.Sequential(\n",
    "            base.conv1, base.bn1, base.relu, base.maxpool\n",
    "        )\n",
    "        self.layer1 = base.layer1\n",
    "        self.layer2 = base.layer2\n",
    "        self.layer3 = base.layer3\n",
    "        self.layer4 = base.layer4\n",
    "        \n",
    "        self.exit1 = self._make_exit(64, num_classes)\n",
    "        self.exit2 = self._make_exit(128, num_classes)\n",
    "        self.exit3 = self._make_exit(256, num_classes)\n",
    "        self.exit4 = nn.Linear(base.fc.in_features, num_classes)\n",
    "\n",
    "    def _make_exit(self, channels, num_classes):\n",
    "        return nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d((1,1)),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(channels, num_classes)\n",
    "        )\n",
    "    def extract_features(self, x):\n",
    "        features = {}\n",
    "\n",
    "        x = self.stem(x)\n",
    "        x = self.layer1(x)\n",
    "        f1 = torch.flatten(nn.AdaptiveAvgPool2d((1,1))(x), 1)\n",
    "        features[\"exit1\"] = f1\n",
    "\n",
    "        x = self.layer2(x)\n",
    "        f2 = torch.flatten(nn.AdaptiveAvgPool2d((1,1))(x), 1)\n",
    "        features[\"exit2\"] = f2\n",
    "\n",
    "        x = self.layer3(x)\n",
    "        f3 = torch.flatten(nn.AdaptiveAvgPool2d((1,1))(x), 1)\n",
    "        features[\"exit3\"] = f3\n",
    "\n",
    "        x = self.layer4(x)\n",
    "        f4 = torch.flatten(nn.AdaptiveAvgPool2d((1,1))(x), 1)\n",
    "        features[\"exit4\"] = f4\n",
    "\n",
    "        return features\n",
    "    def forward(self, x):\n",
    "        x = self.stem(x)\n",
    "        x = self.layer1(x)\n",
    "        out1 = self.exit1(x)\n",
    "        if self._confident(out1):\n",
    "            return out1\n",
    "        \n",
    "        x = self.layer2(x)\n",
    "        out2 = self.exit2(x)\n",
    "        if self._confident(out2):\n",
    "            return out2\n",
    "        \n",
    "        x = self.layer3(x)\n",
    "        out3 = self.exit3(x)\n",
    "        if self._confident(out3):\n",
    "            return out3\n",
    "        \n",
    "        x = self.layer4(x)\n",
    "        x = nn.AdaptiveAvgPool2d((1,1))(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        out4 = self.exit4(x)\n",
    "        return out4, 4\n",
    "\n",
    "    def _confident(self, logits):\n",
    "        probs = logits.softmax(dim=1)\n",
    "        max_conf = probs.max(dim=1).values\n",
    "        return (max_conf > self.threshold).any()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13372477",
   "metadata": {},
   "source": [
    "### GRAD CAM MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32405e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GradCAM:\n",
    "    \"\"\"\n",
    "    Grad-CAM for a given model + target layer.\n",
    "    Works for CNNs that output logits [B, num_classes].A\n",
    "    \"\"\"\n",
    "    def __init__(self, model, target_layer):\n",
    "        self.model = model\n",
    "        self.target_layer = target_layer\n",
    "\n",
    "        self.activations = None\n",
    "        self.gradients = None\n",
    "\n",
    "        self._fwd_handle = target_layer.register_forward_hook(self._forward_hook)\n",
    "        self._bwd_handle = target_layer.register_full_backward_hook(self._backward_hook)\n",
    "\n",
    "    def _forward_hook(self, module, inp, out):\n",
    "        self.activations = out.detach()\n",
    "\n",
    "    def _backward_hook(self, module, grad_in, grad_out):\n",
    "        # grad_out is a tuple; grad_out[0] shape == activations shape\n",
    "        self.gradients = grad_out[0].detach()\n",
    "\n",
    "    def remove(self):\n",
    "        self._fwd_handle.remove()\n",
    "        self._bwd_handle.remove()\n",
    "\n",
    "    def __call__(self, x, class_idx=None):\n",
    "        \"\"\"\n",
    "        x: Tensor [1, C, H, W]\n",
    "        class_idx: int or None -> if None, uses predicted class\n",
    "        returns: cam (H', W') in [0,1], pred_class, probs\n",
    "        \"\"\"\n",
    "        self.model.zero_grad(set_to_none=True)\n",
    "        logits = self.model(x)  # [1, num_classes]\n",
    "        probs = torch.softmax(logits, dim=1)\n",
    "\n",
    "        pred_class = int(probs.argmax(dim=1).item())\n",
    "        target_class = pred_class if class_idx is None else int(class_idx)\n",
    "\n",
    "        score = logits[0, target_class]\n",
    "        score.backward(retain_graph=False)\n",
    "\n",
    "        # activations: [1, K, H', W'], gradients: [1, K, H', W']\n",
    "        grads = self.gradients[0]      # [K, H', W']\n",
    "        acts = self.activations[0]     # [K, H', W']\n",
    "\n",
    "        # Global-average-pool gradients over spatial dims -> weights [K]\n",
    "        weights = grads.mean(dim=(1, 2))  # [K]\n",
    "\n",
    "        # Weighted sum of activations\n",
    "        cam = (weights[:, None, None] * acts).sum(dim=0)  # [H', W']\n",
    "        cam = F.relu(cam)\n",
    "\n",
    "        # Normalize to [0,1]\n",
    "        cam -= cam.min()\n",
    "        cam /= (cam.max() + 1e-8)\n",
    "\n",
    "        return cam.cpu().numpy(), pred_class, probs.detach().cpu().numpy()[0]\n",
    "\n",
    "def get_last_conv_layer(model):\n",
    "    last_conv = model.features[8]  # dernière Conv2d\n",
    "    return last_conv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d54cc788",
   "metadata": {},
   "source": [
    "### TRAINING METHODS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48128e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensure_dir(path: Path) -> None:\n",
    "    path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def make_class_names(dataset):\n",
    "    # dataset.class_to_idx: {label_str: idx}\n",
    "    idx_to_class = {v: k for k, v in dataset.class_to_idx.items()}\n",
    "    return [idx_to_class[i] for i in range(len(idx_to_class))]\n",
    "\n",
    "\n",
    "def to_device(x, device):\n",
    "    return x.to(device, non_blocking=True)\n",
    "\n",
    "\n",
    "def train_one_epoch(model, loader, optimizer, criterion, device, epoch, epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    loop = tqdm(\n",
    "        enumerate(loader, 0),\n",
    "        total=len(loader),\n",
    "        desc=f\"Epoch {epoch+1}/{epochs} [TRAIN]\"\n",
    "    )\n",
    "\n",
    "    for i, data in loop:\n",
    "        idx, inputs, labels, caption = data\n",
    "        inputs = to_device(inputs, device)\n",
    "        labels = to_device(labels, device)\n",
    "\n",
    "\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        loop.set_postfix(loss=running_loss / (i + 1))\n",
    "\n",
    "    avg_loss = running_loss / len(loader)\n",
    "    return avg_loss\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(\n",
    "    model,\n",
    "    loader,\n",
    "    criterion,\n",
    "    device,\n",
    "    epoch,\n",
    "    epochs,\n",
    "    num_classes,\n",
    "    dataset=None,                 \n",
    "    class_names=None,             \n",
    "    caption_fn=None,              \n",
    "    n_mistakes_to_print=5\n",
    "):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "    all_probs = []\n",
    "\n",
    "    mistakes_printed = 0\n",
    "\n",
    "    loop = tqdm(loader, desc=f\"Epoch {epoch+1}/{epochs} [EVAL]\")\n",
    "\n",
    "    for batch in loop:\n",
    "        idxs, inputs, labels, captions = batch\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "      \n",
    "        logits = model(inputs)\n",
    "        loss = criterion(logits, labels)\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        probs = torch.softmax(logits, dim=1)\n",
    "        preds = probs.argmax(dim=1)\n",
    "\n",
    "        all_labels.append(labels)\n",
    "        all_preds.append(preds)\n",
    "        all_probs.append(probs)\n",
    "\n",
    "\n",
    "        can_print_mistakes = (dataset is not None) and (class_names is not None)\n",
    "        if can_print_mistakes and mistakes_printed < n_mistakes_to_print:\n",
    "            mism_mask = (preds != labels).detach().cpu()\n",
    "            if mism_mask.any():\n",
    "                mism_positions = torch.where(mism_mask)[0].tolist()\n",
    "                for pos in mism_positions:\n",
    "                    if mistakes_printed >= n_mistakes_to_print:\n",
    "                        break\n",
    "\n",
    "                    sample_idx = int(idxs[pos].item())  # idx du dataset\n",
    "                    true_i = int(labels[pos].item())\n",
    "                    pred_i = int(preds[pos].item())\n",
    "\n",
    "                    true_name = class_names[true_i]\n",
    "                    pred_name = class_names[pred_i]\n",
    "\n",
    "                    img_path = dataset._get_img_path_from_idx(sample_idx)\n",
    "                    display(Image.open(img_path).convert('RGB'))\n",
    "                    caption = dataset._get_caption_from_idx(sample_idx)\n",
    "\n",
    "                    print(\"\\n--- Mauvaise prédiction ---\")\n",
    "                    print(f\"dataset_idx : {sample_idx}\")\n",
    "                    print(f\"image      : {img_path}\")\n",
    "                    print(f\"vrai label : {true_name} ({true_i})\")\n",
    "                    print(f\"prédit     : {pred_name} ({pred_i})\")\n",
    "                    print(f\"caption    : {caption}\")\n",
    "\n",
    "                    mistakes_printed += 1\n",
    "\n",
    "    avg_loss = running_loss / len(loader)\n",
    "\n",
    "    all_labels = torch.cat(all_labels)\n",
    "    all_preds = torch.cat(all_preds)\n",
    "    all_probs = torch.cat(all_probs)\n",
    "\n",
    "    accuracy = (all_preds == all_labels).float().mean().item()\n",
    "\n",
    "    return (\n",
    "        avg_loss,\n",
    "        all_labels.cpu().numpy(),\n",
    "        all_preds.cpu().numpy(),\n",
    "        all_probs.cpu().numpy(),\n",
    "        accuracy\n",
    "    )\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate_while_training(\n",
    "    model,\n",
    "    loader,\n",
    "    criterion,\n",
    "    device,\n",
    "    epoch,\n",
    "    epochs,\n",
    "):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "    all_probs = []\n",
    "\n",
    "    loop = tqdm(loader, desc=f\"Epoch {epoch+1}/{epochs} [EVAL]\")\n",
    "\n",
    "    for batch in loop:\n",
    "        idxs, inputs, labels, captions = batch\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "      \n",
    "        logits = model(inputs)\n",
    "        loss = criterion(logits, labels)\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        probs = torch.softmax(logits, dim=1)\n",
    "        preds = probs.argmax(dim=1)\n",
    "\n",
    "        all_labels.append(labels)\n",
    "        all_preds.append(preds)\n",
    "        all_probs.append(probs)\n",
    "\n",
    "    avg_loss = running_loss / len(loader)\n",
    "\n",
    "    all_labels = torch.cat(all_labels)\n",
    "    all_preds = torch.cat(all_preds)\n",
    "    all_probs = torch.cat(all_probs)\n",
    "\n",
    "    accuracy = (all_preds == all_labels).float().mean().item()\n",
    "\n",
    "    return (\n",
    "        avg_loss,\n",
    "        all_labels.cpu().numpy(),\n",
    "        all_preds.cpu().numpy(),\n",
    "        all_probs.cpu().numpy(),\n",
    "        accuracy\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab861e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(\n",
    "    model,\n",
    "    train_loader,\n",
    "    test_loader,\n",
    "    num_classes=4,\n",
    "    epochs=50,\n",
    "    lr=1e-3,\n",
    "    momentum=0.9,\n",
    "    patience=5,\n",
    "    models_dir=Path(\"../models\"),\n",
    "    model_saving_name=\"best_model.pth\",\n",
    "    criterion=None,\n",
    "    class_names=None,\n",
    "):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "\n",
    "    if criterion is None:\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "    optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n",
    "\n",
    "    ensure_dir(models_dir)\n",
    "    best_model_path = models_dir / model_saving_name\n",
    "\n",
    "    best_test_loss = float(\"inf\")\n",
    "    patience_counter = 0\n",
    "\n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        train_loss = train_one_epoch(\n",
    "            model, train_loader, optimizer, criterion, device, epoch, epochs\n",
    "        )\n",
    "        train_losses.append(train_loss)\n",
    "        print(f\"\\nEpoch {epoch+1} - Average TRAIN loss: {train_loss:.4f}\")\n",
    "\n",
    "        test_loss, y_true, y_pred, y_prob, acc = evaluate_while_training(\n",
    "            model, test_loader, criterion, device, epoch, epochs\n",
    "        )\n",
    "        test_losses.append(test_loss)\n",
    "\n",
    "        print(f\"Epoch {epoch+1} - Average TEST loss: {test_loss:.4f}\")\n",
    "        print(\"\\nClassification Report:\")\n",
    "        print(classification_report(y_true, y_pred, digits=3))\n",
    "\n",
    "        # Early stopping + save best\n",
    "        if test_loss < best_test_loss:\n",
    "            best_test_loss = test_loss\n",
    "            patience_counter = 0\n",
    "            torch.save(model.state_dict(), best_model_path)\n",
    "            print(f\"Nouveau meilleur modèle sauvegardé (test loss: {best_test_loss:.4f})\")\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            print(f\"Pas d'amélioration ({patience_counter}/{patience})\")\n",
    "            if patience_counter >= patience:\n",
    "                print(f\"\\nEarly stopping déclenché après {epoch+1} époques\")\n",
    "                print(f\"Meilleur test loss: {best_test_loss:.4f}\")\n",
    "                break\n",
    "\n",
    "    print(f\"\\nChargement du meilleur modèle (test loss: {best_test_loss:.4f})\")\n",
    "    model.load_state_dict(torch.load(best_model_path, map_location=device))\n",
    "\n",
    "    final_test_loss, y_true, y_pred, y_prob, acc = evaluate(\n",
    "        model, test_loader, criterion, device, epoch=0, epochs=1, num_classes=num_classes\n",
    "    )\n",
    "    print(f\"Best model - TEST loss: {final_test_loss:.4f}\")\n",
    "\n",
    "    plot_losses(train_losses, test_losses)\n",
    "    plot_confusion_matrix(y_true, y_pred, class_names=class_names, title=\"Confusion Matrix (Best Model)\")\n",
    "    plot_multiclass_roc(y_true, y_prob, num_classes=num_classes, class_names=class_names, title=\"ROC (Best Model, OvR)\")\n",
    "    return model, {\"train_losses\": train_losses, \"test_losses\": test_losses, \"best_test_loss\": best_test_loss}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab61682",
   "metadata": {},
   "source": [
    "### RESNET TRAINING METHODS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece00b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def configure_finetuning(\n",
    "    model,\n",
    "    mode: str,\n",
    "    lr_backbone=1e-4,\n",
    "    lr_head=1e-3,\n",
    "    weight_decay=1e-5,\n",
    "):\n",
    "    \"\"\"\n",
    "    Configure le fine-tuning RESNET\n",
    "\n",
    "    mode:\n",
    "        - \"freeze_all\"\n",
    "        - \"freeze_until_l3\"\n",
    "        - \"unfreeze_all\"\n",
    "        - \"freeze_semantic\n",
    "    \"\"\"\n",
    "\n",
    "    for p in model.parameters():\n",
    "        p.requires_grad = False\n",
    "\n",
    "    params = []\n",
    "    if mode == \"freeze_all\":\n",
    "        for p in model.fc.parameters():\n",
    "            p.requires_grad = True\n",
    "\n",
    "        params = [\n",
    "            {\"params\": model.fc.parameters(), \"lr\": lr_head}\n",
    "        ]\n",
    "\n",
    "    elif mode == \"freeze_until_l3\":\n",
    "        # défreeze layer4 + fc\n",
    "        for p in model.layer4.parameters():\n",
    "            p.requires_grad = True\n",
    "        for p in model.fc.parameters():\n",
    "            p.requires_grad = True\n",
    "\n",
    "        params = [\n",
    "            {\"params\": model.layer4.parameters(), \"lr\": lr_backbone},\n",
    "            {\"params\": model.fc.parameters(),     \"lr\": lr_head},\n",
    "        ]\n",
    "    elif mode == \"freeze_semantic\":\n",
    "        for p in model.parameters():\n",
    "            p.requires_grad = True\n",
    "\n",
    "        for p in model.layer4.parameters():\n",
    "            p.requires_grad = False\n",
    "        backbone_params = []\n",
    "        head_params = []\n",
    "\n",
    "        for name, p in model.named_parameters():\n",
    "            if not p.requires_grad:\n",
    "                continue\n",
    "            if name.startswith(\"fc.\"):\n",
    "                head_params.append(p)\n",
    "            else:\n",
    "                backbone_params.append(p)\n",
    "\n",
    "        params = [\n",
    "            {\"params\": backbone_params, \"lr\": lr_backbone},\n",
    "            {\"params\": head_params,     \"lr\": lr_head},\n",
    "        ]\n",
    "\n",
    "    elif mode == \"unfreeze_all\":\n",
    "        # tout défreeze\n",
    "        for p in model.parameters():\n",
    "            p.requires_grad = True\n",
    "\n",
    "        params = [\n",
    "            {\"params\": model.parameters(), \"lr\": lr_backbone}\n",
    "        ]\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f\"Mode inconnu : {mode}\")\n",
    "\n",
    "    optimizer = optim.Adam(params, weight_decay=weight_decay)\n",
    "\n",
    "    return optimizer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b6f088",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_experiment(\n",
    "    model,\n",
    "    train_loader,\n",
    "    optimizer,\n",
    "    criterion,\n",
    "    device,\n",
    "    epochs=5\n",
    "):\n",
    "    model.to(device)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "\n",
    "        for idx, inputs, labels, caption in tqdm(\n",
    "            train_loader,\n",
    "            desc=f\"TRAIN epoch {epoch+1}\"\n",
    "        ):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            logits = outputs[0] if isinstance(outputs, tuple) else outputs\n",
    "            loss = criterion(logits, labels)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        print(\n",
    "            f\"Epoch {epoch+1}: \"\n",
    "            f\"Train loss = {running_loss / len(train_loader):.4f}\"\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d9f598",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def extract_resnet_layer_embeddings(model, loader, device, max_batches=None):\n",
    "    \"\"\"\n",
    "    Retourne:\n",
    "      feats: dict { \"layer1\": [N, C1], \"layer2\": [N, C2], \"layer3\": [N, C3], \"layer4\": [N, C4] }\n",
    "      labels: [N]\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    feats = {\"layer1\": [], \"layer2\": [], \"layer3\": [], \"layer4\": []}\n",
    "    all_labels = []\n",
    "\n",
    "    for b, batch in enumerate(loader):\n",
    "        if max_batches is not None and b >= max_batches:\n",
    "            break\n",
    "\n",
    "        _, x, y, _ = batch\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        x = model.conv1(x)\n",
    "        x = model.bn1(x)\n",
    "        x = model.relu(x)\n",
    "        x = model.maxpool(x)\n",
    "\n",
    "        x1 = model.layer1(x)\n",
    "        x2 = model.layer2(x1)\n",
    "        x3 = model.layer3(x2)\n",
    "        x4 = model.layer4(x3)\n",
    "\n",
    "        f1 = F.adaptive_avg_pool2d(x1, (1, 1)).flatten(1)\n",
    "        f2 = F.adaptive_avg_pool2d(x2, (1, 1)).flatten(1)\n",
    "        f3 = F.adaptive_avg_pool2d(x3, (1, 1)).flatten(1)\n",
    "        f4 = F.adaptive_avg_pool2d(x4, (1, 1)).flatten(1)\n",
    "\n",
    "        feats[\"layer1\"].append(f1.cpu())\n",
    "        feats[\"layer2\"].append(f2.cpu())\n",
    "        feats[\"layer3\"].append(f3.cpu())\n",
    "        feats[\"layer4\"].append(f4.cpu())\n",
    "        all_labels.append(y.cpu())\n",
    "\n",
    "    for k in feats:\n",
    "        feats[k] = torch.cat(feats[k], dim=0).numpy()\n",
    "    all_labels = torch.cat(all_labels, dim=0).numpy()\n",
    "\n",
    "    return feats, all_labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ccf3aa",
   "metadata": {},
   "source": [
    "### PLOT METHODS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25a9bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    ConfusionMatrixDisplay,\n",
    "    roc_curve,\n",
    "    auc\n",
    ")\n",
    "from sklearn.preprocessing import label_binarize\n",
    "def plot_losses(train_losses, test_losses):\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.plot(train_losses, label=\"Train loss\")\n",
    "    plt.plot(test_losses, label=\"Test loss\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(\"Training vs Test Loss\")\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "def plot_losses(train_losses, test_losses):\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.plot(train_losses, label=\"Train loss\")\n",
    "    plt.plot(test_losses, label=\"Test loss\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(\"Training vs Test Loss\")\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, class_names=None, title=\"Confusion Matrix\"):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\n",
    "    disp.plot(cmap=\"Blues\", values_format=\"d\", xticks_rotation=45)\n",
    "    plt.title(title)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_multiclass_roc(y_true, y_prob, num_classes, class_names=None, title=\"ROC (One-vs-Rest)\"):\n",
    "    \"\"\"\n",
    "    y_true: [N] int labels\n",
    "    y_prob: [N, C] probabilities\n",
    "    \"\"\"\n",
    "    y_true_bin = label_binarize(y_true, classes=list(range(num_classes)))  # [N, C]\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    for c in range(num_classes):\n",
    "        fpr, tpr, _ = roc_curve(y_true_bin[:, c], y_prob[:, c])\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        name = class_names[c] if class_names is not None else f\"Class {c}\"\n",
    "        plt.plot(fpr, tpr, label=f\"{name} (AUC={roc_auc:.3f})\")\n",
    "\n",
    "    # Diagonal\n",
    "    plt.plot([0, 1], [0, 1], linestyle=\"--\")\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.title(title)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "633afe63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "def plot_tsne(model, loader, class_names, max_samples=500):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    model.eval()\n",
    "    feats = { \"exit1\": [], \"exit2\": [], \"exit3\": [], \"exit4\": [] }\n",
    "    labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for _, (idx, imgs, y, caption) in enumerate(loader):\n",
    "            imgs = imgs.to(device)\n",
    "\n",
    "            features = model.extract_features(imgs)\n",
    "            for k in feats.keys():\n",
    "                feats[k].append(features[k].cpu().numpy())\n",
    "\n",
    "            labels.append(y.numpy())\n",
    "            if len(labels) * imgs.size(0) > max_samples:\n",
    "                break\n",
    "\n",
    "    for k in feats.keys():\n",
    "        X = np.concatenate(feats[k], axis=0)\n",
    "        Y = np.concatenate(labels, axis=0)\n",
    "\n",
    "        X_2d = TSNE(n_components=2, learning_rate=\"auto\", init=\"pca\").fit_transform(X)\n",
    "\n",
    "        plt.figure(figsize=(6,5))\n",
    "        for i, class_name in enumerate(class_names):\n",
    "            pts = X_2d[Y == i]\n",
    "            plt.scatter(pts[:,0], pts[:,1], s=12, label=class_name)\n",
    "\n",
    "        plt.title(f\"t-SNE — {k}\")\n",
    "        plt.legend()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c399a158",
   "metadata": {},
   "outputs": [],
   "source": [
    "def denorm_05(t):\n",
    "    #[3,H,W] in [-1,1]\n",
    "    return (t * 0.5 + 0.5).clamp(0, 1)\n",
    "\n",
    "def show_cam_overlay(img_tensor, cam, title=\"Grad-CAM\"):\n",
    "    \"\"\"\n",
    "    img_tensor: [3,H,W] (normalized), cam: [H',W'] from GradCAM\n",
    "    \"\"\"\n",
    "    img = denorm_05(img_tensor).permute(1,2,0).cpu().numpy()  # [H,W,3]\n",
    "\n",
    "    # Resize cam to image size\n",
    "    cam_t = torch.tensor(cam)[None, None, ...]  # [1,1,H',W']\n",
    "    cam_resized = F.interpolate(cam_t, size=img.shape[:2], mode=\"bilinear\", align_corners=False)\n",
    "    cam_resized = cam_resized[0,0].cpu().numpy()\n",
    "\n",
    "    plt.figure(figsize=(10,4))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.imshow(img)\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(\"Image\")\n",
    "\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.imshow(img)\n",
    "    plt.imshow(cam_resized, alpha=0.45) \n",
    "    plt.axis(\"off\")\n",
    "    plt.title(title)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332fe4de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_tsne_one(feat_2d, labels, class_names, title):\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    for i, name in enumerate(class_names):\n",
    "        mask = labels == i\n",
    "        plt.scatter(feat_2d[mask, 0], feat_2d[mask, 1], s=10, label=name, alpha=0.7)\n",
    "    plt.title(title)\n",
    "    plt.legend(markerscale=2, fontsize=8)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_tsne_layers(model, loader, device, class_names, mode_name=\"\", max_batches=None,\n",
    "                     perplexity=30, n_iter=1000, random_state=0):\n",
    "    feats, labels = extract_resnet_layer_embeddings(model, loader, device, max_batches=max_batches)\n",
    "\n",
    "    for layer_name in [\"layer1\", \"layer2\", \"layer3\", \"layer4\"]:\n",
    "        X = feats[layer_name]\n",
    "\n",
    "        # t-SNE\n",
    "        tsne = TSNE(\n",
    "            n_components=2,\n",
    "            perplexity=perplexity,\n",
    "            init=\"pca\",\n",
    "            learning_rate=\"auto\",\n",
    "            random_state=random_state\n",
    "        )\n",
    "        X2 = tsne.fit_transform(X)\n",
    "\n",
    "        plot_tsne_one(\n",
    "            X2, labels, class_names,\n",
    "            title=f\"t-SNE {mode_name} — {layer_name} (N={len(labels)})\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7dac238",
   "metadata": {},
   "source": [
    "### ERRORS VISU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af2f0068",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def show_5_mistakes_with_gradcam(\n",
    "    model,\n",
    "    loader,\n",
    "    device,\n",
    "    class_names,\n",
    "    target_layer,          #POUR CNN BASIC model.features[8]\n",
    "    dataset=None,\n",
    "    n=5\n",
    "):\n",
    "    model.eval()\n",
    "    gc = GradCAM(model, target_layer)\n",
    "    shown = 0\n",
    "\n",
    "    for idxs, inputs, labels, captions in loader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        logits = model(inputs)\n",
    "        probs = torch.softmax(logits, dim=1)\n",
    "        preds = probs.argmax(dim=1)\n",
    "\n",
    "        mism = (preds != labels).detach().cpu()\n",
    "        if mism.any():\n",
    "            for pos in torch.where(mism)[0].tolist():\n",
    "                if shown >= n:\n",
    "                    gc.remove()\n",
    "                    return\n",
    "\n",
    "                sample_idx = int(idxs[pos].item())\n",
    "                true_i = int(labels[pos].item())\n",
    "                pred_i = int(preds[pos].item())\n",
    "\n",
    "                true_name = class_names[true_i]\n",
    "                pred_name = class_names[pred_i]\n",
    "                caption = captions[pos]\n",
    "\n",
    "                img_path = dataset._get_img_path_from_idx(sample_idx) if dataset is not None else \"N/A\"\n",
    "\n",
    "                print(\"\\n--- Mauvaise prédiction ---\")\n",
    "                print(f\"dataset_idx : {sample_idx}\")\n",
    "                print(f\"image      : {img_path}\")\n",
    "                print(f\"vrai label : {true_name} ({true_i})\")\n",
    "                print(f\"prédit     : {pred_name} ({pred_i})\")\n",
    "                print(f\"caption    : {caption}\")\n",
    "\n",
    "                x1 = inputs[pos:pos+1].detach()\n",
    "                x1.requires_grad_(True)\n",
    "\n",
    "                cam_map, _, _ = gc(x1, class_idx=pred_i)\n",
    "\n",
    "                show_cam_overlay(\n",
    "                    inputs[pos].detach().cpu(),\n",
    "                    cam_map,\n",
    "                    title=f\"Grad-CAM (true={true_name} pred={pred_name})\"\n",
    "                )\n",
    "\n",
    "                shown += 1\n",
    "\n",
    "    gc.remove()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c96157",
   "metadata": {},
   "source": [
    "### CNN TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04501a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = make_class_names(train_dataset_custom)\n",
    "class_names\n",
    "\n",
    "model = CNNBasic(4)  \n",
    "trained_model, history = fit(\n",
    "    model=model,\n",
    "    train_loader=train_loader_custom,\n",
    "    test_loader=test_loader_custom,\n",
    "    num_classes=4,\n",
    "    epochs=50,\n",
    "    lr=1e-3,\n",
    "    momentum=0.9,\n",
    "    patience=5,\n",
    "    models_dir=Path(\"../models\"),\n",
    "    model_saving_name=\"best_model_2.pth\",\n",
    "    criterion=nn.CrossEntropyLoss(),\n",
    "    class_names=class_names,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e743e4",
   "metadata": {},
   "source": [
    "### CNN EVAL ON NO AUGMENTED DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e309ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_path = Path(\"../models/best_model_2.pth\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_loaded = CNNBasic(num_classes=4)\n",
    "model_loaded = model_loaded.to(device)\n",
    "model_loaded.load_state_dict(torch.load(best_model_path, map_location=device))\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "final_test_loss, y_true, y_pred, y_prob, acc = evaluate(\n",
    "    model_loaded, train_loader_custom_noaug, criterion, device, class_names=class_names, epoch=0, epochs=1, num_classes=4,dataset=train_dataset_custom_noaug\n",
    ")\n",
    "print(f\"Best model - TEST loss: {final_test_loss:.4f}\")\n",
    "print(f\"Accuracy : {acc}\\n\")\n",
    "plot_confusion_matrix(y_true, y_pred, class_names=class_names, title=\"Confusion Matrix (Best Model)\")\n",
    "plot_multiclass_roc(y_true, y_prob, num_classes=4, class_names=class_names, title=\"ROC (Best Model, OvR)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86838494",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_layer = model_loaded.features[8]\n",
    "show_5_mistakes_with_gradcam(\n",
    "    model=model_loaded,\n",
    "    loader=train_loader_custom_noaug,\n",
    "    device=device,\n",
    "    class_names=class_names,\n",
    "    target_layer=target_layer,\n",
    "    dataset=train_dataset_custom_noaug,\n",
    "    n=5\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cba1dc4",
   "metadata": {},
   "source": [
    "### CNN BASIC SECOND TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e424f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_path = Path(\"../models/best_model_2.pth\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_loaded = CNNBasic(num_classes=4)\n",
    "model_loaded = model_loaded.to(device)\n",
    "model_loaded.load_state_dict(torch.load(best_model_path, map_location=device))\n",
    "\n",
    "trained_model, history = fit(\n",
    "    model=model_loaded,\n",
    "    train_loader=train_loader_custom_noaug,\n",
    "    test_loader=test_loader_custom_noaug,\n",
    "    num_classes=4,\n",
    "    epochs=50,\n",
    "    lr=1e-3,\n",
    "    momentum=0.9,\n",
    "    patience=5,\n",
    "    models_dir=Path(\"../models\"),\n",
    "    model_saving_name=\"best_model_v2_2train.pth\",\n",
    "    criterion=nn.CrossEntropyLoss(),\n",
    "    class_names=class_names,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "181877f8",
   "metadata": {},
   "source": [
    "### CNN EVAL SECON TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb23ec94",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_path = Path(\"../models/best_model_v2_2train.pth\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_loaded = CNNBasic(num_classes=4)\n",
    "model_loaded = model_loaded.to(device)\n",
    "model_loaded.load_state_dict(torch.load(best_model_path, map_location=device))\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "final_test_loss, y_true, y_pred, y_prob, acc = evaluate(\n",
    "    model_loaded, val_loader_custom_noaug, criterion, device, class_names=class_names, epoch=0, epochs=1, num_classes=4,dataset=val_dataset_custom_noaug\n",
    ")\n",
    "print(f\"Best model - TEST loss: {final_test_loss:.4f}\")\n",
    "print(f\"Accuracy : {acc}\\n\")\n",
    "plot_confusion_matrix(y_true, y_pred, class_names=class_names, title=\"Confusion Matrix (Best Model)\")\n",
    "plot_multiclass_roc(y_true, y_prob, num_classes=4, class_names=class_names, title=\"ROC (Best Model, OvR)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "442a447b",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_layer = model_loaded.features[8]\n",
    "show_5_mistakes_with_gradcam(\n",
    "    model=model_loaded,\n",
    "    loader=val_loader_custom_noaug,\n",
    "    device=device,\n",
    "    class_names=class_names,\n",
    "    target_layer=target_layer,\n",
    "    dataset=val_dataset_custom_noaug,\n",
    "    n=5\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adca496f",
   "metadata": {},
   "source": [
    "### RESNET TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dbc418c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import resnet18, ResNet18_Weights\n",
    "num_classes = 4\n",
    "\n",
    "model_resnet = resnet18(weights=ResNet18_Weights.IMAGENET1K_V1)\n",
    "model_resnet.fc = nn.Linear(model_resnet.fc.in_features, num_classes)\n",
    "model_resnet.avgpool = nn.AdaptiveAvgPool2d((1, 1)) \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model_resnet = model_resnet.to(device)\n",
    "optimizer = optim.Adam(model_resnet.parameters(), lr=1e-4, weight_decay=1e-5)\n",
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model_resnet.parameters(), lr=1e-4, weight_decay=1e-5)\n",
    "\n",
    "best_val_loss = float(\"inf\")\n",
    "best_epoch = -1\n",
    "save_path = \"best-model-resnet.pth\"\n",
    "\n",
    "for epoch in range(11):\n",
    "    model_resnet.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for idx, inputs, labels, caption in tqdm(train_loader_resnet, desc=f\"TRAIN {epoch+1}\"):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        logits = model_resnet(inputs)\n",
    "        loss = criterion(logits, labels)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    train_loss = running_loss / len(train_loader_resnet)\n",
    "    print(f\"Epoch {epoch+1}: Train loss = {train_loss:.4f}\")\n",
    "\n",
    "\n",
    "    model_resnet.eval()\n",
    "    val_loss = 0.0\n",
    "    correct, total = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, inputs, labels, caption in tqdm(val_loader_resnet, desc=f\"VAL {epoch+1}\"):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            logits = model_resnet(inputs)\n",
    "            loss = criterion(logits, labels)\n",
    "\n",
    "            val_loss += loss.item()\n",
    "            preds = logits.argmax(dim=1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    val_loss /= len(val_loader_resnet)\n",
    "    val_acc = correct / total\n",
    "\n",
    "    print(f\"Epoch {epoch+1}: Val loss = {val_loss:.4f} | Val acc = {val_acc:.4f}\")\n",
    "\n",
    "    # ===== SAVE BEST =====\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        best_epoch = epoch + 1\n",
    "\n",
    "        torch.save({\n",
    "            \"epoch\": best_epoch,\n",
    "            \"model_state_dict\": model_resnet.state_dict(),\n",
    "            \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "            \"val_loss\": best_val_loss,\n",
    "        }, save_path)\n",
    "\n",
    "        print(f\"Best model saved at epoch {best_epoch} with val_loss={best_val_loss:.4f}\")\n",
    "\n",
    "print(f\"\\nTraining finished. Best epoch = {best_epoch}, best val_loss = {best_val_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c935ff2",
   "metadata": {},
   "source": [
    "### RESNET EVAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc2d1398",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "final_test_loss, y_true, y_pred, y_prob, acc = evaluate(\n",
    "    model_resnet, test_loader_resnet_noaug, criterion, device, epoch=0, epochs=1, num_classes=num_classes\n",
    ")\n",
    "print(f\"Best model - TEST loss: {final_test_loss:.4f}\")\n",
    "print(f\"Accuracy : {acc}\\n\")\n",
    "plot_confusion_matrix(y_true, y_pred, class_names=class_names, title=\"Confusion Matrix (Best Model)\")\n",
    "plot_multiclass_roc(y_true, y_prob, num_classes=4, class_names=class_names, title=\"ROC (Best Model, OvR)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "927ff218",
   "metadata": {},
   "source": [
    "### RENETS LAYER FINETUNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae8ca373",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_class_names_resnet(dataset):\n",
    "    # dataset.class_to_idx: {label_str: idx}\n",
    "    idx_to_class = {v: k for k, v in dataset.class_to_idx.items()}\n",
    "    print(idx_to_class)\n",
    "    return [idx_to_class[i] for i in range(len(idx_to_class))]\n",
    "\n",
    "\n",
    "class_name_resnet = make_class_names_resnet(train_dataset_resnet_noaug)\n",
    "\n",
    "modes = [\n",
    "    \"freeze_all\",\n",
    "    \"freeze_until_l3\",\n",
    "    \"freeze_semantic\",\n",
    "    \"unfreeze_all\",\n",
    "]\n",
    "\n",
    "for mode in modes:\n",
    "    print(f\"Training mode: {mode}\")\n",
    "\n",
    "\n",
    "    model_resnet_freeze = resnet18(weights=ResNet18_Weights.IMAGENET1K_V1)\n",
    "    model_resnet_freeze.fc = nn.Linear(model_resnet_freeze.fc.in_features, num_classes)\n",
    "\n",
    "    optimizer = configure_finetuning(model_resnet_freeze, mode=mode)\n",
    "\n",
    "    train_one_experiment(\n",
    "        model=model_resnet_freeze,\n",
    "        train_loader=train_loader_resnet,\n",
    "        optimizer=optimizer,\n",
    "        criterion=criterion,\n",
    "        device=device,\n",
    "        epochs=5\n",
    "    )\n",
    "\n",
    "    plot_tsne_layers(\n",
    "        model=model_resnet_freeze,\n",
    "        loader=val_loader_resnet,\n",
    "        device=device,\n",
    "        class_names=class_names,\n",
    "        mode_name=mode,\n",
    "        max_batches=10,       \n",
    "        perplexity=30,\n",
    "        random_state=11\n",
    "    )\n",
    "    target_layer = model_resnet_freeze.layer4[-1]\n",
    "\n",
    "    show_5_mistakes_with_gradcam(\n",
    "        model=model_resnet_freeze,\n",
    "        loader=train_loader_custom_noaug,\n",
    "        device=device,\n",
    "        class_names=class_name_resnet,\n",
    "        target_layer=target_layer,\n",
    "        dataset=train_dataset_custom_noaug,\n",
    "        n=5\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c39949f",
   "metadata": {},
   "source": [
    "### RESNET LAYER 3 CLASSIFICATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515b20c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet18Layer3Classifier(nn.Module):\n",
    "    def __init__(self, num_classes=4, weights=ResNet18_Weights.IMAGENET1K_V1):\n",
    "        super().__init__()\n",
    "        base = resnet18(weights=weights)\n",
    "\n",
    "        #backbone layer3\n",
    "        self.conv1 = base.conv1\n",
    "        self.bn1 = base.bn1\n",
    "        self.relu = base.relu\n",
    "        self.maxpool = base.maxpool\n",
    "        self.layer1 = base.layer1\n",
    "        self.layer2 = base.layer2\n",
    "        self.layer3 = base.layer3\n",
    "\n",
    "        self.pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(256, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "\n",
    "        x = self.pool(x).flatten(1)\n",
    "        logits = self.fc(x)\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3ebcec",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_l3 = ResNet18Layer3Classifier(num_classes=4).to(device)\n",
    "\n",
    "optimizer = optim.Adam(model_l3.parameters(), lr=1e-4, weight_decay=1e-5)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in range(11):\n",
    "    model_l3.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for idx, inputs, labels, caption in tqdm(train_loader_resnet, desc=f\"TRAIN {epoch+1}\"):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        logits = model_l3(inputs)\n",
    "        loss = criterion(logits, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}: Train loss = {running_loss/len(train_loader_resnet):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "499b7eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_test_loss, y_true, y_pred, y_prob, acc = evaluate(\n",
    "    model_l3, train_loader_resnet_noaug, criterion, device, epoch=0, epochs=1, num_classes=num_classes\n",
    ")\n",
    "print(f\"Best model - TEST loss: {final_test_loss:.4f}\")\n",
    "print(f\"Accuracy : {acc}\\n\")\n",
    "plot_confusion_matrix(y_true, y_pred, class_names=class_names, title=\"Confusion Matrix (Best Model)\")\n",
    "plot_multiclass_roc(y_true, y_prob, num_classes=4, class_names=class_names, title=\"ROC (Best Model, OvR)\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
