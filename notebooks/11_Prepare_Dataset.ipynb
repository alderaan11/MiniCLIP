{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "957c921c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from typing import List, Dict, Tuple\n",
    "from PIL import Image, ImageEnhance, ImageOps, ImageDraw, ImageFilter\n",
    "from pydantic import BaseModel\n",
    "from enum import Enum\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea6a784b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "from pydantic import BaseModel\n",
    "from typing import Dict, List\n",
    "\n",
    "class AugmType(Enum):\n",
    "    H_FLIP = \"h_flip\"\n",
    "    V_FLIP = \"v_flip\"\n",
    "    CROP = \"crop\"\n",
    "    PAD = \"padding\"\n",
    "    BRIGHT = \"brightness\"\n",
    "    CONTRAST = \"contrast\"\n",
    "    SAT = \"saturation\"\n",
    "    ROT = \"rotate\"\n",
    "    FLASH = \"flash\"\n",
    "    BW = \"bw\"\n",
    "\n",
    "\n",
    "class Label(Enum):\n",
    "    DOG = \"dog\"\n",
    "    BIKE = \"bike\"\n",
    "    BALL = \"ball\"\n",
    "    WATER = \"water\"    \n",
    "\n",
    "\n",
    "\n",
    "class ImageDir(BaseModel):\n",
    "    img_stem: str\n",
    "    label: Label\n",
    "    caption: str\n",
    "    imgs_paths: Dict[str, List[AugmType]]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "659137fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "flicker_dir = Path(\"../data/flicker\")\n",
    "flicker_dir_2 = Path(\"../data/flickr_long_subset\")\n",
    "\n",
    "data_dir = flicker_dir\n",
    "\n",
    "flicker_imgs_dir = data_dir / \"images\"\n",
    "caption_csv_path = data_dir / \"captions.csv\"\n",
    "\n",
    "\n",
    "augmented_dir = Path(\"../data/augmented\")\n",
    "augmented_dir_no = Path(\"../data/augmented_no\")\n",
    "augmented_dir_2 = Path(\"../data/augmented_2\")\n",
    "augmented_dir_3 = Path(\"../data/augmented_3\")\n",
    "\n",
    "ag = augmented_dir_3\n",
    "\n",
    "flicker_dir.mkdir(parents=True, exist_ok=True)\n",
    "ag.mkdir(parents=True, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "df0244d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['image_path', 'label', 'caption'], dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(caption_csv_path)\n",
    "df2 = pd.read_csv(flicker_dir / \"captions.csv\")\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df3a7f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(img_path: Path) -> Image.Image:\n",
    "    return Image.open(img_path).convert('RGB')\n",
    "\n",
    "def random_horizontal_flip(img: Image.Image, flip: float) -> Tuple[float, Image.Image]:\n",
    "    random_flip = random.random()\n",
    "    if random_flip < flip:\n",
    "        return random_flip, ImageOps.mirror(img)\n",
    "    return random_flip, img\n",
    "\n",
    "def random_vertical_flip(img: Image.Image, flip: float) -> Tuple[float, Image.Image]:\n",
    "    random_flip = random.random()\n",
    "    if random_flip < flip:\n",
    "        return random_flip, ImageOps.flip(img)  \n",
    "    return random_flip, img\n",
    "\n",
    "def random_crop(img: Image.Image, scale: float) -> Tuple[Tuple[int], Image.Image]:\n",
    "    w, h = img.size\n",
    "    crop_w = int(w * scale)\n",
    "    crop_h = int(h * scale)\n",
    "\n",
    "    x = random.randint(0, w - crop_w)\n",
    "    y = random.randint(0, h - crop_h)\n",
    "\n",
    "    cropped = img.crop((x, y, x+crop_w, y+crop_h))\n",
    "    return ((x, y), cropped.resize((w,h), Image.BILINEAR))\n",
    "\n",
    "def random_padding(img: Image.Image, padding_range: int) -> Tuple[int, Image.Image]:\n",
    "    pad = random.randint(0, padding_range)\n",
    "    w, h = img.size\n",
    "    padded = ImageOps.expand(img, border=pad, fill=(0,0,0))\n",
    "    return (pad, padded.resize((w,h), Image.BILINEAR))\n",
    "\n",
    "def random_brightness(img: Image.Image, min_range: int, max_range: int) -> Tuple[float, Image.Image]:\n",
    "    amount = random.uniform(min_range, max_range)\n",
    "    factor = 1 + (amount / 100.0)\n",
    "    enhancer = ImageEnhance.Brightness(img)\n",
    "    return (factor, enhancer.enhance(factor))\n",
    "\n",
    "\n",
    "def random_contrast(img: Image.Image, min_range: int, max_range: int) -> Tuple[float, Image.Image]:\n",
    "    amount = random.uniform(min_range, max_range)\n",
    "    factor = 1 + (amount / 100.0)\n",
    "    enhancer = ImageEnhance.Contrast(img)\n",
    "    return (factor, enhancer.enhance(factor))\n",
    "\n",
    "\n",
    "def random_saturation(img: Image.Image, min_range: int, max_range: int) -> Tuple[float, Image.Image]:\n",
    "    amount = random.uniform(min_range, max_range)\n",
    "    factor = 1 + (amount / 100.0)\n",
    "    enhancer = ImageEnhance.Color(img)\n",
    "    return (factor, enhancer.enhance(factor))\n",
    "\n",
    "\n",
    "def random_rotate(img: Image.Image, min_angle: int, max_angle: int) -> Tuple[float, Image.Image]:\n",
    "    angle = random.uniform(min_angle, max_angle)\n",
    "    return (angle, img.rotate(angle, resample=Image.BILINEAR, expand=True).resize(img.size))\n",
    "\n",
    "\n",
    "def random_flash(img: Image.Image, max_radius: float, max_intensity: float) -> Image.Image:\n",
    "    w, h= img.size\n",
    "\n",
    "    flash_mask = Image.new(\"L\", (w, h), 0)\n",
    "    draw = ImageDraw.Draw(flash_mask)\n",
    "\n",
    "    cx = random.randint(0, w)\n",
    "    cy = random.randint(0, h)\n",
    "\n",
    "    radius = int(min(w,h) * random.uniform(0.1, max_radius))\n",
    "\n",
    "    intensity = int(255 * random.uniform(0.3, max_intensity))\n",
    "\n",
    "    draw.ellipse((cx - radius, cy - radius, cx + radius, cy + radius), fill=intensity)\n",
    "\n",
    "    flash_mask = flash_mask.filter(ImageFilter.GaussianBlur(radius / 2))\n",
    "    white_layer = Image.new(\"RGB\", (w, h), (255, 255, 255))\n",
    "\n",
    "    return Image.composite(white_layer, img, flash_mask)\n",
    "\n",
    "def random_black_and_white(img: Image.Image) -> Tuple[float, Image.Image]:    \n",
    "    bw = ImageOps.grayscale(img).convert(\"RGB\")\n",
    "    return bw\n",
    "    \n",
    "\n",
    "def sequence_aug_spatial(img: Image.Image, prob: float) -> Image.Image:\n",
    "    list_aug : List[str] = []\n",
    "    if random.random() < prob:\n",
    "        i, img = random_horizontal_flip(img, flip=0.5)\n",
    "        list_aug.append(\"h_flip\")\n",
    "    if random.random() < prob:\n",
    "        i, img = random_vertical_flip(img, flip=0.5)\n",
    "        list_aug.append(\"v_flip\")\n",
    "    if random.random() < prob:\n",
    "        i, img = random_crop(img, scale=0.9)\n",
    "        list_aug.append(\"crop\")\n",
    "    # if random.random() < prob:\n",
    "    #     img = random_padding(img, padding_range=20)\n",
    "\n",
    "    if random.random() < prob:\n",
    "        i, img = random_rotate(img, -10, 10)\n",
    "        list_aug.append(\"rotate\")\n",
    "\n",
    "    return list_aug, img\n",
    "\n",
    "def sequence_aug_colors(img: Image.Image, prob: float) -> Image.Image:\n",
    "    list_aug : List[str] = []\n",
    "    if random.random() < 0.3:\n",
    "        img = random_black_and_white(img)\n",
    "        list_aug.append(\"bw\")\n",
    "        return list_aug, img\n",
    "    if random.random() < prob:\n",
    "        img = random_flash(img, 0.4, 1.7)\n",
    "        list_aug.append((\"flash\"))\n",
    "    if random.random() < prob:\n",
    "        i, img = random_brightness(img, -20, 40)\n",
    "        list_aug.append(\"brightness\")\n",
    "    if random.random() < prob:\n",
    "        i, img = random_saturation(img, -20, 40)\n",
    "        list_aug.append(\"saturation\")\n",
    "    if random.random() < prob:\n",
    "        i, img = random_contrast(img, 0, 40)\n",
    "        list_aug.append(\"contrast\")\n",
    "\n",
    "    return list_aug, img\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "300e5918",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_augm_enum_list(list_str: List[str]) -> List[AugmType]:\n",
    "    return [AugmType(s) for \n",
    "    s in list_str]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf1c8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in df.iterrows(): \n",
    "    img_path = Path(row[\"image_path\"])\n",
    "    label = Label(row[\"label\"])\n",
    "    caption = row[\"caption\"]\n",
    "    path = data_dir / img_path\n",
    "    # path = flicker_dir_2 / img_path\n",
    "    \n",
    "    type_dir = ag / label.value\n",
    "    type_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    img_dir = type_dir / img_path.stem\n",
    "    img_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    img = load_image(path)\n",
    "    new_img_path = img_dir / f\"{img_path.stem}.jpg\"\n",
    "    img.save(new_img_path)\n",
    "\n",
    "    # list_spatial_aug, spatial_aug_img = sequence_aug_spatial(img, 0.7)\n",
    "    # img_spatial_aug_path = img_dir / f\"{img_path.stem}_spatial.jpg\"\n",
    "    # spatial_aug_img.save(img_spatial_aug_path)\n",
    "\n",
    "    # list_color_aug, color_aug_img = sequence_aug_colors(img, 0.7)\n",
    "    # img_color_aug_path = img_dir / f\"{img_path.stem}_color.jpg\"\n",
    "    # color_aug_img.save(img_color_aug_path)\n",
    "\n",
    "    # spatial_enum = to_augm_enum_list(list_spatial_aug)\n",
    "    # color_enum = to_augm_enum_list(list_color_aug)\n",
    "\n",
    "    imgs_paths = {\n",
    "        str(new_img_path): [],\n",
    "        # str(img_spatial_aug_path): spatial_enum,\n",
    "        # str(img_color_aug_path): color_enum,\n",
    "    }\n",
    "\n",
    "    img_infos = ImageDir(\n",
    "        img_stem=img_path.stem,\n",
    "        label=label,\n",
    "        caption=caption,\n",
    "        imgs_paths=imgs_paths\n",
    "    )\n",
    "\n",
    "    infos_path = img_dir / \"infos.json\"\n",
    "    infos_path.write_text(img_infos.model_dump_json(indent=4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8cab9a35",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotADirectoryError",
     "evalue": "[Errno 20] Not a directory: '../data/augmented_3/metadata.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNotADirectoryError\u001b[39m                        Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m rows = []\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m type_dir \u001b[38;5;129;01min\u001b[39;00m ag.iterdir():\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mimg_dir\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtype_dir\u001b[49m\u001b[43m.\u001b[49m\u001b[43miterdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m        \u001b[49m\u001b[43mjson_path\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mimg_dir\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m/infos.json\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mjson_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mutf-8\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mas\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.11.14-linux-x86_64-gnu/lib/python3.11/pathlib.py:931\u001b[39m, in \u001b[36mPath.iterdir\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    927\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34miterdir\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    928\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Iterate over the files in this directory.  Does not yield any\u001b[39;00m\n\u001b[32m    929\u001b[39m \u001b[33;03m    result for the special paths '.' and '..'.\u001b[39;00m\n\u001b[32m    930\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m931\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m os.listdir(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    932\u001b[39m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28mself\u001b[39m._make_child_relpath(name)\n",
      "\u001b[31mNotADirectoryError\u001b[39m: [Errno 20] Not a directory: '../data/augmented_3/metadata.csv'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "rows = []\n",
    "for type_dir in ag.iterdir():\n",
    "    for img_dir in type_dir.iterdir():\n",
    "        json_path = Path(f\"{img_dir}/infos.json\")\n",
    "        with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            data = json.load(f)\n",
    "            imgs_infos = ImageDir(**data)\n",
    "        \n",
    "        for k, v in imgs_infos.imgs_paths.items():\n",
    "            rows.append({\n",
    "                \"image_path\": Path(k).name,\n",
    "                \"label\": imgs_infos.label,\n",
    "                \"caption\": imgs_infos.caption,\n",
    "\n",
    "            })\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "print(df)\n",
    "\n",
    "pd_output_path = Path(f\"{ag}/metadata.csv\")\n",
    "\n",
    "df.to_csv(pd_output_path, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "332d94af",
   "metadata": {},
   "source": [
    "### CONCATENATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cef3d03b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requesting...\n",
      "\n",
      "Téléchargement réussi. Extraction...\n",
      "Données extraites dans : ../data/new_dataset\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import io \n",
    "import os\n",
    "import zipfile\n",
    "flicker_dir = Path(\"../data/new_dataset\")\n",
    "flicker_dir.mkdir(parents=True, exist_ok=True)\n",
    "'''Get dataset from flicker'''\n",
    "# url = \"https://www.lirmm.fr/~poncelet/Ressources/flickr_subset2.zip\"\n",
    "url_augmented = \"https://www.lirmm.fr/~poncelet/Ressources/flickr_long_subset.zip\"\n",
    "print(\"Requesting...\\n\")\n",
    "response = requests.get(url_augmented)\n",
    "if response.status_code == 200:\n",
    "    print(\"Téléchargement réussi. Extraction...\")\n",
    "    with zipfile.ZipFile(io.BytesIO(response.content)) as zip_ref:\n",
    "        # Extraire sans ajouter de sous-dossier supplémentaire\n",
    "        for member in zip_ref.namelist():\n",
    "            # Corrige les chemins pour ignorer un éventuel prefixe flickr_subset2/\n",
    "            member_path = member\n",
    "            if member.startswith(\"flickr_subset2/\"):\n",
    "                member_path = member[len(\"flickr_subset2/\"):]\n",
    "            target_path = flicker_dir / member_path\n",
    "\n",
    "            # Si c'est un répertoire, on le crée\n",
    "            if member.endswith(\"/\"):\n",
    "                target_path.mkdir(exist_ok=True, parents=True)\n",
    "            else:\n",
    "                os.makedirs(os.path.dirname(target_path), exist_ok=True)\n",
    "                with zip_ref.open(member) as source, open(target_path, \"wb\") as target:\n",
    "                    target.write(source.read())\n",
    "    print(f\"Données extraites dans : {flicker_dir}\")\n",
    "else:\n",
    "    print(\"Échec du téléchargement. Code HTTP :\", response.status_code)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de9be99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "base_dataset_dir = Path(\"../data/flicker\")\n",
    "new_dataset_dir = Path(\"../data/flickr_long_subset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b9cee91",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_base = pd.read_csv(base_dataset_dir / \"captions.csv\")\n",
    "df_new = pd.read_csv(new_dataset_dir / \"captions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4523972d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['image_path', 'label', 'caption'], dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8adafbee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "final_dataset_dir = Path(\"../data/final_dataset_noaug2\")\n",
    "final_dataset_dir.mkdir(parents=True, exist_ok=True)\n",
    "for index, row in df_new.iterrows(): \n",
    "\n",
    "    img_path = Path(row[\"image_path\"])\n",
    "    label = Label(row[\"label\"])\n",
    "    caption = row[\"caption\"]\n",
    "    path = new_dataset_dir / img_path\n",
    "    # path = flicker_dir_2 / img_path\n",
    "    \n",
    "    type_dir = final_dataset_dir /  f\"new_{label.value}\"\n",
    "    type_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    img_dir = type_dir / img_path.stem\n",
    "    img_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    img = load_image(path)\n",
    "    new_img_path = img_dir / f\"new_{img_path.stem}.jpg\"\n",
    "    img.save(new_img_path)\n",
    "\n",
    "    # list_spatial_aug, spatial_aug_img = sequence_aug_spatial(img, 0.7)\n",
    "    # img_spatial_aug_path = img_dir / f\"new_{img_path.stem}_spatial.jpg\"\n",
    "    # spatial_aug_img.save(img_spatial_aug_path)\n",
    "\n",
    "    # list_color_aug, color_aug_img = sequence_aug_colors(img, 0.7)\n",
    "    # img_color_aug_path = img_dir / f\"new_{img_path.stem}_color.jpg\"\n",
    "    # color_aug_img.save(img_color_aug_path)\n",
    "\n",
    "    # spatial_enum = to_augm_enum_list(list_spatial_aug)\n",
    "    # color_enum = to_augm_enum_list(list_color_aug)\n",
    "\n",
    "    imgs_paths = {\n",
    "        str(new_img_path): [],\n",
    "        # str(img_spatial_aug_path): spatial_enum,\n",
    "        # str(img_color_aug_path): color_enum,\n",
    "    }\n",
    "\n",
    "    img_infos = ImageDir(\n",
    "        img_stem=img_path.stem,\n",
    "        label=label,\n",
    "        caption=caption,\n",
    "        imgs_paths=imgs_paths\n",
    "    )\n",
    "\n",
    "    infos_path = img_dir / \"infos.json\"\n",
    "    infos_path.write_text(img_infos.model_dump_json(indent=4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "62be749a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             image_path       label  \\\n",
      "0      new_ball_683.jpg  Label.BALL   \n",
      "1      new_ball_196.jpg  Label.BALL   \n",
      "2      new_ball_092.jpg  Label.BALL   \n",
      "3      new_ball_708.jpg  Label.BALL   \n",
      "4      new_ball_190.jpg  Label.BALL   \n",
      "...                 ...         ...   \n",
      "1395  base_ball_084.jpg  Label.BALL   \n",
      "1396  base_ball_015.jpg  Label.BALL   \n",
      "1397  base_ball_049.jpg  Label.BALL   \n",
      "1398  base_ball_031.jpg  Label.BALL   \n",
      "1399  base_ball_137.jpg  Label.BALL   \n",
      "\n",
      "                                                caption  \n",
      "0     Two black dogs, their fur fluffed up in agitat...  \n",
      "1     In the sun-drenched backyard, a joyful black a...  \n",
      "2     A young boy, his eyes fixed on the ball in his...  \n",
      "3     A sunny day at the local park, where families ...  \n",
      "4     A young boy stands in front of the bathroom si...  \n",
      "...                                                 ...  \n",
      "1395       A laughing boy lies on a pit of blue balls .  \n",
      "1396  A little boy points to the face of another lit...  \n",
      "1397  A goalie tries to catch a ball during a soccer...  \n",
      "1398           Several children playing in a ball pit .  \n",
      "1399  A horse mascot gives high fives to some footba...  \n",
      "\n",
      "[1400 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "final_dataset_dir = Path(\"../data/final_dataset_noaug2\")\n",
    "\n",
    "rows = []\n",
    "for type_dir in final_dataset_dir.iterdir():\n",
    "    for img_dir in type_dir.iterdir():\n",
    "        json_path = Path(f\"{img_dir}/infos.json\")\n",
    "        with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            data = json.load(f)\n",
    "            imgs_infos = ImageDir(**data)\n",
    "        \n",
    "        for k, v in imgs_infos.imgs_paths.items():\n",
    "            rows.append({\n",
    "                \"image_path\": Path(k).name,\n",
    "                \"label\": imgs_infos.label,\n",
    "                \"caption\": imgs_infos.caption,\n",
    "\n",
    "            })\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "print(df)\n",
    "\n",
    "pd_output_path = Path(f\"{final_dataset_dir}/metadata.csv\")\n",
    "\n",
    "df.to_csv(pd_output_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c30aae6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1400"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_verify = pd.read_csv(\"../data/final_dataset_noaug2/metadata.csv\")\n",
    "len(df_verify)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2a929de0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 375)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_path = Path(\"/home/ubuntu/MiniCLIP/data/final_dataset_noaug/base_water/water_002/new_water_002.jpg\")\n",
    "Image.open(image_path).size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d46ba6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "miniclip",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
