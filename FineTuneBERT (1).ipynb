{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gscFMbZ7bFG-"
      },
      "source": [
        "<h1 style=\"text-align: center;\">TP - Finer tuner BERT sur ces données pour en faire un classifier. </h1>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bg1lXHhqbPvD"
      },
      "source": [
        "\n",
        "L'objectif de ce TP est de fine tuner BERT et de l'étendre pour faire une tâche de classification précise.   \n",
        "\n",
        "Vous connaissz bien le jeu de données que nous allons utiliser :)   \n",
        "Il s'agit des tweets scientifiques. Par contre nous n'allons nous intéresser qu'au premier niveau de classification (\"science_related\") et donc à une classification binaire (le tweet parle de science ou non).   \n",
        "\n",
        "La première partie du TP est plus une partie observation/compréhension de BERT. Ne négligez pas les questions qui vous seront posées elles seront très utiles pour la suite du TP. Passez du temps pour bien comprendre. Les modèles de transformer ne sont pas simples. Il faut que vous compreniez bien les différents composants.\n",
        "\n",
        "\n",
        "\n",
        "**Remarque.** BERT, développé par Google en 2018, est un encodeur de référence et de nouvelles variantes apparaissent régulièrement, comme par exemple [NEOBERT](https://arxiv.org/html/2502.19587v1).  \n",
        "Le code des modèles est disponible sur GitHub ([BERT2018](https://github.com/google-research/bert)) et les poids pré-entraînés ainsi que les tokenizers (par exemple `bert-base-uncased`, `bert-large-uncased`) sont disponibles sur le [Hugging Face Hub](https://huggingface.co/docs/transformers/model_doc/bert).\n",
        "\n",
        "Il existe de nombreuses variantes adaptées à une langue ou à un domaine comme par exemple :\n",
        "- CamemBERT (français, archi RoBERTa), pré-entraîné sur OSCAR. [CamemBERT](XXX)\n",
        "- FlauBERT (français, archi BERT), pré-entraîné sur un large corpus hétérogène. [FlauBERT](XXX)\n",
        "- BioBERT (biomédical), pré-entraîné sur PubMed/PMC. [BioBERT](XXX)\n",
        "\n",
        "Le tableau suivant vous donne un aperçu des ordres de grandeurs du nombre de paramètres de différents modèles :   \n",
        "\n",
        "| Modèle      | Paramètres (≈) | Données de pré-entraînement (principales) |\n",
        "|-------------|----------------:|--------------------------------------------|\n",
        "| BERT-base   | 110 M           | BookCorpus + Wikipedia (EN)                |\n",
        "| BERT-large  | 340 M           | BookCorpus + Wikipedia (EN)                |\n",
        "| DistilBERT  | 66 M            | Distillation à partir de BERT-base         |\n",
        "| CamemBERT   | ~110 M          | OSCAR (FR)                                 |\n",
        "| FlauBERT    | tailles variées | Corpus FR hétérogène (Wikipedia, CCNet/OSCAR, …) |\n",
        "| BioBERT     | ~110 M          | PubMed + PMC (biomédical)                  |\n",
        "\n",
        "Sur Colab, BERT (110 M ou 340 M) est lourd aussi nous utiliserons plutôt DistilBERT qui est beaucoup plus léger.   \n",
        "\n",
        "Pour information, DistilBERT a été obtenu par distillation, c'est à dire  on entraîne un petit modèle \"élève\" pour imiter un grand modèle “professeur”(BERT-base) pendant le pré-entraînement. Résultat, on a moins de paramètres, c'est plus rapide et les performances restent assez proches du modèle source. C'est comme cela qu'aurait d'ailleurs été appris Deepseek [DeepSeek-OpenAI](https://info.haas-avocats.com/droit-digital/openai-vs-deepseek-une-accusation-de-distillation-qui-fait-debat).\n",
        "\n",
        "\n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q3iCDsIidd9E"
      },
      "source": [
        "# A FAIRE EN TOUT PREMIER PREMIER"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "95eg3KW-c452"
      },
      "source": [
        "L'utilisation de BERT avec Google Colab pose des problèmes de versions !!! Les librairies évoluent sans cette et cela pose de vrais problèmes. **Il est impératif au tout début d'exécuter la cellule suivante et de redémarrer le noyau**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WfLOLYAoumd7"
      },
      "source": [
        "# Importation des librairies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "QYLPjVCMuqe_"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-27 09:07:45.156885: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-11-27 09:07:45.175596: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1764234465.202663    4714 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1764234465.210329    4714 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-11-27 09:07:45.236462: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "/home/ubuntu/MiniCLIP/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
        "\n",
        "import pandas as pd\n",
        "import re\n",
        "import numpy as np\n",
        "import random\n",
        "import zipfile\n",
        "import requests\n",
        "import io\n",
        "from pathlib import Path\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import Image, display\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import roc_auc_score, average_precision_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import roc_curve, precision_recall_curve\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "import tensorflow as tf\n",
        "import tf_keras as keras\n",
        "from tf_keras import layers, Model\n",
        "from tf_keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras.models import load_model\n",
        "tf.config.list_physical_devices('GPU')\n",
        "\n",
        "from transformers import DistilBertTokenizerFast\n",
        "from transformers import TFDistilBertModel\n",
        "from transformers import DistilBertConfig\n",
        "from transformers import TFDistilBertForQuestionAnswering\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7C-ua7yT7aC-"
      },
      "source": [
        "# Un petit tour de BERT/DistilBERT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5BYrAgVE7dNV"
      },
      "source": [
        "Avant de commencer à faire du fine tuning, nous allons déjà essayer de mieux comprendre le fonctionnement de BERT.\n",
        "\n",
        "**Attention :**   \n",
        "- ERT/DistilBERT sont des encodeurs entraînés avec comme objectif de prédire des tokens masqués au milieu de la phrase, en regardant à gauche et à droite. Ils ne peuvent donc pas prédire le prochain mot ou compléter une phrase comme le fait un modèle comme GPT qui est lui un décodeur. Si vous avez un doute regardez les différentes architectures des transformers.   \n",
        "- Au-delà du modèle général, il existe des variantes BERT/DistilBERT déjà adaptées à des tâches comme la question-réponse ([SQuAD](https://rajpurkar.github.io/SQuAD-explorer/), [FQuAD](https://fquad.github.io/)), la classification ([Allociné](https://huggingface.co/datasets/allocine), [SST-2](https://huggingface.co/datasets/glue/viewer/sst2/train)), le NER ([CoNLL-2003](https://huggingface.co/datasets/conll2003), modèles FR comme [CamemBERT NER](https://huggingface.co/Jean-Baptiste/camembert-ner)), ou des domaines spécialisés ([BioBERT](https://arxiv.org/abs/1901.08746)). Dans cette section, nous en testerons une en QA pour voir le fonctionnement général.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m5Kja-5o-QyX"
      },
      "source": [
        "## Au départ les tokens"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kBdaPY6O-Xqo"
      },
      "source": [
        "Le point de départ des modèles sont des textes qui sont transformés en tokens. Ici nous utiliserons `DistilBertTokenizerFast` qui a déjà été entraîné et est disponible dans `distilbert-base-uncased`.   \n",
        "L'idée est donc tout simplement de charger le tokenizer appris et après de l'utiliser pour \"tokenizer\" des phrases.\n",
        "Le code suivant permet de tokenizer vos phrases :\n",
        "\n",
        "```python\n",
        "enc = tok(texts, padding=False, truncation=True)\n",
        "```\n",
        "On applique la fonction du tokenizer sur nos textes. `padding=False`  indique qu'on ne rajoute rien pour égaliser les longueurs des séquences (chaque phrase garde sa longueur propre). `truncation=True` indique simplement que si une phrase dépasse la longueur maximale autorisée par le modèle (par défaut la longueur interne du tokenizer), elle sera coupée à cette longueur plutôt que de provoquer une erreur.\n",
        "\n",
        "\n",
        "\n",
        "Essayez quelques exemples de textes pour voir ce que cela donne. L'exemple que vous avez est très simple et le résultat assez attendu, alors testez avec de longs mots, avec de longues phrases, avec des emojis et surtout regardez bien comment les tokens sont créés (leur découpage) et la valeur qu'ils ont. C'est important de bien comprendre cette tokenization qui n'est pas forcément courante.  \n",
        "\n",
        "Question subsidiaire : à votre avis si on veut fine tuner un modèle est ce qu'on est obligé de charger un tokenizer appris ?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "FulXss34-T38"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " Alice sees the white rabbit\n",
            "['[CLS]', 'alice', 'sees', 'the', 'white', 'rabbit', '[SEP]']\n",
            "ids: [101, 5650, 5927, 1996, 2317, 10442, 102]\n",
            "decoded: [CLS] alice sees the white rabbit [SEP]\n"
          ]
        }
      ],
      "source": [
        "tok = DistilBertTokenizerFast.from_pretrained(\"distilbert-base-uncased\")\n",
        "\n",
        "######## ESSAYER PLUSIEURS PHRASES ET BIEN REGARDER LA SORTIE DU MODELE\n",
        "texts = [\n",
        "    \"Alice sees the white rabbit\"\n",
        "]\n",
        "enc = tok(texts, padding=False, truncation=True)\n",
        "for t, ids in zip(texts, enc[\"input_ids\"]):\n",
        "    print(\"\\n\", t)\n",
        "    print(tok.convert_ids_to_tokens(ids))\n",
        "    print(\"ids:\", ids)\n",
        "    print(\"decoded:\", tok.decode(ids))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iCkMWO57Fr3O"
      },
      "source": [
        "Allons un peu plus loin sur cette histoire de padding. Regardez le résultat de l'exécution de la cellule suivante."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "YK1g6tSqFsyV"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sans padding:\n",
            "phrase  0 longueur : 4 decoded [CLS] alice sees [SEP]\n",
            "phrase  1 longueur : 7 decoded [CLS] alice sees the white rabbit [SEP]\n"
          ]
        }
      ],
      "source": [
        "tok = DistilBertTokenizerFast.from_pretrained(\"distilbert-base-uncased\")\n",
        "\n",
        "short = \"Alice sees\"\n",
        "long  = \"Alice sees the white rabbit\"\n",
        "texts = [short, long]\n",
        "enc_var = tok(texts, padding=False, truncation=False)\n",
        "print(\"Sans padding:\")\n",
        "for i, ids in enumerate(enc_var[\"input_ids\"]):\n",
        "    print(\"phrase \", i, \"longueur :\", len(ids), \"decoded\", tok.decode(ids))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g9EF4CFDGWqk"
      },
      "source": [
        "Maintenant on va mettre du padding. On relance le tokenizer sur le texte que l'on stocke dans une variable `enc_auto` qui est un dictionnaire. Affichez le type de  `enc_auto` et ses clés. Regardez bien les print"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "TYHCtR-5GXQe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Le type de enc_auto <class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
            "Les différentes clés \n",
            "\n",
            "Padding=True (longueur = longueur du plus long):\n",
            "input_ids[0]: [101, 5650, 5927, 102, 0, 0, 0]\n",
            "attention_mask[0]: [1, 1, 1, 1, 0, 0, 0]\n",
            "input_ids[1]: [101, 5650, 5927, 1996, 2317, 10442, 102]\n",
            "attention_mask[1]: [1, 1, 1, 1, 1, 1, 1]\n"
          ]
        }
      ],
      "source": [
        "enc_auto = tok(texts, padding=True, truncation=False)\n",
        "\n",
        "# Afficher ici le type de enc_auto et les clés associés\n",
        "\n",
        "# A COMPLETER\n",
        "print (\"Le type de enc_auto\", type(enc_auto))\n",
        "print (\"Les différentes clés \", )\n",
        "\n",
        "print(\"\\nPadding=True (longueur = longueur du plus long):\")\n",
        "print(\"input_ids[0]:\", enc_auto[\"input_ids\"][0])\n",
        "print(\"attention_mask[0]:\", enc_auto[\"attention_mask\"][0])\n",
        "print(\"input_ids[1]:\", enc_auto[\"input_ids\"][1])\n",
        "print(\"attention_mask[1]:\", enc_auto[\"attention_mask\"][1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8c6npRB4H_aF"
      },
      "source": [
        "et voilà vous voyez il y a une clé qui s'appelle `attention_mask` et voilà le padding va en fait remplir les valeurs 1 quand une valeur existe et 0 si elle n'existe pas.   \n",
        "\n",
        "**Attention :** l'exemple est donné pour illustration, en réalité on utilisera une valeur `max_length` pour que toutes les séquences  aient la même longueur bien sûr."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dO_DzDLEDGjA"
      },
      "source": [
        "## On sort les masques"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OYl2_2vADJqV"
      },
      "source": [
        "Maintenant nous allons examiner un peu plus attentivement ce `attention_mask`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ckhZnBB9DKf9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " Alice was sleeping.\n",
            "['[CLS]', 'alice', 'was', 'sleeping', '.', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
            "ids: [101, 5650, 2001, 5777, 1012, 102, 0, 0, 0, 0, 0, 0]\n",
            "decoded: [CLS] alice was sleeping. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
            "\n",
            " Alice sees the white rabbit.\n",
            "['[CLS]', 'alice', 'sees', 'the', 'white', 'rabbit', '.', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
            "ids: [101, 5650, 5927, 1996, 2317, 10442, 1012, 102, 0, 0, 0, 0]\n",
            "decoded: [CLS] alice sees the white rabbit. [SEP] [PAD] [PAD] [PAD] [PAD]\n"
          ]
        }
      ],
      "source": [
        "tok = DistilBertTokenizerFast.from_pretrained(\"distilbert-base-uncased\")\n",
        "\n",
        "texts=[\"Alice was sleeping.\",\n",
        "\"Alice sees the white rabbit.\"]\n",
        "\n",
        "enc = tok(texts, padding=\"max_length\", truncation=True, max_length=12)\n",
        "for t, ids in zip(texts, enc[\"input_ids\"]):\n",
        "    print(\"\\n\", t)\n",
        "    print(tok.convert_ids_to_tokens(ids))\n",
        "    print(\"ids:\", ids)\n",
        "    print(\"decoded:\", tok.decode(ids))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fcjza7HDOg10"
      },
      "source": [
        "Exécutez la cellule suivante. Vous n'avez pas besoin d'essayer de comprende le code. Que constatez vous sur le modèle affiché ?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "phABFXdBM-3T"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFDistilBertModel: ['vocab_transform.weight', 'vocab_projector.bias', 'vocab_transform.bias', 'vocab_projector.weight', 'vocab_layer_norm.bias', 'vocab_layer_norm.weight']\n",
            "- This IS expected if you are initializing TFDistilBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFDistilBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the weights of TFDistilBertModel were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertModel for predictions without further training.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
          ]
        }
      ],
      "source": [
        "backbone = TFDistilBertModel.from_pretrained(\"distilbert-base-uncased\",\n",
        "                                             from_pt=True)\n",
        "\n",
        "MAX_LEN = 12\n",
        "ids  = layers.Input(shape=(MAX_LEN,), dtype=\"int32\", name=\"input_ids\")\n",
        "mask = layers.Input(shape=(MAX_LEN,), dtype=\"int32\", name=\"attention_mask\")\n",
        "\n",
        "h = backbone({\"input_ids\": ids, \"attention_mask\": mask}).last_hidden_state\n",
        "probe = Model(inputs=[ids, mask], outputs=h, name=\"distilbert_probe\")\n",
        "\n",
        "model_dir = \"./figs\"; os.makedirs(model_dir, exist_ok=True)\n",
        "model_path = os.path.join(model_dir, \"distilbert_probe.png\")\n",
        "\n",
        "keras.utils.plot_model(\n",
        "    probe, model_path,\n",
        "    show_shapes=True, show_dtype=True, show_layer_names=True,\n",
        "    expand_nested=True, rankdir=\"BT\", show_layer_activations=True\n",
        ")\n",
        "\n",
        "# display(Image(filename=model_path))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FQW9sb_IOvts"
      },
      "source": [
        "Et oui les modèles BERT/DistillBERT ont deux entrées. `input_ids` correspond à un tableau des identifiant des phrases tokenizées et `association_mask` est un tableau des masques associés.  \n",
        "\n",
        "La cellule suivante illustre comment utiliser le modèle en lui donnant un batch composé de deux entrées. Regardez bien les entrées. Est-ce cohérent ? et regardez aussi la sortie, est-ce que c'est cohérent avec le schéma obtenu ci-dessus."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "E_M9WejeNnrV"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFDistilBertModel: ['vocab_transform.weight', 'vocab_projector.bias', 'vocab_transform.bias', 'vocab_projector.weight', 'vocab_layer_norm.bias', 'vocab_layer_norm.weight']\n",
            "- This IS expected if you are initializing TFDistilBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFDistilBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the weights of TFDistilBertModel were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertModel for predictions without further training.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Les masques input_id et les masques en entrée du modèle \n",
            "\n",
            "input_ids[0] :  [ 101 5650 2001 5777 1012  102    0    0    0    0    0    0] attention_mask[0] : [1 1 1 1 1 1 0 0 0 0 0 0]\n",
            "input_ids[1] :  [  101  5650  5927  1996  2317 10442  1012   102     0     0     0     0] attention_mask[1] : [1 1 1 1 1 1 1 1 0 0 0 0]\n",
            "\n",
            "last_hidden_state shape: (2, 12, 768)\n"
          ]
        }
      ],
      "source": [
        "model = TFDistilBertModel.from_pretrained(\"distilbert-base-uncased\",\n",
        "                                          from_pt=True)\n",
        "\n",
        "# Il est nécessaire de convertir en tenseur pour l'utiliser\n",
        "batch = {\n",
        "    \"input_ids\": tf.convert_to_tensor(enc[\"input_ids\"]),\n",
        "    \"attention_mask\": tf.convert_to_tensor(enc[\"attention_mask\"]),\n",
        "}\n",
        "\n",
        "out = model(batch)\n",
        "\n",
        "print (\"Les masques input_id et les masques en entrée du modèle \\n\")\n",
        "\n",
        "print(\"input_ids[0] : \", batch[\"input_ids\"][0].numpy(),\n",
        "      \"attention_mask[0] :\", batch[\"attention_mask\"][0].numpy())\n",
        "print(\"input_ids[1] : \", batch[\"input_ids\"][1].numpy(),\n",
        "      \"attention_mask[1] :\", batch[\"attention_mask\"][1].numpy())\n",
        "\n",
        "print(\"\\nlast_hidden_state shape:\", out.last_hidden_state.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SHsXo9E7SuuA"
      },
      "source": [
        "Normalement vous devriez voir : `last_hidden_state shape: (2, 12, 768)`. Quelques explications : si on regarde la sortie du modèle DistillBERT (voir schéma du modèle) on constate qu'effectivement c'est cohérent avec la sortie. En fait le `2`correspond au nombre d'entrées dans le batch (ici nous avons deux phrases). Le `12` correspond à `max_length` et le `768` correspond au `hidden_size` c'est à dire la dimension des vecteurs internes de DistilBERT (768 pour distilbert-base-*).  \n",
        "\n",
        "En fait l'intuition derrière est que pour chaque phrase du batch et pour chaque position (jusqu'à 12 tokens), le modèle renvoie un vecteur de 768.  \n",
        "\n",
        "Pour vous faire une idée, essayons de regarder à quoi correspond le vecteur pour le token correspondant à Alice. Attention, il a été tokénizé donc il est en minuscule, on doit donc chercher 'alice' et regarder à quel numéro de token il correspond."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "uOKho1M-UFdv"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Les numéros de tokens de la première phrase\n",
            "[ 101 5650 2001 5777 1012  102    0    0    0    0    0    0]\n",
            "La correspondance id - token\n",
            "['[CLS]', 'alice', 'was', 'sleeping', '.', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
            "Index 'alice' (phrase 0): 1  - vec shape: (768,)\n"
          ]
        }
      ],
      "source": [
        "print (\"Les numéros de tokens de la première phrase\")\n",
        "print (batch[\"input_ids\"][0].numpy())\n",
        "\n",
        "print (\"La correspondance id - token\")\n",
        "tokens0 = tok.convert_ids_to_tokens(batch[\"input_ids\"][0].numpy())  # phrase 0\n",
        "print(tokens0)\n",
        "\n",
        "# on cherche 'alice' (il a été converti en minuscule)\n",
        "idx = tokens0.index('alice')\n",
        "vec_alice = out.last_hidden_state[0, idx, :].numpy()\n",
        "print(\"Index 'alice' (phrase 0):\", idx, \" - vec shape:\", vec_alice.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "__BMFpnaWrqE"
      },
      "source": [
        "et maintenant si on veut voir à quoi correspond le vecteur associé à 'alice' :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0UW-G142Vy2s"
      },
      "outputs": [],
      "source": [
        "print (vec_alice)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gxnt3GqlYLFz"
      },
      "source": [
        "## Et les embeddings ?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UqTm4euWYOlv"
      },
      "source": [
        "Il y a deux 'alice' dans deux phrases différentes. Comparons un peu les débuts des vecteurs de sortie pour la phrase 1 et la phrase 2."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "x8JHNOM2Y6ml"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Les numéros de tokens de la première phrase\n",
            "[ 101 5650 2001 5777 1012  102    0    0    0    0    0    0]\n",
            "La correspondance id - token (phrase 1)\n",
            "['[CLS]', 'alice', 'was', 'sleeping', '.', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
            "Index 'alice' (phrase 1):  1  - vec shape : (768,)\n",
            "\n",
            "Les numéros de tokens de la deuxième phrase\n",
            "[  101  5650  5927  1996  2317 10442  1012   102     0     0     0     0]\n",
            "La correspondance id - token (phrase 2)\n",
            "['[CLS]', 'alice', 'sees', 'the', 'white', 'rabbit', '.', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
            "Index 'alice' (phrase 2): 1  - vec shape : (768,)\n"
          ]
        }
      ],
      "source": [
        "print(\"Les numéros de tokens de la première phrase\")\n",
        "print(batch[\"input_ids\"][0].numpy())\n",
        "\n",
        "print(\"La correspondance id - token (phrase 1)\")\n",
        "tokens0 = tok.convert_ids_to_tokens(batch[\"input_ids\"][0].numpy())\n",
        "print(tokens0)\n",
        "\n",
        "# on cherche 'alice' (minuscule car modèle uncased)\n",
        "idx0 = tokens0.index('alice')\n",
        "vec_alice_p1 = out.last_hidden_state[0, idx0, :].numpy()\n",
        "print(\"Index 'alice' (phrase 1): \",idx0, \" - vec shape :\",vec_alice_p1.shape)\n",
        "\n",
        "print(\"\\nLes numéros de tokens de la deuxième phrase\")\n",
        "print(batch[\"input_ids\"][1].numpy())\n",
        "\n",
        "print(\"La correspondance id - token (phrase 2)\")\n",
        "tokens1 = tok.convert_ids_to_tokens(batch[\"input_ids\"][1].numpy())\n",
        "print(tokens1)\n",
        "\n",
        "idx1 = tokens1.index('alice')\n",
        "vec_alice_p2 = out.last_hidden_state[1, idx1, :].numpy()\n",
        "print(\"Index 'alice' (phrase 2):\",idx1, \" - vec shape :\",vec_alice_p2.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LhI9gZqLZYdq"
      },
      "source": [
        "Nous avons déjà vu qu'une bonne manière de comparer des vecteurs est la similarité cosinus :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "bZxzZYhvZh8X"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Similarité cosinus entre 'Alice' (phrase 1 vs 2): 0.904\n"
          ]
        }
      ],
      "source": [
        "cos = float(np.dot(vec_alice_p1, vec_alice_p2) /\n",
        "            (np.linalg.norm(vec_alice_p1) * np.linalg.norm(vec_alice_p2) + 1e-9))\n",
        "print(f\"\\nSimilarité cosinus entre 'Alice' (phrase 1 vs 2): {cos:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4F_VepvGb3_Q"
      },
      "source": [
        "Surpris du résultat ? Est-ce qu'on est sûr qu'on parle de la même 'alice' ? déjà on peut véfifier qu'on a le même identifiant."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "gjrsk_tHhr1m"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Id du token 'alice' (phrase 1) : 5650\n",
            "Id du token 'alice' (phrase 2) : 5650\n",
            "Est-ce le même id ?  True\n",
            "Token pour id_p1 : alice\n",
            "Token pour id_p2 : alice\n"
          ]
        }
      ],
      "source": [
        "# Vérifier que c’est le même id de token pour 'alice' dans les deux phrases\n",
        "id_p1 = int(batch[\"input_ids\"][0, idx0].numpy())\n",
        "id_p2 = int(batch[\"input_ids\"][1, idx1].numpy())\n",
        "print(\"\\nId du token 'alice' (phrase 1) :\", id_p1)\n",
        "print(\"Id du token 'alice' (phrase 2) :\", id_p2)\n",
        "print(\"Est-ce le même id ? \", id_p1 == id_p2)\n",
        "\n",
        "print(\"Token pour id_p1 :\", tok.convert_ids_to_tokens([id_p1])[0])\n",
        "print(\"Token pour id_p2 :\", tok.convert_ids_to_tokens([id_p2])[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ohe1U70wcTDG"
      },
      "source": [
        "Donc oui on parle de la même alice. Le numéro du token est le même.   \n",
        "\n",
        "Examinons ça un peu plus en détail ... Juste après la couche d'entrée dans les transformers il y a une couche d'embeddings. Regardons un peu ce qu'elle contient ?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "HbPzCglzeP9n"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tokens phrase 1: ['[CLS]', 'alice', 'was', 'sleeping', '.', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
            "tokens phrase 2: ['[CLS]', 'alice', 'sees', 'the', 'white', 'rabbit', '.', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
            "idx0 - token alice dans la phrase 1  1 , idx1 - token alice dans phrase 2 : 1\n",
            "token_id d'alice dans la phrase1: 5650  -  token_id d'alice dans la phrase2: 5650\n",
            "vec_emb_alice_p1 shape: (768,)\n",
            "vec_emb_alice_p2 shape: (768,)\n"
          ]
        }
      ],
      "source": [
        "print(\"tokens phrase 1:\", tok.convert_ids_to_tokens(batch[\"input_ids\"][0].numpy()))\n",
        "print(\"tokens phrase 2:\", tok.convert_ids_to_tokens(batch[\"input_ids\"][1].numpy()))\n",
        "\n",
        "idx0 = tokens0.index('alice')\n",
        "idx1 = tokens1.index('alice')\n",
        "\n",
        "print(\"idx0 - token alice dans la phrase 1 \",\n",
        "      idx0,\", idx1 - token alice dans phrase 2 :\", idx1)\n",
        "id_p1 = int(batch[\"input_ids\"][0, idx0].numpy())\n",
        "id_p2 = int(batch[\"input_ids\"][1, idx1].numpy())\n",
        "print(\"token_id d'alice dans la phrase1:\",\n",
        "      id_p1, \" -  token_id d'alice dans la phrase2:\", id_p2)\n",
        "\n",
        "# Récupération de la matrice d'embedding de mot (statique)\n",
        "we = model.get_input_embeddings()\n",
        "emb_batch = we(batch[\"input_ids\"])\n",
        "vec_emb_alice_p1 = emb_batch[0, idx0, :].numpy()\n",
        "vec_emb_alice_p2 = emb_batch[1, idx1, :].numpy()\n",
        "\n",
        "print(\"vec_emb_alice_p1 shape:\", vec_emb_alice_p1.shape)\n",
        "print(\"vec_emb_alice_p2 shape:\", vec_emb_alice_p2.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qP6JZUCWc81D"
      },
      "source": [
        "et si on compare avec un cosinus on obtient :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "Z750FYJWc7T-"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Similarité cosinus entre 'Alice' (phrase 1 vs 2) en entrée du modèle : 1.000\n"
          ]
        }
      ],
      "source": [
        "cos = float(np.dot(vec_emb_alice_p1, vec_emb_alice_p2) /\n",
        "            (np.linalg.norm(vec_emb_alice_p1) * np.linalg.norm(vec_emb_alice_p2) + 1e-9))\n",
        "print(f\"\\nSimilarité cosinus entre 'Alice' (phrase 1 vs 2) en entrée du modèle : {cos:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vNlXc_2viw2P"
      },
      "source": [
        "En entrée pour les embeddings on a une similarité cosinus = 1. C'est le même vecteur. En sortie on a une similarité cosinus différente de 1. Ce sont donc deux vecteurs différents. Si vous avez compris pourquoi vous avez compris le rôle des transformeurs :) si vous n'avez pas compris relisez vos cours et les guides qui vous ont été donnés !!!     \n",
        "\n",
        "C'est tout ça la puissance d'un transformer c'est de pouvoir tenir compte du contexte : alice dans 'Alice was sleeping.' n'aura pas exactement la même représentation que alice dans 'Alice sees the white rabbit\". Les embeddings en entrée correspondent au vocabulaire de base, ils sont justement transformés en passant par les couches d'atttention avec de prendre en compte le contexte."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VIaKZ3bZRHqK"
      },
      "source": [
        "Pour finir de vous en convaincre, exécutez la cellule suivante qui effectue une ACP sur les embeddings. Comparez les différents plots pour voir la différence."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "C1d4OkU-ROs4"
      },
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABLsAAAH/CAYAAAC/998mAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjcsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvTLEjVAAAAAlwSFlzAAAPYQAAD2EBqD+naQAAf5dJREFUeJzs3XlclWX+//H3YREJBUG0JFBcMkTkHBL3LFc0TcY0t/qSW4uDjWPphNZUOtaYZdrUVNpY5i+11FwycyWzcilXkkLNBRTUcgOOIqLA/fvD8YzErhyW4+v5eJzH8dz3dd33575v0I+fc93XbTIMwxAAAAAAAADgAJwqOgAAAAAAAACgrFDsAgAAAAAAgMOg2AUAAAAAAACHQbELAAAAAAAADoNiFwAAAAAAABwGxS4AAAAAAAA4DIpdAAAAAAAAcBgUuwAAAAAAAOAwKHYBAAAAAADAYVDsAspBYGCgHnzwQbvvJykpSSaTSR9//HGxbYcNG6bAwMA8y0wmkyZNmmSX2Kq6SZMmyWQyVXQYZaZXr1564oknKjqMPNauXasaNWro9OnTFR0KAOAWQH6Gyqasr/Xrr7+uoKAg5ebmltk2b9bZs2fl4eGh1atXV3QocHAUu3DL+vjjj2UymQp9/fDDDxUdIkpp4cKFeuutt264/8WLFzVp0iRt2rSpzGKqjLZs2aL169crJibGtmzTpk15fv5dXV3VqFEjPfbYYzpy5Ei+bVitVk2ePFlms1k1atSQu7u7QkJCFBMToxMnThS434EDB8pkMuXZ7/V69uypJk2aaOrUqWVzoACAKof8DCVxszlfSSUkJGjSpElKSkqy+77KmtVq1bRp0xQTEyMnp//9t//63ycnJyf5+fkpIiKiwPw3JydHc+fOVadOneTj4yM3NzcFBgZq+PDh2rlzZ4H7fe+992QymdSmTZsC19euXVuPP/64XnzxxTI5TqAwLhUdAFDR/vGPf6hhw4b5ljdp0qQCoqlYmZmZcnGpun8tLFy4UD///LPGjh17Q/0vXryoyZMnS5I6deqUZ93f//53TZgw4SYjrBzeeOMNde3atcCf8TFjxqhVq1a6cuWKdu/erQ8++EBfffWV4uPj5efnJ0k6cuSIunXrpmPHjmnAgAF68sknVa1aNe3du1cffvihli9frl9//TXPdq1Wq7788ksFBgbq008/1WuvvVbgSLmnnnpK48eP1+TJk1WzZk37nAAAQKVHfvY/VT0/s4ebzflKKiEhQZMnT1anTp3yjbir7D766CNlZ2dryJAh+dZ1795djz32mAzDUGJiot577z116dJFX331lR544AFJV3/u+vXrp7Vr1+q+++7T888/Lx8fHyUlJWnx4sWaN2+ejh07Jn9//zzbXrBggQIDA7V9+3YdOnSowN/ZUaNG6e2339bGjRvVpUsX+5wA3PL4WxO3vAceeEDh4eEVHUalUL169YoOodJycXFxiETz1KlT+uqrrzRr1qwC13fs2FEPP/ywJGn48OFq2rSpxowZo3nz5mnixInKzs5Wv3799Pvvv2vTpk2699578/R/9dVXNW3atHzbXbp0qXJycvTRRx+pS5cu+u6773T//ffna9e/f3/95S9/0ZIlSzRixIgyOGIAQFVEfvY/5Ge4EXPnzlVkZGSBPz9NmzbV//3f/9k+P/TQQwoNDdVbb71lK3b97W9/09q1azVz5sx8RcWXX35ZM2fOzLfdxMREbd26VcuWLdNTTz2lBQsW6OWXX87XrlmzZgoJCdHHH39MsQt2w22MQDGuzbMwffp0vfvuu2rUqJFuu+02RUREKDk5WYZhaMqUKfL395e7u7v+9Kc/6dy5cwVua/369bJYLKpevbqCg4O1bNmyfG3S0tI0duxYBQQEyM3NTU2aNNG0adPy3WuflpamYcOGycvLS7Vq1dLQoUOVlpZW4H5XrFihkJAQVa9eXSEhIVq+fHmB7f44T8C1eaoOHTqkYcOGqVatWvLy8tLw4cN18eLFPH0zMzM1ZswY+fr6qmbNmoqMjNTx48fzbfP8+fMaO3asAgMD5ebmprp166p79+7avXt3gTGVtF+nTp301Vdf6ejRo7ah2de+gbt8+bJeeukltWzZUl5eXvLw8FDHjh31zTff2LaflJSkOnXqSJImT55s28a12AuasysrK0vPPPOM6tSpYzvmlJSUfMdc0PwbhW1TkubPn6+WLVvK3d1dPj4+Gjx4sJKTk/O0OXjwoPr376877rhD1atXl7+/vwYPHqz09PQiz+NXX32l7OxsdevWrch211xLQBITEyVdLVr99NNPeuGFF/IVuiTJ09NTr776ar7lCxYsUPfu3dW5c2c1a9ZMCxYsKHB/devWVWhoqL744osSxQcAuDWRn1WO/EySjh8/rpEjR8rPz09ubm5q2LCh/vznP+vy5cu2NkeOHNGAAQPk4+Oj2267TW3bttVXX32VZzvXplRYvHixXn31Vfn7+6t69erq2rWrDh06ZGtXVM4nXc3PXn75ZTVp0kRubm4KCAjQc889p6ysLFuboUOHqnr16tq3b1+eGHr06CFvb2+dOHFCH3/8sQYMGCBJ6ty5s21f1273K2x+rcDAQA0bNizPspL+/PzRjV6XxMRE7d27t8T5XosWLeTr62vL91JSUjR79mx17969wNFzzs7OGj9+fIGjury9vdW7d289/PDDheZ70tXRZV9++aUMwyhRjEBpVf1hCsBNSk9P15kzZ/IsM5lMql27dp5lCxYs0OXLl/WXv/xF586d0+uvv66BAweqS5cu2rRpk2JiYnTo0CG98847Gj9+vD766KM8/Q8ePKhBgwZp1KhRGjp0qObOnasBAwZo7dq16t69u6Srt9Hdf//9On78uJ566inVr19fW7du1cSJE3Xy5Enb3ASGYehPf/qTNm/erFGjRqlZs2Zavny5hg4dmu/41q9fr/79+ys4OFhTp07V2bNnNXz48Hz/OBVl4MCBatiwoaZOnardu3drzpw5qlu3bp4RPMOGDdPixYsVFRWltm3b6ttvv1Xv3r3zbWvUqFH6/PPP9fTTTys4OFhnz57V5s2btW/fPt1zzz2FxlBcvxdeeEHp6elKSUmxfdNUo0YNSVdvoZszZ46GDBmiJ554QufPn9eHH36oHj16aPv27bJYLKpTp47ef/99/fnPf9ZDDz2kfv36SZJCQ0MLjenxxx/X/Pnz9cgjj6h9+/bauHFjgcdcGq+++qpefPFFDRw4UI8//rhOnz6td955R/fdd5/27NmjWrVq6fLly+rRo4eysrL0l7/8RXfccYeOHz+uVatWKS0tTV5eXoVuf+vWrapdu7YaNGhQongOHz4sSbbfh5UrV0qSoqKiSnxMJ06c0DfffKN58+ZJkoYMGaKZM2fq3//+t6pVq5avfcuWLbVixYoSbx8A4HjIz4pXGfKzEydOqHXr1kpLS9OTTz6poKAgHT9+XJ9//rkuXryoatWq6ffff1f79u118eJFjRkzRrVr19a8efMUGRmpzz//XA899FCebb722mtycnLS+PHjlZ6ertdff12PPvqofvzxR0kqMufLzc1VZGSkNm/erCeffFLNmjVTfHy8Zs6cqV9//dWWX/zrX//Sxo0bNXToUG3btk3Ozs6aPXu21q9fr08++UR+fn667777NGbMGL399tt6/vnn1axZM0myvZdUSX9+CnKj12Xr1q2SVGSb66Wmpio1NdV2y+GaNWuUnZ1dqnxPuvr72K9fP1WrVk1DhgzR+++/rx07dqhVq1b52rZs2VIzZ87UL7/8opCQkFLtBygRA7hFzZ0715BU4MvNzc3WLjEx0ZBk1KlTx0hLS7MtnzhxoiHJMJvNxpUrV2zLhwwZYlSrVs24dOmSbVmDBg0MScbSpUtty9LT04169eoZYWFhtmVTpkwxPDw8jF9//TVPrBMmTDCcnZ2NY8eOGYZhGCtWrDAkGa+//rqtTXZ2ttGxY0dDkjF37lzbcovFYtSrVy9P7OvXrzckGQ0aNMizH0nGyy+/bPv88ssvG5KMESNG5Gn30EMPGbVr17Z93rVrlyHJGDt2bJ52w4YNy7dNLy8vY/To0UZplaRf79698x2TYVw9N1lZWXmWpaamGrfffnueYzt9+nS+eK+5di6uiYuLMyQZ0dHRedo98sgj+bYxdOjQAuP64zaTkpIMZ2dn49VXX83TLj4+3nBxcbEt37NnjyHJWLJkSb5tFufee+81WrZsmW/5N998Y0gyPvroI+P06dPGiRMnjK+++soIDAw0TCaTsWPHDsMwDCMsLMzw8vIq1T6nT59uuLu7G1ar1TAMw/j1118NScby5csLbP/Pf/7TkGT8/vvvpdoPAKDqIz+rWvnZY489Zjg5OdnyhOvl5uYahmEYY8eONSQZ33//vW3d+fPnjYYNGxqBgYFGTk6OYRj/y0WaNWuWJ2/717/+ZUgy4uPjbcsKy/k++eQTw8nJKc++DMMwZs2aZUgytmzZYlu2bt06Q5LxyiuvGEeOHDFq1Khh9O3bN0+/JUuWGJKMb775Jt++CssZGzRoYAwdOtT2uaQ/PwVt80avy9///ndDknH+/PkC4x45cqRx+vRp49SpU8aPP/5odO3a1ZBkvPnmm4ZhGMYzzzxjSDL27NlT4n3u3LnTkGRs2LDBMIyr19/f39/461//WmD7rVu3GpKMRYsWlfr4gJLgNkbc8t59911t2LAhz2vNmjX52g0YMCDPiJlrTxj5v//7vzxzObVp00aXL1/W8ePH8/T38/PL882Vp6enHnvsMe3Zs0e//fabJGnJkiXq2LGjvL29debMGdurW7duysnJ0XfffSdJWr16tVxcXPTnP//Ztj1nZ2f95S9/ybPPkydPKi4uTkOHDs0Te/fu3RUcHFziczRq1Kg8nzt27KizZ8/KarVKktauXStJio6OztPuj/FIUq1atfTjjz8W+sS+wtxoP+nqubk2gig3N1fnzp1Tdna2wsPDSzQ8vyDXHpc8ZsyYPMtvZqLUZcuWKTc3VwMHDsxz/e+44w7dddddttsur13LdevW5btdoThnz56Vt7d3oetHjBihOnXqyM/PT71791ZGRobmzZtnmzfFarWWeuL4BQsWqHfv3rZ+d911l1q2bFno0PZr8f3xG30AwK2D/Kx4FZ2f5ebmasWKFerTp0+B86tdm6ph9erVat26dZ7pD2rUqKEnn3xSSUlJSkhIyNNv+PDheUZ+d+zYUZIKfDr0Hy1ZskTNmjVTUFBQnmt1bVqG66ewiIiI0FNPPaV//OMf6tevn6pXr67Zs2eX+PhLqqQ/PwW50fz37NmzcnFxsY14+6MPP/xQderUUd26ddWmTRtt2bJFzz77rC2PvfYzVJqcb8GCBbr99tvVuXNnSVev/6BBg/TZZ58pJycnX3vyPdgbtzHilte6desSTYBav379PJ+vJScBAQEFLk9NTc2zvEmTJvnmZ2ratKmkq/NO3HHHHTp48KD27t1rmzvqj06dOiVJOnr0qOrVq5fvH7C77747z+ejR49Kulpc+KO77767xIWePx77tX+cUlNT5enpqaNHj8rJySnfU5MKevrK66+/rqFDhyogIEAtW7ZUr1699Nhjj6lRo0ZFxnCj/a6ZN2+e3nzzTe3fv19XrlyxLS/oSU8lce2YGzdunGf5H69BaRw8eFCGYRR4vSTJ1dVV0tWYn332Wc2YMUMLFixQx44dFRkZqf/7v/8r8hbGa4wi5kZ46aWX1LFjRzk7O8vX11fNmjXL858FT0/PEiWb1+zbt0979uzRY489lm++jXfffVdWq1Wenp4FxlfQfGYAgFsD+VnxKjo/O336tKxWa7G3oB09etRWhLzetdsBjx49mmcbRR1XcQ4ePKh9+/YVe62umT59ur744gvFxcVp4cKFqlu3brH7KK2S/vwU5Gbz38L86U9/0tNPPy2TyaSaNWuqefPm8vDwsK2/lpudP3++RNvLycnRZ599ps6dO9vm/ZKuFpnffPNNff3114qIiMjTh3wP9kaxCyghZ2fnUi0vqqBQmNzcXHXv3l3PPfdcgeuvJV/lrSyPceDAgerYsaOWL1+u9evX64033tC0adO0bNky29NfyrKfdHXC92HDhqlv377629/+prp168rZ2VlTp061zUllT4X9I/7Hb7lyc3NlMpm0Zs2aAs/59cnzm2++qWHDhumLL77Q+vXrNWbMGE2dOlU//PBDkfN91K5du8hksUWLFkVOZhoUFKQ9e/YoOTk5338kCjJ//nxJ0jPPPKNnnnkm3/qlS5dq+PDheZZdi8/X17fY7QMAbm3kZ/mVZ35mDzdzXLm5uWrRooVmzJhR4Po/5i579uyxFZvi4+M1ZMiQUkabX0H53Y3+/Nzodaldu7ays7N1/vz5Akdn+fv7F5vvSVfPicViKbTdNRs3btTJkyf12Wef6bPPPsu3fsGCBfmKXeR7sDeKXeVg1apVGj9+vHJyctSiRQt9/PHH+UYywPEdOnRIhmHkKXz8+uuvkmR7gkzjxo114cKFYp+c0qBBA3399de6cOFCngLIgQMH8rWTrn6j9Ed/bHszGjRooNzcXCUmJub5lvL6kTzXq1evnqKjoxUdHa1Tp07pnnvu0auvvlpsMlVcv8KKSp9//rkaNWqkZcuW5Wnzx0chl+abpWvHfPjw4Tzf2BZ0Xr29vQt8EtO1b3avady4sQzDUMOGDUuUOLdo0UItWrTQ3//+d23dulUdOnTQrFmz9MorrxTaJygoSEuXLi1224Xp06ePPv30U82fP18TJ04ssq1hGFq4cKE6d+6c7xYKSZoyZYoWLFiQr9iVmJgoX1/fQr8BBQCgrJCf/U9p87M6derI09NTP//8c7FxFHRc+/fvt60vrcJytsaNG+unn35S165di83rMjIyNHz4cAUHB6t9+/Z6/fXX9dBDD+WZTL2obRSU312+fFknT57MF1NJfn4KcyN587ViVWJiYpEPWyrMAw88IGdnZ82fP79Ek9QvWLBAdevW1bvvvptv3bJly7R8+XLNmjVL7u7utuXXRoCVdsJ/oKSYs8vOLly4oJEjR2rFihU6ePCg/Pz8NGXKlIoOCxXgxIkTeR4pbbVa9f/+3/+TxWLRHXfcIenqtzfbtm3TunXr8vVPS0tTdna2JKlXr17Kzs7W+++/b1ufk5Ojd955J0+fevXqyWKxaN68eUpPT7ct37BhQ775EW5Gjx49JEnvvfdenuV/jCcnJydPHJJUt25d+fn55Xkc9B+VtJ+Hh0e+dtL/viG8/hvBH3/8Udu2bcvT7rbbbpOkQh8Rfr1rCcbbb7+dZ3lBT9Rp3Lix0tPTtXfvXtuykydP5nvEeL9+/eTs7KzJkyfn+/bSMAydPXtW0tWfnWs/C9e0aNFCTk5ORZ5HSWrXrp1SU1NLdSvi9R5++GG1aNFCr776ar7zJ10d7v7CCy9IkrZs2aKkpCQNHz5cDz/8cL7XoEGD9M033+Sbh2LXrl1q167dDcUHAEBpkJ/deH7m5OSkvn376ssvv9TOnTvzrb+Wy/Tq1Uvbt2/PkzdkZGTogw8+UGBgYKnmKbumsJxv4MCBOn78uP7zn//kW5eZmamMjAzb55iYGB07dkzz5s3TjBkzFBgYqKFDh+bLLaWCc8PGjRvnm2/rgw8+yDeyq6Q/P390o9dFki2PKui6lERAQICeeOIJrV+/Pt/Pi3R1tNqbb76plJQUZWZmatmyZXrwwQcLzPeefvppnT9/3vZE72t27dolLy8vNW/e/IZiBIrDyK4ylJmZqWHDhik+Pl6urq66/fbb9cQTTygsLMxWXY+OjlZERITeeOONCo4W16xZs8b2zdL12rdvf9P3w1+vadOmGjlypHbs2KHbb79dH330kX7//XfNnTvX1uZvf/ubVq5cqQcffFDDhg1Ty5YtlZGRofj4eH3++edKSkqSr6+v+vTpow4dOmjChAlKSkpScHCwli1bVuA/+lOnTlXv3r117733asSIETp37pzeeecdNW/eXBcuXCiTY2vZsqX69++vt956S2fPnrU92vraN6PXvhU7f/68/P399fDDD8tsNqtGjRqKjY3Vjh079Oabbxa6/ZL2a9mypRYtWqRnn31WrVq1Uo0aNdSnTx89+OCDWrZsmR566CH17t1biYmJmjVrloKDg/OcA3d3dwUHB2vRokVq2rSpfHx8FBISUuBcFBaLRUOGDNF7772n9PR0tW/fXl9//XWB35YOHjxYMTExeuihhzRmzBhdvHhR77//vpo2bZpnXo7GjRvrlVde0cSJE5WUlKS+ffuqZs2aSkxM1PLly/Xkk09q/Pjx2rhxo55++mkNGDBATZs2VXZ2tj755BM5Ozurf//+RV6r3r17y8XFRbGxsXryySeLbFsQV1dXLVu2TN26ddN9992ngQMHqkOHDnJ1ddUvv/yihQsXytvbW6+++qoWLFggZ2fnAh9xLkmRkZF64YUX9Nlnn+nZZ5+VdHXeir1792r06NGljg0A4DjIz26evfMzSfrnP/+p9evX6/7779eTTz6pZs2a6eTJk1qyZIk2b96sWrVqacKECfr000/1wAMPaMyYMfLx8dG8efOUmJiopUuXysmp9OMvCsv5oqKitHjxYo0aNUrffPONOnTooJycHO3fv1+LFy/WunXrFB4ero0bN+q9997Tyy+/rHvuuUeSNHfuXHXq1EkvvviiXn/9dUlX8z1nZ2dNmzZN6enpcnNzU5cuXVS3bl09/vjjGjVqlPr376/u3bvrp59+0rp16/LdllfSn58/upnr0qhRI4WEhCg2NlYjRowo9fmVrk6ZcfjwYY0ZM8ZWzPL29taxY8e0ZMkS7d+/X4MHD9bKlSt1/vx5RUZGFridtm3bqk6dOlqwYIEGDRpkW75hwwb16dOHObtgP+X+/EcHtmzZMiMiIsL2+ezZs8b06dONJ5980rYsIyPDcHJysj0K2Ww2G8ePHy/3WFH0o6113eOhrz3a+o033sjT/9rjkZcsWVLgdq9/BHODBg2M3r17G+vWrTNCQ0MNNzc3IygoKF9fw7j6KOaJEycaTZo0MapVq2b4+voa7du3N6ZPn25cvnzZ1u7s2bNGVFSU4enpaXh5eRlRUVHGnj178j3a2jAMY+nSpUazZs0MNzc3Izg42Fi2bJkxdOjQEj/a+vTp0wUeY2Jiom1ZRkaGMXr0aMPHx8f26OYDBw4YkozXXnvNMAzDyMrKMv72t78ZZrPZqFmzpuHh4WGYzWbjvffeK/AaXVPSfhcuXDAeeeQRo1atWnke3Z2bm2v885//NBo0aGC4ubkZYWFhxqpVqwo8B1u3bjVatmxpVKtWLc/5uHYurpeZmWmMGTPGqF27tuHh4WH06dPHSE5OLvBR1OvXrzdCQkKMatWqGXfffbcxf/78ArdpGFev17333mt4eHgYHh4eRlBQkDF69GjjwIEDhmEYxpEjR4wRI0YYjRs3NqpXr274+PgYnTt3NmJjY4s8j9dERkYaXbt2zbOssJ/nwqSmphovvfSS0aJFC+O2224zqlevboSEhBgTJ040Tp48aVy+fNmoXbu20bFjxyK307BhwzyPd3///feN2267zbBarSWKAwDgWMjPqk5+ds3Ro0eNxx57zKhTp47h5uZmNGrUyBg9erSRlZVla3P48GHj4YcfNmrVqmVUr17daN26tbFq1ao82yns2l271tefv8JyPsMwjMuXLxvTpk0zmjdvbri5uRne3t5Gy5YtjcmTJxvp6emG1Wo1GjRoYNxzzz22/5Nd88wzzxhOTk7Gtm3bbMv+85//GI0aNTKcnZ0NScY333xjGIZh5OTkGDExMYavr69x2223GT169DAOHTpkNGjQwBg6dGie7Zb05+f6a32z12XGjBlGjRo1jIsXL+ZZLskYPXp0ibaRnZ1tzJkzx+jYsaPh5eVluLq6Gg0aNDCGDx9u7NmzxzAMw+jTp49RvXp1IyMjo9DtDBs2zHB1dTXOnDljGIZh7Nu3z5BU4twVuBEmw7iBGQxRoCNHjqhTp0568MEHdf/996tXr1764IMP9Ouvv9oeY3vx4kXVrFlTWVlZeZ5wBjiiuLg4hYWFaf78+Xr00UcrOpxyYzKZ9PLLL2vSpEkVHUqBvv/+e3Xq1En79+8v9MmPFSUsLEydOnXSzJkzKzoUAAAc0q2an91q0tPT1ahRI73++usaOXJkRYeTx9ixY/Xdd99p165djOyC3TBnVxlq1KiREhIS1LNnT23ZskUhISGqX79+nkmok5KSVK9ePQpdcDiZmZn5lr311ltycnLSfffdVwERoTAdO3ZURESEbYh+ZbF27VodPHiw2InvAQBAyZCf3bq8vLz03HPP6Y033lBubm5Fh2Nz9uxZzZkzR6+88gqFLtgVI7vKUEpKiry9veXh4aHLly+rSZMm+vLLL9W9e3d99913CgoK0tNPP63q1atr+vTpFR0uUKYmT56sXbt2qXPnznJxcdGaNWu0Zs0aPfnkk7aRjbeKyj6yCwAA3BrIzwDcqhheVIbi4+M1ceJEGYah7OxsRUVFyWw2a86cOerbt6+ys7MVEhKiefPm2fpYLBatXr1afn5+WrlypVauXKk5c+ZU4FEAN6Z9+/basGGDpkyZogsXLqh+/fqaNGmS7cl8AAAAKF/kZwBuVYzsAgAAAAAAgMOw25xdOTk5evHFF9WwYUO5u7urcePGmjJliqitAQAAVG7kcQAAoCqz222M06ZN0/vvv6958+apefPm2rlzp4YPHy4vLy+NGTPGXrsFAADATSKPAwAAVZndbmN88MEHdfvtt+vDDz+0Levfv7/c3d01f/78Em0jNzdXJ06cUM2aNXlSAwAAKBOGYej8+fPy8/OTkxMPpi7IzeZx5HAAAMAeSprH2W1kV/v27fXBBx/o119/VdOmTfXTTz9p8+bNmjFjRqF9srKylJWVZft8/PhxBQcH2ytEAABwC0tOTpa/v39Fh1EplTaPI4cDAADlqbg8zm7FrgkTJshqtSooKEjOzs7KycnRq6++qkcffbTQPlOnTtXkyZPzLU9OTpanp6e9Qi2RmRt+1cdbk5STm38gnLOTScPaB+qZ7k0rIDIAAFAaVqtVAQEBqlmzZkWHUmmVNo+rzDkcAABwHCXN4+x2G+Nnn32mv/3tb3rjjTfUvHlzxcXFaezYsZoxY4aGDh1aYJ8/fit47SDS09MrPFFKPJOhrm9uUgG1LjmZpI3jOinQ16P8AwMAAKVitVrl5eVVKfKLyqq0eVxlzuEAAIDjKGkeZ7diV0BAgCZMmKDRo0fblr3yyiuaP3++9u/fX6JtVLZkdMnOZMUs3SuTySTDMGzv0/qHakB4QEWHBwAASqCy5ReV0c3mcZxjAABgDyXNMex2G+PFixfzTRbm7Oys3Nxce+3S7gaEB6hVoI8W7UxWSmqm/L3dNSg8gBFdAADAoThiHgcAAG4ddit29enTR6+++qrq16+v5s2ba8+ePZoxY4ZGjBhhr12Wi0BfD8X0DCpx+wsXLqh///7atWuXsrOzlZaWZr/gAAAAyoCj5nEAAODWYLfbGM+fP68XX3xRy5cv16lTp+Tn56chQ4bopZdeUrVq1Uq0DUcYAp+VlaUtW7bIx8dHnTp1otgFAEAFc4T8wt5uNo/jHAMAAHuo8Dm7ykJVS5QyMzM1bNgwxcfHy9XVVbfffrvWr18vSUpKSpLFYqHYBQBABatq+UVVxDkGAAD2UOFzdt2K1q5dq7S0NCUkJEiSzp07V2wfi8Wi1atXy8/Pz97hAQAAAAAAODyn4pugpMxms/bt26fo6GgtWrRIrq6uxfaJi4uj0AUAAAAAAFBGKHaVoUaNGikhIUE9e/bUli1bFBISotTU1IoOCwAAAAAA4JZBsasMpaSkyGQyKTIyUtOnT5dhGEpOTq7osAAAAAAAAG4ZFLtKKfFMhqat3a+/fLpH09buV+KZDNu6+Ph4dejQQWazWWFhYYqKilJoaKhCQ0PVrl07Wa1W+fv7KyoqytbHYrHoxIkTkqSVK1fq8ccfL/djAgAAAAAAcBQ8jbEUFu9M1oSle2UymWQYhu19Wv9QDQgPqOjwAABACVS2/MIRcY4BAIA9lDTHYGRXCSWeydCEpXuVa0g5uUae95ile5V03QgvAAAAAAAAVAyKXSW0eGeyTCZTgetMJpMW7WRuLgAAAAAAgIpGsauEUlIzVdgdn4ZhKCU1s5wjAgAAAAAAwB9R7Cohf2/3Ikd2+Xu7l3NEAAAAAAAA+COKXSU0MDygyJFdg5igHgAAAAAAoMJR7Cqhhr4emtY/VE4mydnJlOd9Wv9QBfp6VHSIAAAAAAAAtzyXig6gKhkQHqBWgT5atDNZKamZ8vd216DwAApdAAAAAAAAlQTFrlIK9PVQTM+gig4DAAAAAAAABeA2RgAAAAAAADgMil0AAAAAAABwGBS7AAAAAAAA4DAodgEAAAAAAMBhUOwCAAAAAACAw6DYBQAAAAAAAIdBsQsAAAAAAAAOg2IXAAAAAAAAHAbFLgB2c+HCBfXo0UO+vr6qVatWmW03KSmp0O0Vte7EiRPq2LGj7fOkSZN06dKlMosLAAAAAFDxKHYBsBtXV1fFxMQoNja2VP2ys7PtEo+fn5++//572+fJkydT7AIAAAAAB0OxC0CZyMzM1KBBgxQcHCyz2ayIiAi5ubmpS5cuJRrVNWzYMI0YMUL33XefQkJCJEmPPvqowsPDFRoaqt69e+u3337L02f8+PEKDQ1V8+bN8xXUClp3/aivUaNGSZI6duwoi8WiU6dO3eQZAAAAAABUBhS7AJSJtWvXKi0tTQkJCfrpp5/02WefFdvHYrHoxIkTts+7du3SV199pf3790uS3nrrLe3cuVN79+5Vx44dNWnSJFvb9PR0NWvWTHv37tWHH36oRx55ROfPny923TWzZs2SJH3//feKi4tT3bp1b/YUAAAAAAAqAZeKDgCAYzCbzdq3b5+io6N1//33q1evXsX2iYuLy/N5wIABqlmzpu3zwoUL9cknn+jSpUu6dOmSfH19betcXFw0bNgwSVLbtm3l5+enPXv2qH79+kWuAwAAAAA4NkZ2ASgTjRo1UkJCgnr27KktW7YoJCREqamppdpGjRo1bH/evHmz3n77ba1evVo///yzZsyYUez8WiaT6YbWAQAAAAAcB8UuAGUiJSVFJpNJkZGRmj59ugzDUHJy8g1vLzU1VTVr1lTt2rV1+fJlzZ49O8/67OxsffLJJ5Kk7du368SJE7JYLMWuu17NmjWVnp5+wzECAAAAACofil0AykR8fLw6dOggs9mssLAwRUVFKTQ0VKGhoWrXrp2sVqv8/f0VFRVl6/PHObuu17NnT9199926++67bZPIX8/Ly0s///yzzGazhg8froULF9pugSxq3fXGjRun7t27M0E9AAAAADgQk2EYRkUHURir1SovLy+lp6fL09OzosMBICnxTIYW70xWSmqm/L3dNTA8QA19PSo6LAAoMfIL++McAwAAeyhpjsEE9QBKbPHOZE1Yulcmk0mGYchkMmn2t4c1rX+oBoQHVHR4AAAAAABwGyOAkkk8k6EJS/cq15Byco087zFL9yrpTEZFhwgAAAAAAMUuACWzeGdyoU80NJlMWrTzxiejBwAAAACgrFDsAlAiKamZKmyKP8MwlJKaWc4RAQAAAACQH8Uu4CZduHBBPXr0kK+vr2rVqnXT25s0aZLGjh1b4LqVK1fqmWeekSQlJSVp1qxZN72/kvL3di9yZJe/t3u5xQIAAAAAQGEodgE3ydXVVTExMYqNjbX7viIjIzVz5kxJ5V/sGhgeUOTIrkFMUA8AAAAAqAQodgGlkJmZqUGDBik4OFhms1kRERFyc3NTly5dih3VlZGRIR8fH125ckWS1Lp1az3yyCOSpGPHjqlx48a2tidPnlSfPn0UHBysLl266Ny5c5Kkjz/+WH379pUkjRo1SgcOHJDFYlFkZKQk6eDBg+rdu7datWql0NBQ/fvf/y6zY2/o66Fp/UPlZJKcnUx53qf1D1Wgr0eZ7QsAAAAAgBvlUtEBAFXJ2rVrlZaWpoSEBEmyFaGKYrFYtHr1avn5+SkkJETbtm1TixYtdPnyZe3YsUOGYWjDhg3q2rWrrc+PP/6oXbt2qXbt2ho8eLBmz56tiRMn5tnurFmzNHbsWMXFxUmScnJyNGTIEM2fP19BQUG6ePGi2rZtqzZt2qhVq1ZlcvwDwgPUKtBHi3YmKyU1U/7e7hoUHkChCwAAAABQaVDsAkrBbDZr3759io6O1v33369evXoV2+daMUqSunXrptjYWJ0+fVoRERHat2+f4uPjFRsbaxuxJUk9e/ZU7dq1JUnt2rVTfHx8sfs5cOCAfvnlFw0ePNi27Pz580pISCizYpckBfp6KKZnUJltDwAAAACAskSxCyiFRo0aKSEhQRs3blRsbKyee+45xcXFydvbu0T9u3XrpvHjx+v06dN66KGHdOedd2rDhg365ptv9Pbbb9vaVa9e3fZnZ2dnZWdnF7ttwzDk4+OTp7gGAAAAAMCthjm7gFJISUmRyWRSZGSkpk+fLsMwlJycXOL+rVu31oEDB7RhwwZ17NhR3bp10zvvvKM77rhDderUKVUsnp6eSk9Pt32+++675enpqblz59qWHTp0qES3WgIAAAAA4CgodgGlEB8frw4dOshsNissLExRUVEKDQ1VaGio2rVrJ6vVKn9/f0VFRdn6WCwWnThxQpLk4uKiDh06qH79+nJ3d1fz5s115cqVPPN1lVRoaKiaN2+ukJAQRUZGysXFRatWrdKyZcts60aOHKnMzMwyO34AAAAAACo7k2EYRkUHURir1SovLy+lp6fL09OzosPBLSLxTIYWXzcB+8DwADVkAnYAcBjkF/bHOQYAAPZQ0hyDObuA6yzemawJS/fKZDLJMAyZTCbN/vawpvUP1YDwgIoODwAAAAAAFIPbGIH/SjyToQlL9yrXkHJyjTzvMUv3KulMRkWHCAAAAAAAikGxC/ivxTuTZTKZClxnMpm0aGfJJ6IHAAAAAAAVg2IX8F8pqZkqbAo7wzCUkspE7wAAAAAAVHYUu4D/8vd2L3Jkl7+3ezlHBAAAAAAASotiF/BfA8MDihzZNYgJ6gEAAAAAqPQodgH/1dDXQ9P6h8rJJDk7mfK8T+sfqkBfj4oOEQAAAAAAFMOlogMAKpMB4QFqFeijRTuTlZKaKX9vdw0KD6DQBQAAAABAFUGxC/iDQF8PxfQMqugwAAAAAADADeA2RgAAAAAAADgMil0AAAAAAABwGHYtdh0/flz/93//p9q1a8vd3V0tWrTQzp077blLAAAAlAHyOAAAUFXZbc6u1NRUdejQQZ07d9aaNWtUp04dHTx4UN7e3vbaJQAAAMoAeRwAAKjK7FbsmjZtmgICAjR37lzbsoYNG9prdwAAACgj5HEAAKAqs9ttjCtXrlR4eLgGDBigunXrKiwsTP/5z3+K7JOVlSWr1ZrnBQAAgPJV2jyOHA4AAFQmdit2HTlyRO+//77uuusurVu3Tn/+8581ZswYzZs3r9A+U6dOlZeXl+0VEBBgr/AAAABQiNLmceRwAACgMjEZhmHYY8PVqlVTeHi4tm7dals2ZswY7dixQ9u2bSuwT1ZWlrKysmyfrVarAgIClJ6eLk9PT3uECQAAbjFWq1VeXl7kF0UobR5HDgcAAMpDSfM4u43sqlevnoKDg/Msa9asmY4dO1ZoHzc3N3l6euZ5AQAAoHyVNo8jhwMAAJWJ3YpdHTp00IEDB/Is+/XXX9WgQQN77RIAAABlgDwOAABUZXYrdj3zzDP64Ycf9M9//lOHDh3SwoUL9cEHH2j06NH22iUAAADKAHkcAACoyuxW7GrVqpWWL1+uTz/9VCEhIZoyZYreeustPfroo/baJQAAAMoAeRwAAKjK7DZBfVlgAlkAAFDWyC/sj3MMAADsocInqAcAAAAAAADKG8UuAAAAAAAAOAyKXQAAAAAAAHAYFLsAAAAAAADgMCh2AQAAAAAAwGFQ7KoCLly4oB49esjX11e1atUqsu2KFSv0ww8/2D5v2rRJFovFvgECAAAAAABUEhS7qgBXV1fFxMQoNja22LZ/LHYBAAAAAADcSih2VTKZmZkaNGiQgoODZTabFRERITc3N3Xp0qXYUV2rV6/WypUr9cYbb8hisWjOnDmSpOzsbEVHR8tsNqt58+bauXOnrc+6det07733qmXLlmrdurW++eYbex4eAAAAAACAXblUdADIa+3atUpLS1NCQoIk6dy5c8X2sVgsWr16tXr16qXIyEhZLBaNHTtW0tXbGPfv368PP/xQ7733nmbNmqUXXnhB69at05EjRzRp0iStW7dOnp6eOnTokDp27KikpCS5ubnZ8zABAAAAAADsgpFdlYzZbNa+ffsUHR2tRYsWydXVtdg+cXFx8vPzK3R9kyZN1KZNG0lSu3btdPjwYUlXC2uHDh3SfffdJ4vFoocfflhOTk46duxY2RwMAAAAAABAOaPYVck0atRICQkJ6tmzp7Zs2aKQkBClpqbe1DarV69u+7Ozs7Oys7MlSYZhqHv37oqLi7O9jh8/rrvuuuum9gcAAAAAAFBRKHZVMikpKTKZTIqMjNT06dNlGIaSk5NL3N/T01Pp6eklatujRw/FxsZq7969tmXbt28vdcwAAAAAAACVBcWuCpJ4JkPT1u7XXz7do2lr9yvxTIYkKT4+Xh06dJDZbFZYWJiioqIUGhqq0NBQtWvXTlarVf7+/oqKirJty2Kx6MSJE5KkqKgoLV68WGFhYbYJ6gvTpEkTLVy4UE899ZTMZrOaNWumt956y27HDAAAAAAAYG8mwzCMig6iMFarVV5eXkpPT5enp2dFh1NmFu9M1oSle2UymWQYhu19Wv9QDQgPqOjwAABwaI6aX1QmnGMAAGAPJc0xGNlVzhLPZGjC0r3KNaScXCPPe8zSvUr67wgvAAAAAAAAlB7FrnK2eGeyTCZTgetMJpMW7Sz5/FwAAAAAAADIi2JXOUtJzVRhd44ahqGU1MxyjggAAAAAAMBxUOwqZ/7e7kWO7PL3di/niAAAAAAAABwHxa5yNjA8oMiRXYOYoB4AAAAAAOCGUewqZw19PTStf6icTJKzkynP+7T+oQr09ajoEAEAAAAAAKosl4oO4FY0IDxArQJ9tGhnslJSM+Xv7a5B4QEUugAAAAAAAG4Sxa4KEujroZieQRUdBgAAAAAAgEPhNkYAAAAAAAA4DIpdAAAAAAAAcBgUuwAAAAAAAOAwKHYBAAAAAADAYVDsAgAAAAAAgMOg2AUAAAAAAACHQbELAAAAAAAADoNiFwAAAAAAABwGxS4AAAAAAAA4DIpdAAAAAAAAcBgUuwAAAAAAAOAwKHYBAAAAAADAYVDsQj6rVq1SUFCQ7rrrLvXr109Wq7WiQwIAAAAAACgRil3I48KFCxo5cqRWrFihgwcPys/PT1OmTKnosAAAAAAAAEqEYtctLDMzU4MGDVJwcLDMZrMiIiK0Zs0ahYWFKSgoSJIUHR2tTz/9NF/fjIwM+fj46MqVK5Kk1q1b65FHHpEkHTt2TI0bN5Ykff3112rXrp3CwsLUvHlzffjhh7ZtzJkzR8HBwbJYLGrRooV+/PFHex8yAAAAAABwcC4VHQAqztq1a5WWlqaEhARJ0rlz5zR37lw1aNDA1iYwMFAnT55Udna2XFxcZLFYtHr1avn5+SkkJETbtm1TixYtdPnyZe3YsUOGYWjDhg3q2rWrJOmee+7R5s2b5ezsrHPnziksLEw9evSQv7+/xo0bp/3796tevXq6cuWKsrKyKuQ8AAAAAAAAx0Gx6xZmNpu1b98+RUdH6/7771evXr2K7RMXF2f7c7du3RQbG6vTp08rIiJC+/btU3x8vGJjY9W3b19J0tmzZzVy5Ej9+uuvcnFx0dmzZ/Xzzz/L399fXbt2VVRUlPr06aMHHnhATZs2tdORAgAAAACAWwW3Md7CGjVqpISEBPXs2VNbtmxRSEiI6tevr6NHj9raJCUlqV69enJxyV8XvVbsio2NVbdu3dStWzdt2LBB33zzjbp06SJJGjVqlO69917Fx8crLi5OTZs21aVLlyRJS5cu1WuvvaYrV66oV69e+uyzz8rnwAEAAAAAgMNiZNctLCUlRd7e3oqMjFTPnj21YsUKNW3aVLt379b+/fsVFBSk9957T4MHDy6wf+vWrXXgwAGdOnVKM2bM0J133qnevXvrjjvuUJ06dSRJqampatCggUwmk7777jv99NNPkqTs7GwlJSUpPDxc4eHhOnPmjLZv317ovgAAAAAAAEqCYtctLD4+XhMnTpRhGMrOzlZUVJTMZrPmzJmjvn37Kjs7WyEhIZo3b56tz/Vzdrm4uKhDhw66cOGC3N3d1bx5c125csU2X5ckvfbaa4qOjtaUKVNksVjUpk0bSVJOTo5GjBihc+fOycXFRXXq1NHcuXPL/RwAAAAAAADHYjIMw6joIApjtVrl5eWl9PR0eXp6VnQ4VVLimQwt3pmslNRM+Xu7a2B4gBr6elR0WAAAVBjyC/vjHAMAAHsoaY7ByC4HtnhnsiYs3SuTySTDMGQymTT728Oa1j9UA8IDKjo8AAAAAACAMscE9Q4q8UyGJizdq1xDysk18rzHLN2rpDMZFR0iAAAAAABAmaPY5aAW70yWyWQqcJ3JZNKincnlHBEAAAAAAID9UexyUCmpmSpsOjbDMJSSmlnOEQEAAAAAANgfxS4H5e/tXuTILn9v93KOCAAAAAAAwP4odjmogeEBRY7sGsQE9QAAAAAAwAFR7HJQDX09NK1/qJxMkrOTKc/7tP6hCvT1qOgQAQAAAAAAypxLRQcA+xkQHqBWgT5atDNZKamZ8vd216DwAApdAAAAAADAYTGyy8EF+noopmeQ3hkSppieQRS67GzVqlUKCgrSXXfdpX79+slqtZaqf2BgoOLi4uwTnCSLxaLz58/bbfsAAAAAAFQ0il1AGblw4YJGjhypFStW6ODBg/Lz89OUKVMqOqw84uLiVLNmzYoOAwAAAAAAu6HYBdyAzMxMDRo0SMHBwTKbzYqIiNCaNWsUFhamoKAgSVJ0dLQ+/fTTAvvPmTNHwcHBslgsatGihX788cd8bX777TcNHDhQrVu3VosWLfT3v//dtu7gwYPq3bu3WrVqpdDQUP373/+2rTOZTPr73/+usLAwNW3aVAsWLMizLi0tTdLVUWQvvfSS2rVrp4YNG+qVV16xtdu/f7/atWun5s2bq1+/foqIiNDHH398M6cMAAAAAIBywZxdwA1Yu3at0tLSlJCQIEk6d+6c5s6dqwYNGtjaBAYG6uTJk8rOzpaLi4ssFotWr14tPz8/jRs3Tvv371e9evV05coVZWVl5dvH0KFD9fzzz+v+++9Xdna2HnzwQS1ZskT9+vXTkCFDNH/+fAUFBenixYtq27at2rRpo1atWkm6WtTas2ePjhw5ovDwcHXo0EGBgYH59pGWlqZt27bpzJkzaty4sYYPH64777xTUVFRio6O1vDhw7Vv3z6FhYXpkUcesc/JBAAAAACgDJXbyK7XXntNJpNJY8eOLa9dAnZjNpu1b98+RUdHa9GiRXJ1dS22T1xcnPz8/CRJXbt2VVRUlP71r38pMTFRNWrUyNM2IyNDX3/9tf7617/KYrEoPDxchw4d0oEDB3TgwAH98ssvGjx4sCwWi9q3b6/z58/bCm+S9Pjjj0uSGjVqpPvuu0/fffddgTFdK2D5+vqqUaNGSkxMlNVqVVxcnB577DFJUrNmzXTvvfeW/iQBABwCORwAAKhqymVk144dOzR79myFhoaWx+4Au2vUqJESEhK0ceNGxcbG6rnnntP06dO1YcMGW5ukpCTVq1dPLi75f82WLl2qXbt2adOmTerVq5deeeUVDR482LbeMAxJ0g8//KDq1avn6fvLL7/Ix8enVBPZm0ymApdfv21nZ2dlZ2eXqj8AwLGRwwEAgKrI7iO7Lly4oEcffVT/+c9/5O3tbe/dAeUiJSVFJpNJkZGRmj59ugzDUNOmTbV7927t379fkvTee+/lKWBdk52drcOHDys8PFzjx4/Xww8/rO3bt+dpU6NGDXXu3FmvvfaabdmJEyeUkpKiu+++W56enpo7d65t3aFDh3Tu3Dnb52vrkpKS9P3336tjx44lPjZPT0+ZzWbNnz9fknTgwAFt3ry5xP0BAI6BHA4AAFRVdi92jR49Wr1791a3bt2KbZuVlSWr1ZrnBVRG8fHx6tChg8xms8LCwhQVFSWz2aw5c+aob9++atKkiVJSUvTiiy/a+lgsFp04cUI5OTkaMWKEQkJCZLFYtGvXLj377LP59rFgwQIdOnRIISEhatGihfr166ezZ8/KxcVFq1at0rJlyxQaGqrmzZtr5MiRyszMtPXNyclRWFiYIiIi9Pbbbxc4X1dR/t//+396//33FRISopiYGLVq1Uq1atW60dMFAKiCyOEAAEBVZTKu3S9lB5999pleffVV7dixQ9WrV1enTp1ksVj01ltvFdh+0qRJmjx5cr7l6enp8vT0tFeYQIESz2Ro8c5kpaRmyt/bXQPDA9TQ16OiwyqWyWRSamrqTRWnLly4IA8PD5lMJiUmJqpdu3basWOHAgICyi5QAKggVqtVXl5e5BdFIIcDAACVUUnzOLvN2ZWcnKy//vWv2rBhQ745hwozceLEPCNcrFYr/7lGhVi8M1kTlu6VyWSSYRgymUya/e1hTesfqgHhjv8zuXXrVv3tb3+TdHWU2MyZM/ldBIBbBDkcAACo6uw2smvFihV66KGH5OzsbFuWk5Mjk8kkJycnZWVl5VlXEL55RUVIPJOhrm9uUm4BvxlOJmnjuE4KrAIjvAAABSO/KBo5HAAAqKwqfGRX165dFR8fn2fZ8OHDFRQUpJiYmGKTJKCiLN6ZfPXpgwXUgU0mkxbtTFZMz6AKiAwAAPsjhwMAAFWd3YpdNWvWVEhISJ5lHh4eql27dr7lQGWSkpqpwgY8GoahlNTMAtcBAOAIyOEAAEBVZ/enMQJVjb+3+9WRXQUwmUzy93Yv54gAAAAAAEBJ2W1kV0E2bdpUnrsDbsjA8ADN/vZwgesMw9CgW2CCegAArkcOBwAAqhJGdgF/0NDXQ9P6h8rJJDk7mfK8T+sfyuT0AAAAAABUYuU6sguoKgaEB6hVoI8W7UxWSmqm/L3dNSg8gEIXAAAAAACVHMUuoBCBvh48dREAAAAAgCqG2xgBAAAAAADgMCh2AQAAAAAAwGFQ7AIAAAAAAIDDoNgFAAAAAAAAh0GxCwAAAAAAAA6DYhcAAAAAAAAcBsUuAAAAAAAAOAyKXQAAAAAAAHAYFLsAAAAAAADgMCh2AQAAAAAAwGFQ7AIAAAAAAIDDoNgFAAAAAAAAh0GxCwAAAAAAAA6DYhcAAAAAAAAcBsUuAAAAAAAAOAyKXQAAAAAAAHAYFLsAAAAAAADgMCh2AQAAAAAAwGFQ7AIAAAAAAIDDoNgFAAAAAAAAh0GxCwAAAAAAAA6DYhcAAAAAAAAcBsUuAAAAAAAAOAyKXQAAAAAAAHAYFLsAAAAAAADgMCh2AQAAAAAAwGFQ7AIAAAAAAIDDoNgFAAAAAAAAh0GxCwAAAAAAAA6DYhcAAAAAAAAcBsUuAAAAAAAAOAyKXQAAAAAAAHAYFLsAAAAAAADgMCh2AQAAAAAAwGFQ7AIAAAAAAIDDoNgFAAAAAAAAh0GxCwAAAAAAAA6DYhcAAAAAAAAcBsUuAAAAAAAAOAyKXQAAAAAAAHAYFLsAAAAAAADgMCh2AQAAAAAAwGFQ7AIAAAAAAIDDoNgFAAAAAAAAh0GxCwAAAAAAAA6DYhcAAAAAAAAcBsUuAAAAAAAAOAyKXQAAAAAAAHAYFLsAAAAAAADgMCh2AQAAAAAAwGFQ7AIAAAAAAIDDoNgFAAAAAAAAh2HXYtfUqVPVqlUr1axZU3Xr1lXfvn114MABe+4SAAAAN4kcDgAAVGV2LXZ9++23Gj16tH744Qdt2LBBV65cUUREhDIyMuy5WwAAANwEcjgAAFCVmQzDMMprZ6dPn1bdunX17bff6r777iu2vdVqlZeXl9LT0+Xp6VkOEQIAAEdHflF65HAAAKAyKGmO4VKOMSk9PV2S5OPjU+D6rKwsZWVl2T5brdZyiQsAAACFI4cDAABVSblNUJ+bm6uxY8eqQ4cOCgkJKbDN1KlT5eXlZXsFBASUV3gAAAAoADkcAACoasrtNsY///nPWrNmjTZv3ix/f/8C2xT0rWBAQABD4AEAQJnhFrvSIYcDAACVRaW6jfHpp5/WqlWr9N133xWaJEmSm5ub3NzcyiMkAAAAFIMcDgAAVEV2LXYZhqG//OUvWr58uTZt2qSGDRvac3cAAAAoA+RwAACgKrNrsWv06NFauHChvvjiC9WsWVO//fabJMnLy0vu7u723DUAAABuEDkcAACoyuw6Z5fJZCpw+dy5czVs2LBi+zOnBgAAKGvkF8UjhwMAAJVRpZizq5zmvgcAAEAZIocDAABVmVNFBwAAAAAAAACUFYpdAAAAAAAAcBgUuwAAAAAAAOAwKHYBAAAAAADAYVDsAgAAAAAAgMOg2AUAAAAAAACHQbELAAAAAAAADoNiFwAAAAAAABwGxS4AAAAAAAA4DIpdAAAAAAAAcBgUuwAAAAAAAOAwKHYBdnThwgX16NFDvr6+qlWrVkWHAwAAAACAw6PYBdiRq6urYmJiFBsbW9GhAAAAAABwS6DYBZSRzMxMDRo0SMHBwTKbzYqIiJCbm5u6dOlSolFdc+bMUXBwsCwWi1q0aKEff/xRknTw4EH17t1brVq1UmhoqP7973/b+uzYsUNdunRReHi4wsLCtGTJEknS6dOnFRERoRYtWig0NFTDhw+3yzEDAAAAAFDZuFR0AICjWLt2rdLS0pSQkCBJOnfuXLF9LBaLVq9eLT8/P40bN0779+9XvXr1dOXKFWVlZSknJ0dDhgzR/PnzFRQUpIsXL6pt27Zq06aN7rrrLj355JNavXq16tWrpzNnzuiee+5R+/bttXjxYjVs2FDr168vcSwAAAAAADgCil1AGTGbzdq3b5+io6N1//33q1evXsX2iYuLs/25a9euioqKUp8+ffTAAw+oadOmSkhI0C+//KLBgwfb2p0/f14JCQk6ffq0jhw5ogceeCDPNg8cOKC2bdtq5syZGjdunO677z717NmzzI4TAAAAAIDKjGIXUEYaNWqkhIQEbdy4UbGxsXruuecUFxcnb2/vEvVfunSpdu3apU2bNqlXr1565ZVX1KJFC/n4+OQpil3z1VdfqXnz5tq6dWuB24uLi1NsbKyWLVumF198UXv27JGzs/PNHCIAAAAAAJUec3YBZSQlJUUmk0mRkZGaPn26DMNQcnJyifpmZ2fr8OHDCg8P1/jx4/Xwww9r+/btuvvuu+Xp6am5c+fa2h46dEjnzp1T+/btlZiYmGfy+7i4OF2+fFmJiYmqUaOGBg4cqHfeeUe//vqrLly4UObHDAAAAABAZcPILqCMxMfHa+LEiTIMQ9nZ2YqKilJoaKhCQ0N1+vRpWa1W+fv7q3Pnzvrkk08k/W/Ortq1a2vEiBE6d+6cXFxcVKdOHc2dO1cuLi5atWqVxo4dq5kzZyonJ0e+vr5auHCh7rzzTn311VcaP368xo0bpytXrqh+/fpasWKFNm3apBkzZsjZ2VnZ2dl644035OXlVcFnCAAAAAAA+zMZhmFUdBCFsVqt8vLyUnp6ujw9PSs6HECSlHgmQ4t3JislNVP+3u4aGB6ghr4eFR0WAKCEyC/sj3MMAADsoaQ5BiO7gFJYvDNZE5bulclkkmEYMplMmv3tYU3rH6oB4QEVHR4AAAAAALc85uwCSijxTIYmLN2rXEPKyTXyvMcs3aukMxkVHSIAAAAAALc8il1ACS3emSyTyVTgOpPJpEU7SzYZPQAAAAAAsB+KXUAJpaRmqrAp7gzDUEpqZjlHBAAAAAAA/ohiF1BC/t7uRY7s8vd2L+eIAAAAAADAH1HsAkpoYHhAkSO7BjFBPQAAAAAAFY5iF1BCDX09NK1/qJxMkrOTKc/7tP6hCvT1qOgQAQAAAAC45blUdABAVTIgPECtAn20aGeyUlIz5e/trkHhARS6AAAAAACoJCh2AaUU6OuhmJ5BFR0GAAAAAAAoALcxAgAAAAAAwGFQ7AIAAAAAAIDDoNgFAAAAAAAAh0GxCwAAAAAAAA6DYhcAAAAAAAAcBsUuAAAAAAAAOAyKXQAAAAAAAHAYFLsAAAAAAADgMCh2AQAAAAAAwGFQ7AIAAAAAAIDDoNgFAAAAAAAAh0GxCwAAAAAAAA6DYhcAAAAAAAAcBsUuAAAAAAAAOAyKXQAAAAAAAHAYFLsAAAAAAADgMCh2AQAAAAAAwGFQ7AIAAAAAAIDDoNgFAAAAAAAAh0GxCwAAAAAAAA6DYhcAAAAAAAAcBsUuAAAAAAAAOAyKXQAAAAAAAHAYFLsAAAAAAADgMCh2AQAAAAAAwGFQ7AIAAAAAAIDDsHux691331VgYKCqV6+uNm3aaPv27fbeJQAAAMoAeRwAAKiK7FrsWrRokZ599lm9/PLL2r17t8xms3r06KFTp07Zc7cAAAC4SeRxAACgqrJrsWvGjBl64oknNHz4cAUHB2vWrFm67bbb9NFHH9lztwAAALhJ5HEAAKCqslux6/Lly9q1a5e6dev2v505Oalbt27atm1bgX2ysrJktVrzvAAAAFC+SpvHkcMBAIDKxG7FrjNnzignJ0e33357nuW33367fvvttwL7TJ06VV5eXrZXQECAvcIDAABAIUqbx5HDAQCAyqRSPY1x4sSJSk9Pt72Sk5MrOiQAAAAUgxwOAABUJi722rCvr6+cnZ31+++/51n++++/64477iiwj5ubm9zc3OwVEgAAAEqgtHkcORwAAKhM7Dayq1q1amrZsqW+/vpr27Lc3Fx9/fXXateunb12CwAAgJtEHgcAAKoyu43skqRnn31WQ4cOVXh4uFq3bq233npLGRkZGj58uD13CwAAgJtEHgcAAKoquxa7Bg0apNOnT+ull17Sb7/9JovForVr1+ab7BQAAACVC3kcAACoqkyGYRgVHURhrFarvLy8lJ6eLk9Pz4oOBwAAOADyC/vjHAMAAHsoaY5RqZ7GCAAAAAAAANwMil0AAAAAAABwGBS7AAAAAAAA4DAodgEAAAAAAMBhUOwCAAAAAACAw6DYBQAAAAAAAIdBsQsAAAAAAAAOg2IXAAAAAAAAHAbFLgAAAAAAADgMil0AAAAAAABwGBS7AAAAAAAA4DAodgEAAAAAAMBhUOwCAAAAAACAw6DYBQAAAAAAAIdBsQsAAAAAAAAOg2IXAAAAAAAAHAbFLgAAAAAAADgMil0AAAAAAABwGBS7AAAAAAAA4DAodgEAAAAAAMBhUOwCAAAAAACAw6DYBQAAAAAAAIdBsQsAAAAAAAAOg2IXAAAAAAAAHAbFLgAAAAAAADgMil0AAAAAAABwGBS7AAAAAAAA4DAodgEAAAAAAMBhUOwCAAAAAACAw6DYBQAAAAAAAIdBsQsAAAAAAAAOg2IXAAAAAAAAHAbFLgAAAAAAADgMil0AAAAAAABwGBS7AAAAAAAA4DAodgEAAAAAAMBhUOwCAAAAAACAw6DYBQAAAAAAAIdBsQsAAABwMBcuXFCPHj3k6+urWrVqldl2k5KSCt1eUetOnDihjh072j5PmjRJly5dKrO4AAC4HsUuAAAAwMG4uroqJiZGsbGxpeqXnZ1tl3j8/Pz0/fff2z5PnjyZYhcAwG4odgEAAABVWGZmpgYNGqTg4GCZzWZFRETIzc1NXbp0KdGormHDhmnEiBG67777FBISIkl69NFHFR4ertDQUPXu3Vu//fZbnj7jx49XaGiomjdvnq+gVtC660d9jRo1SpLUsWNHWSwWnTp16ibPAAAAeVHsAgAAAKqwtWvXKi0tTQkJCfrpp5/02WefFdvHYrHoxIkTts+7du3SV199pf3790uS3nrrLe3cuVN79+5Vx44dNWnSJFvb9PR0NWvWTHv37tWHH36oRx55ROfPny923TWzZs2SJH3//feKi4tT3bp1b/YUAACQh0tFBwAAAADgxpnNZu3bt0/R0dG6//771atXr2L7xMXF5fk8YMAA1axZ0/Z54cKF+uSTT3Tp0iVdunRJvr6+tnUuLi4aNmyYJKlt27by8/PTnj17VL9+/SLXAQBQXhjZBQAAAFRhjRo1UkJCgnr27KktW7YoJCREqamppdpGjRo1bH/evHmz3n77ba1evVo///yzZsyYUez8WiaT6YbWAQBgDxS7AAAAgCosJSVFJpNJkZGRmj59ugzDUHJy8g1vLzU1VTVr1lTt2rV1+fJlzZ49O8/67OxsffLJJ5Kk7du368SJE7JYLMWuu17NmjWVnp5+wzECAFAUil0AAABAFRYfH68OHTrIbDYrLCxMUVFRCg0NVWhoqNq1ayer1Sp/f39FRUXZ+vxxzq7r9ezZU3fffbfuvvtu2yTy1/Py8tLPP/8ss9ms4cOHa+HChbZbIItad71x48ape/fuTFAPALALk2EYRkUHURir1SovLy+lp6fL09OzosMBAAAOgPzC/jjHZS/xTIYW70xWSmqm/L3dNTA8QA19PSo6LAAAylVJcwwmqAcAAAAqscU7kzVh6V6ZTCYZhiGTyaTZ3x7WtP6hGhAeUNHhAQBQ6XAbIwAAAFBJJZ7J0ISle5VrSDm5Rp73mKV7lXQmo6JDBACg0qHYBQAAAFRSi3cmF/o0Q5PJpEU7b3wiegAAHBXFLgAAAKCSSknNVGFT7BqGoZTUzHKOCACAyo9iFwAAAFBJ+Xu7Fzmyy9/bvZwjAgCg8qPYBQAAAFRSA8MDihzZNYgJ6gEAyIdiFwAAAFBJNfT10LT+oXIySc5Opjzv0/qHKtDXo6JDBACg0qHYBQAAUIgLFy7onnvukYuLi5ydndWvXz9ZrdZSb6dWrVqaOHGiJOm+++5TdHR0WYcKBzYgPEAbx3XSk/c1Uu9QPz15XyNtHNdJAxjVBQBAgexS7EpKStLIkSPVsGFDubu7q3Hjxnr55Zd1+fJle+wOAADALrKyspSYmKglS5aoZs2a8vPz05QpU25qm999953ee++9Moqw7JHHVU6Bvh6K6Rmkd4aEKaZnECO6AAAogl2KXfv371dubq5mz56tX375RTNnztSsWbP0/PPP22N3AAAAN+3cuXOqX7++3Nzc5O7urtq1a2vjxo1q06aNwsLCJEnR0dH69NNPC+w/evRo1ahRQ7fddpvc3d314osvFtiuSZMmeuihhyRdHTnWqlUrVa9eXe7u7vL19bW1e/DBB23b8/X11ZYtW8r4iAtGHgcAAKo6uxS7evbsqblz5yoiIkKNGjVSZGSkxo8fr2XLltljdwAAADdt2rRpunjxorKyspSZmant27fr2LFjatCgga1NYGCgTp48qezsbEmSu7u7du/eLUkaO3asrFarLl68qA0bNuif//xnsbc89unTRykpKTp16pQyMzP1/fffS7paODt06JDOnTunixcv6uGHH7YVyOyNPA4AAFR1LuW1o/T0dPn4+BTZJisrS1lZWbbPNzInBgAAwI144IEH9OabbyokJERdu3ZVTExMsX0yMzNtf962bZvatWunCxcuyGQyKTc3V5s3b1avXr0K7b99+3b94x//kKenpySpWbNmkqSVK1fqt99+k5eXlyQV+jS+8lJcHkcOBwAAKpNymaD+0KFDeuedd/TUU08V2W7q1Kny8vKyvQICmHQTAACUj06dOiklJUV/+tOftGnTJtWvX18+Pj46evSorU1SUpLq1asnF5f83xeOHDlSQ4cO1aVLl5SZmSmTyaTz58/fUCyGYWjQoEHKzMxUZmamLl26pEuXLt3wsd2MkuRx5HAAAKAyKVWxa8KECTKZTEW+9u/fn6fP8ePH1bNnTw0YMEBPPPFEkdufOHGi0tPTba/k5OTSHxEAAMAN2LFjh5ycnPTqq6/a5seqUaOGdu/ercOHD0uS3nvvPQ0ePLjA/jk5Oba5vf785z+XaDRW27ZtNX36dNtIqH379kmSIiMjtWzZMtt+L168WOhcYSVlzzyOHA4AAFQmpbqNcdy4cRo2bFiRbRo1amT784kTJ9S5c2e1b99eH3zwQbHbd3Nzk5ubW2lCAgAAKBNr1qzR1KlTJV0dWdWmTRsNGDBAf/vb39SjRw/l5OToww8/VGRkpK2Pu7u7tmzZonvuuUdPPfWUhg8frieffFLBwcFydnYudp9ffPGFOnfurLp168pkMqlmzZo6deqU3nvvPf3+++8KCQmxxdO9e3cNGTLkho/PnnkcORwAAKhMTIadJoE4fvy4OnfurJYtW2r+/PklSvj+yGq1ysvLS+np6ba5LAAAAG7U9wdPa9rKPfpqfA/yiyLcbB5HDgcAAOyhpDmGXSaoP378uDp16qQGDRpo+vTpOn36tG3dHXfcYY9dAgAAFOlvn/+kJTtTlJt1saJDqdTI4wAAQFVnl2LXhg0bdOjQIR06dEj+/v551lX004QAAMCt5/uDp7VkZ0pFh1ElkMcBAICqzi5PYxw2bJgMwyjwBQAAUN5mbPi1okOoMsjjAABAVWeXYhcAAEBl8rs1q6JDAAAAQDmh2AUAABze7Z48KRAAAOBWQbELAAA4vGe7N63oEAAAAFBOKHYBAACH1/GuOhoY7l98QwAAAFR5FLsAAMAt4fWHzZo/srVC/b0qOhQAAADYEcUuAABwy7j3rjpa+ETbig4DAAAAdkSxCwAAAAAAAA6DYhcAAAAAAAAcBsUuAAAAAAAAOAyKXQAAAAAAAHAYFLsAAAAAAADgMCh2AQAAAAAAwGFQ7AIAAAAAAIDDoNgFAAAAAAAAh0GxCwAAAAAAAA6DYhcAAABQBlatWqWgoCDddddd6tevn6xWa6n6BwYGKi4uzj7BSbJYLDp//rzdtg8AQGVBsQsAAAC4SRcuXNDIkSO1YsUKHTx4UH5+fpoyZUpFh5VHXFycatasWdFhAABgdxS7AAAAgFLIzMzUoEGDFBwcLLPZrIiICK1Zs0ZhYWEKCgqSJEVHR+vTTz8tsP+cOXMUHBwsi8WiFi1a6Mcff8zX5rffftPAgQPVunVrtWjRQn//+99t6w4ePKjevXurVatWCg0N1b///W/bOpPJpL///e8KCwtT06ZNtWDBgjzr0tLSJF0dRfbSSy+pXbt2atiwoV555RVbu/3796tdu3Zq3ry5+vXrp4iICH388cc3c8oAAChXLhUdAAAAAFCVrF27VmlpaUpISJAknTt3TnPnzlWDBg1sbQIDA3Xy5EllZ2fLxcVFFotFq1evlp+fn8aNG6f9+/erXr16unLlirKysvLtY+jQoXr++ed1//33Kzs7Ww8++KCWLFmifv36aciQIZo/f76CgoJ08eJFtW3bVm3atFGrVq0kXS1q7dmzR0eOHFF4eLg6dOigwMDAfPtIS0vTtm3bdObMGTVu3FjDhw/XnXfeqaioKEVHR2v48OHat2+fwsLC9Mgjj9jnZAIAYAcUuwAAAIBSMJvN2rdvn6Kjo3X//ferV69exfa5fi6url27KioqSn369NEDDzygpk2b5mmbkZGhr7/+Wr///rtt2YULF3TgwAEdOHBAv/zyiwYPHmxbd/78eSUkJNiKXY8//rgkqVGjRrrvvvv03XffFVjsulbA8vX1VaNGjZSYmKiaNWsqLi5Ojz32mCSpWbNmuvfee0t2YgAAqCQodgEAAACl0KhRIyUkJGjjxo2KjY3Vc889p+nTp2vDhg22NklJSapXr55cXPKn20uXLtWuXbu0adMm9erVS6+88ooefPBB/f777+rcubMMw5Ak/fDDD6pevXqevr/88ot8fHyKnch+0qRJtlsWTSZTnnUrV67UuXPnVL16dSUlJWnt2rVydnZWdnZ2gdv6Y38AACo75uwCAAAASiElJUUmk0mRkZGaPn26DMNQ06ZNtXv3bu3fv1+S9N577+UZfXVNdna2Dh8+rPDwcI0fP14PP/ywtm/fLldXV3l6emrWrFmSpM6dO+u1116z9Ttx4oRSUlJ09913y9PTU3PnzrWtO3TokM6dO2f7fG2d1WrV999/r44dO+aJITIyUj4+PpKuFuWu7VOSPD09ZTabNX/+fEnSgQMHtHnz5ps6XwAAlDdGdgEAAAB/kHgmQ4t3JislNVP+3u4aGB6ghr4ekqT4+HhNnDhRhmEoOztbUVFRMpvNmjNnjvr27avs7GyFhIRo3rx5tu1dm7Ordu3aGjp0qH7++WdlZWXJ1dVVYWFhcnNzk7u7u+1piQsWLNCzzz6rkJAQmUwmeXh4aPbs2fL29tbJkyf1+eefa+bMmTp48KBq1qypPXv26NixY5KknJwc/ec//1FGRobuuusu9erVS3fccYctlo8//linTp2SJI0aNUpHjx6VyWTSCy+8oC1btmjKlCl65JFHNGrUKFWrVk133nmnatWqVU5nHgCAm0exCwAAALjO4p3JmrB0r0wmkwzDkMlk0uxvD2ta/1ANCA/QAw88oAceeCBfv8jISEVGRha4zetvOxw/frxmzZqldevWSZJtVFZSUpKSkpIkSXXr1rWNrpKuFsvq1KkjDw8PhYaGKiYmRi1atFDnzp2VkZEhPz8/ffTRR5KkcePGydnZWR9//LE2bNig2rVra/DgwfrnP/9pK1pFRETIYrFo1qxZGjt2rC2+nJwcvfDCC9q6dauaNWumhIQEmc3mAm/HBACgsuJfLQAAAOC/Es9kaMLSvco1JP137qxr7zFL96pVoI8C/zvC60bd7AT33bp1U2xsrE6fPq2IiAjt27dP8fHxio2NzdOnZ8+eql27tiSpXbt2io+PL3Y/1ybAv+eee2zLvL29dfbs2RIeHQAAFY85uwAAAID/WrwzudAJ2U0mkxbtTL7pfVyb4L5nz57asmWLQkJClJqaWuL+14pdsbGx6tatm7p166YNGzbom2++0alTp2yjt66f3L6oCeivZxiGfH19lZmZaXudOnVKQ4cOLfVx3gpWrVqloKAg3XXXXerXr5+sVmupt9GpUyetWLFCkvTSSy9pwYIFZRwlANx6KHYBAAAA/5WSmml7GuIfGYahlNTMm99HARPcJyeXvIjWunVrHThwQBs2bFDHjh3VrVs3vfPOO7rjjjtUp06dUsXi6emp9PR02+eSTICPqy5cuKCRI0dqxYoVOnjwoPz8/DRlyhTbuh49esjX17dU85394x//0KOPPmr7TCEMAG4MxS4AAADgv/y93Ysc2eXv7X7T+4iPj1eHDh1kNpsVFhamqKgohYaGKjQ0VO3atZPVapW/v7+ioqJsfSwWi06cOCFJcnFxUYcOHVS/fn25u7urefPmunLlirp27VrqWEJDQ9W8eXOFhIQoMjJSLi4uWrVqlZYtW2ZbN3LkSGVm3nyRryrLzMzUoEGDFBwcLLPZrIiICK1Zs0ZhYWEKCgqSJEVHR+vTTz+VJLm6uiomJsZ2a+nChQvVpk0bhYWFyWw268svvyxwP8OGDdNbb70lSbp8+bIOHz6sMWPGyGw2a/v27bZC2PTp09W6dWvdc8896tmzp44ePWrnMwAAVYvJKOyrq0rAarXKy8tL6enp8vT0rOhwAACAAyC/sL+qfI4Tz2So65ubrs7Z9QdOJmnjuE4lmrOrqKc5oupZvnx5vocKzJ07V7/++qveeustDRs2THv37tX+/fttt5VaLBbNnj1bPXr00OHDh+Xj4yOTyaSkpCS1bdtWR48elZubm5o1a6acnBx5eHjo6NGj6tevn+bMmaPJkyfrnXfe0fvvv68BAwZo8ODBatu2rerWravY2Fh5e3tr3bp1slqtyszM1OnTpyVdLYQtXrxY2dnZqlu3rmbPnq0GDRpU5OkDgDJT0hyDkV0AAADAfzX09dC0/qFyMknOTqY879P6h5ao0LV4Z7K6vrlJH3x3RF/tPaEPvjuirm9u0pIymO8LFeP6hwosWrRIrq6utnVr165VWlqadu3aJScnJ9uthnFxcbr99tslSYmJiXrggQcUEhKivn376vfff9ePP/4oSfLx8dG0adO0Z88edenSRYsXL1ZWVpZWrVolf39/276uzcG2YsUKLV++XHPmzJGTk5O8vLzk6+sr6eoIsgMHDmjbtm3avXu3Hn30UUVHR5fbeQKAyoKnMQIAAADXGRAeoFaBPlp03cisQeEBJR7RZe+nOaL8XXuowMaNGxUbG6vnnntO06dP14YNG2yFsBEjRsjLy0vu7vlvdR08eLBee+01Pfzww5KuFriujUi4dOmSpkyZohdffFEnTpzQxYsXlZiYWGgshmHIy8tLH330kbp06ZJn3YoVK7Rjxw61bNlSkpSTk1NWpwAAqhRGdgEAAAB/EOjroZieQXpnSJhiegaVuEBVHk9zRPkr6KECTZs21e7du3X58mUlJCTo/PnzCgwMLPDpmqmpqWrYsKEkaf78+XnWJyQkqFu3bvr5558VGRkpNzc3Xbp0SZGRkUpJSdGVK1ckXS2KSVLfvn11+vRp25Mfr1y5oj179ki6WgibOHGi4uLiFBcXp/j4eMXHx9v9/ABAZUOxCwAAACgj5fE0R5S/gh4qYDabNWfOHPXu3VuhoaFydXXVunXrbE/XtFgs+v333yVJ//rXv/Twww8rLCxMe/bsUf369W3bzs7Ott3uePjwYV28eFGSFBMTI3d3dz377LOyWCzavHmzJOnRRx9Vp06dNHToULVo0UIWi0UrV66UdLUQNmvWLNvTM68vhAHArYTbGAEAAIAyYnuaYwEFr7J6miPso6iHCgS1uk9DXvsszzpJioyMlKurqyZOnKjExER16tTJ9nTN3Nxc9e3bV1arVRMmTFDnzp31ySefSJK+/vpr1a1bV5I0d+5cvfjii5o/f766dOmiY8eOSZKqVaumxo0ba+zYserbt6+GDRtmi3X58uV64YUXtHr1arm6utrm/3r00Ud19uxZde7cWdLVQtqIESMUFhZWLucQACoLnsYIAABuKeQX9ncrn+OyepojytfincmasHSvTCaTDMOwvU/rHypDKnTdgP8WvQAA5YOnMQIAAADlrCye5ojydf1DBXJyjTzvz32+t9B1MUv3KulMRkWHDwAoALcxAgAAAGXoZp7miPJne6hAoXOtFdzv2gMHYnoG2TE6AMCNoNgFAAAAlLFrT3NE5VfkQwWK6McDBwCg8uI2RgAAAAC3LNtDBQpg+u+rwHU8cAAAKi2KXQAAAABuWQPDAwod2SVJhdTBZBiGBjFBPQBUShS7AAAAANyyinqowOsPh/LAAQCogpizCwAAAMAtrbiHCvDAAQCoWih2AQAAALjlFfVQAR44AABVC7cxAgAAAAAAwGFQ7AIAAAAAAIDDoNgFAAAAAAAAh0GxCwAAAAAAAA6DYhcAAAAAAAAcBsUuAAAAAAAAOAyKXQAAAAAAAHAYFLsAAAAAAADgMCh2AQAAAAAAwGFQ7AIAAAAAAIDDoNgFAAAAAAAAh0GxCwAAAAAAAA7D7sWurKwsWSwWmUwmxcXF2Xt3AAAAKCPkcQAAoCqye7Hrueeek5+fn713AwAAgDJ2K+dxFy5cUI8ePeTr66tatWpVdDgAAKAU7FrsWrNmjdavX6/p06fbczcAAAAoY7d6Hufq6qqYmBjFxsZWdCgAAKCU7Fbs+v333/XEE0/ok08+0W233VaiPllZWbJarXleAAAAKF+lzeOqeg6XmZmpQYMGKTg4WGazWREREXJzc1OXLl1KNKprzpw5Cg4OlsViUYsWLfTjjz9Kkg4ePKjevXurVatWCg0N1b///W9bnx07dqhLly4KDw9XWFiYlixZIkk6ffq0IiIi1KJFC4WGhmr48OF2OWYAAByZiz02ahiGhg0bplGjRik8PFxJSUkl6jd16lRNnjzZHiEBAACgBG4kj6vqOdzatWuVlpamhIQESdK5c+eK7WOxWLR69Wr5+flp3Lhx2r9/v+rVq6crV64oKytLOTk5GjJkiObPn6+goCBdvHhRbdu2VZs2bXTXXXfpySef1OrVq1WvXj2dOXNG99xzj9q3b6/FixerYcOGWr9+fYljAQAAeZVqZNeECRNkMpmKfO3fv1/vvPOOzp8/r4kTJ5YqmIkTJyo9Pd32Sk5OLlV/AAAAFMyeeVxVz+HMZrP27dun6OhoLVq0SK6ursX2iYuLs81n1rVrV0VFRelf//qXEhMTVaNGDR04cEC//PKLBg8eLIvFovbt2+v8+fNKSEjQ1q1bdeTIET3wwAOyWCzq1q2bJOnAgQNq27at1qxZo3HjxumLL76Qh4eHXY8dAABHZDIMwyhp49OnT+vs2bNFtmnUqJEGDhyoL7/8UiaTybY8JydHzs7OevTRRzVv3rwS7c9qtcrLy0vp6eny9PQsaZgAAACFulXzi/LM46riOb5w4YI2btyo2NhYffHFF4qLi5O3t7eSkpJksViUlpZWaF/DMLRr1y5t2rRJs2bN0iuvvKIWLVooIiJCx48fz9f+q6++0quvvqqtW7cWuL1z584pNjZWX331lfbs2aM9e/bI2dm5rA4VAIAqq6Q5RqmKXSV17NixPHM1nDhxQj169NDnn3+uNm3ayN/fv0TbqYqJEgAAqNzIL4pWFnlcVTvHKSkp8vb2loeHhy5fvqwmTZpo1apVCg0NLbbYlZ2draSkJDVp0kTS1RF0ly9f1uuvv64WLVroueees827dejQIfn4+MhkMik4OFiffPKJbVRXXFycgoODdfz4cd15552qVq2arFar6tatq99//11eXl7lci4AAKjMSppj2GXOrvr16+f5XKNGDUlS48aNS1zoAgAAQPm7FfO4+Ph4TZw4UYZhKDs7W1FRUQoNDVVoaKhOnz4tq9Uqf39/de7cWZ988omk/83ZVbt2bY0YMULnzp2Ti4uL6tSpo7lz58rFxUWrVq3S2LFjNXPmTOXk5MjX11cLFy7UnXfeqa+++krjx4/XuHHjdOXKFdWvX18rVqzQpk2bNGPGDDk7Oys7O1tvvPEGhS4AAErJLiO7/igpKUkNGzbUnj17ZLFYStyvqn0rCAAAKj/yi9K5kTyuMp7jxDMZWrwzWSmpmfL3dtfA8AA19GU+LAAAqpIKHdn1R4GBgSqHmhoAAADKmCPkcYt3JmvC0r0ymUwyDEMmk0mzvz2saf1DNSA8oKLDAwAAZaxUT2MEAAAAqpLEMxmasHSvcg0pJ9fI8x6zdK+SzmRUdIgAAKCMUewCAACAw1q8MznPkyWvZzKZtGhncjlHBAAA7I1iFwAAABxWSmpmobdhGoahlNTMco4IAADYG8UuAAAAOCx/b/ciR3b5e7uXc0QAAMDeKHYBAACgSrhw4YJ69OghX19f1apVq0R9BoYHFDmyaxAT1AMA4HAodgEAAKBKcHV1VUxMjGJjY0vcp6Gvh6b1D5WTSXJ2MuV5n9Y/VIG+HnaMGAAAVASXig4AAAAA+KPMzEwNGzZM8fHxcnV11e23367169erS5cuSkpKKtW2BoQHqFWgjxbtTFZKaqb8vd01KDyAQhcAAA6KYhcAAAAqnbVr1yotLU0JCQmSpHPnzhXbx2KxaPXq1fLz88u3LtDXQzE9g8o8TgAAUPlwGyMAAAAqHbPZrH379ik6OlqLFi2Sq6trsX3i4uIKLHQBAIBbC8UuAAAAVDqNGjVSQkKCevbsqS1btigkJESpqakVFk9pJsdfsWKFfvjhB9vnTZs2yWKx2DdAAABgQ7ELAAAAlU5KSopMJpMiIyM1ffp0GYah5OTkCounNJPj/7HYBQAAyhfFLgAAAFSIxDMZmrZ2v/7y6R5NW7tfiWcybOvi4+PVoUMHmc1mhYWFKSoqSqGhoQoNDVW7du1ktVrl7++vqKgoWx+LxaITJ05IklauXKnHH39cq1atUlBQkO666y7169dPVqu12LgyMzM1aNAgBQcHy2w2KyIiQm5uburSpUuxo7pWr16tlStX6o033pDFYtGcOXMkSdnZ2YqOjpbZbFbz5s21c+dOW59169bp3nvvVcuWLdW6dWt98803pTmNAADgD0yGYRgVHURhrFarvLy8lJ6eLk9Pz4oOBwAAOADyC/sryTlevDNZE5bulclkkmEYtvdp/UM1IDygTOK4cOGCGjdurG+//VZBQUF6+umn5e7urjfeeKPIfsuXL9esWbO0bt06SVcnx/fx8ZEkJSUlyWKxKC0tLU+f6yfHHzZsmCwWi8aOHSvp6m2M3bp105YtW9SmTRvNmjVLy5cv17p163TkyBE9+uijWrdunTw9PXXo0CF17NhRSUlJcnNzK5PzAACAoyhpHsfILgAAAJSrxDMZmrB0r3INKSfXyPMes3Svkq4b4VVSBY3GWrNmjcLCwhQUdPUpjNHR0fr000/z9c3IyJCPj4+uXLkiSXr55Ze1efNmRUdH691331XLli0lSV9//bUeeughnT9/Xs2bN9eHH35o28bTTz+tbt26yWKx6IsvvtDRo0fz7KNJkyZq06aNJKldu3Y6fPiwpKtPnTx06JDuu+8+WSwWPfzww3JyctKxY8dKfQ4AAMBVFLsAAABQrhbvTJbJZCpwnclk0qKdpZ+ba+3atUpLS1NCQoJ++uknffbZZzp27JgaNGhgaxMYGKiTJ08qOztb0v9ue/Tw8FBISIi2bdum1NRUOTk56Y477lCPHj20bNkynTlzRqmpqbrnnnv0+eefq2bNmvr+++/1j3/8QykpKZKkcePG6euvv1ZcXJz69OmjO+64I0981atXt/3Z2dnZFoNhGOrevbvi4uJsr+PHj+uuu+4q9TkAAABXUewCAABAuUpJzVRhM2kYhqGU1MxSb9NsNmvfvn2Kjo7WokWL5OrqWmyfuLg4+fn5SZK6deum2NhYbdy4Ue3atVPTpk3VsGFD1a5dW25ubkpOTtbZs2cVHR2t8+fPq0uXLjp79qx+/vlnSVLXrl0VFRWlf/3rX5KkS5culSjuHj16KDY2Vnv37rUt2759e2kPHwAAXIdiFwAAAMqVv7d7kSO7/L3dS73NRo0aKSEhQT179tSWLVsUEhKi+vXr57mdMCkpSfXq1ZOLi0u+/teKXbGxsfL399fevXvVs2dPLVu2zDY5flhYmLZt2ybDMHTmzBlVq1bNVtQ6cuSIxo0bpytXrmjjxo36z3/+o7CwMNsE9YVp0qSJFi5cqKeeekpms1nNmjXTW2+9VerjBwAA/8ME9QAA4JZCfmF/xZ3jxDMZ6vrmJuUWkIU6maSN4zop0NejVPtMSUmRt7e3PDw8dPnyZTVp0kRffvmlunfvru+++842QX316tU1ffp0WxyLdyYrJTVT9Txd9UbU/art4634+HgdOXJEvXv3Vq1atRQXFydJatmypZ5//nn1799f3333nTp37qylS5fqwQcfVFJSkpo0aSJJmjBhgi5fvqwZM2aU7sQBAIAilTSPy/+1FgAAAGBHDX09NK1/qGIKeRpjUYWu6wtU/t7uGhgeoIa+HoqPj9fEiRNlGIays7MVFRUls9msOXPmqG/fvsrOzlZISIjmzZsn6eq8YVG979cdAyfLuYaPTCaTLtduouq1XOTu7q7mzZvrypUr6tq1q23fr732mqKjozVlyhRZLBbbhPM5OTkaMWKEzp07JxcXF9WpU0dz586170kEAACFYmQXAAC4pZBf2F9Jz3HSmQwtuq5wNSg8oMhC1+KdyZpQSIFsQHhAieOzx8gyAABgf4zsAgAAQKUW6OuhmJ5BJWqbeCZDE5buvVqguvZd7X/fY5buVatAnxIXqGxPgyzgO99rT4MsaVwAAKDyYYJ6AAAAVHq2AlUBrhWoSsoeT4MEAACVB8UuAAAAVHplWaCyx9MgAQBA5UGxCwAAAJVeWRaoBoYHFFk4G1SK+b8AAEDlQ7ELAAAAlV5ZFqiuPQ3SySQ5O5nyvBf3NEgAAFD5MUE9AAAAKr1rBaqYQp7GWNoC1YDwALUK9CnV0yABAEDVQLELAAAAVUJZF6hK8zRIAABQdVDsAgAAQJVBgQoAABSHObsAAAAAAADgMCh2AQAAAAAAwGFQ7AIAAECFWrVqlYKCgnTXXXepX79+slqtFR0SAACowih2AQAAoMJcuHBBI0eO1IoVK3Tw4EH5+flpypQpFR0WAACowih2AQAAoFxkZmZq0KBBCg4OltlsVkREhNasWaOwsDAFBV2ddD46OlqffvppBUcKAACqMopdAAAAKBdr165VWlqaEhIS9NNPP+mzzz7TsWPH1KBBA1ubwMBAnTx5UtnZ2ZIki8WiEydOVFTIAACgCqLYBQAAgHJhNpu1b98+RUdHa9GiRXJ1dS22T1xcnPz8/MohOgAA4CgodgEAAKBcNGrUSAkJCerZs6e2bNmikJAQ1a9fX0ePHrW1SUpKUr169eTi4lKBkQIAgKqMYhcAAADKRUpKikwmkyIjIzV9+nQZhqGmTZtq9+7d2r9/vyTpvffe0+DBgys4UgAAUJVR7AIAAIBdzNzwqxLPZNg+x8fHq0OHDjKbzQoLC1NUVJTMZrPmzJmjvn37qkmTJkpJSdGLL75o63P9nF0rV67U448/Xu7HAQAAqhaTYRhGRQdRGKvVKi8vL6Wnp8vT07OiwwEAAA6A/ML+rp3jwGeXyFTNXdP6h2pAeEBFhwUAAKq4kuZxjOwCAACAXeTkGso1pJile5V03QgvAAAAe6rUM39eG3RmtVorOBIAAOAoruUVlXhwe5V37dzmZl2UJJmcTJr37T49071pRYYFAACquJLmcZX6NsaUlBQFBDDkHQAAlL3k5GT5+/tXdBgOiRwOAADYU3F5XKUuduXm5urEiROqWbOmTCZTvvVWq1UBAQFKTk6+5ebc4Ng5do791sGxc+wce9kyDEPnz5+Xn5+fnJyY0cEeyOEKx7Fz7Bz7rYNj59g59rJX0jyuUt/G6OTkVKJvXD09PW+5H6JrOHaO/VbDsXPstxqO3T7H7uXlZZft4ipyuOJx7Bz7rYZj59hvNRy7/Y69JHkcX2cCAAAAAADAYVDsAgAAAAAAgMOo0sUuNzc3vfzyy3Jzc6voUModx86x32o4do79VsOx35rHfqu4la8xx86x32o4do79VsOxV45jr9QT1AMAAAAAAAClUaVHdgEAAAAAAADXo9gFAAAAAAAAh0GxCwAAAAAAAA6DYhcAAAAAAAAcBsUuAAAAAAAAOIwqV+wKDAyUyWTK83rttdeK7HPp0iWNHj1atWvXVo0aNdS/f3/9/vvv5RRx2UhKStLIkSPVsGFDubu7q3Hjxnr55Zd1+fLlIvt16tQp3/kaNWpUOUV94959910FBgaqevXqatOmjbZv315k+yVLligoKEjVq1dXixYttHr16nKKtOxMnTpVrVq1Us2aNVW3bl317dtXBw4cKLLPxx9/nO/6Vq9evZwiLjuTJk3KdxxBQUFF9nGEay4V/HeayWTS6NGjC2xfla/5d999pz59+sjPz08mk0krVqzIs94wDL300kuqV6+e3N3d1a1bNx08eLDY7Zb274uKUNSxX7lyRTExMWrRooU8PDzk5+enxx57TCdOnChymzfye1MRirvuw4YNy3ccPXv2LHa7VeG6Iy9yOHK4gjjCv+fkcORw5HDkcORwlS+Hq3LFLkn6xz/+oZMnT9pef/nLX4ps/8wzz+jLL7/UkiVL9O233+rEiRPq169fOUVbNvbv36/c3FzNnj1bv/zyi2bOnKlZs2bp+eefL7bvE088ked8vf766+UQ8Y1btGiRnn32Wb388svavXu3zGazevTooVOnThXYfuvWrRoyZIhGjhypPXv2qG/fvurbt69+/vnnco785nz77bcaPXq0fvjhB23YsEFXrlxRRESEMjIyiuzn6emZ5/oePXq0nCIuW82bN89zHJs3by60raNcc0nasWNHnuPesGGDJGnAgAGF9qmq1zwjI0Nms1nvvvtugetff/11vf3225o1a5Z+/PFHeXh4qEePHrp06VKh2yzt3xcVpahjv3jxonbv3q0XX3xRu3fv1rJly3TgwAFFRkYWu93S/N5UlOKuuyT17Nkzz3F8+umnRW6zqlx35EcORw53PUf595wcjhyOHI4cjhyuEuZwRhXToEEDY+bMmSVun5aWZri6uhpLliyxLdu3b58hydi2bZsdIiw/r7/+utGwYcMi29x///3GX//61/IJqIy0bt3aGD16tO1zTk6O4efnZ0ydOrXA9gMHDjR69+6dZ1mbNm2Mp556yq5x2tupU6cMSca3335baJu5c+caXl5e5ReUnbz88suG2WwucXtHveaGYRh//etfjcaNGxu5ubkFrneUay7JWL58ue1zbm6ucccddxhvvPGGbVlaWprh5uZmfPrpp4Vup7R/X1QGfzz2gmzfvt2QZBw9erTQNqX9vakMCjr2oUOHGn/6059KtZ2qeN1BDnc9crirHPXfc3K4wjnqNTcMcjhyuKvI4YpWnte9So7seu2111S7dm2FhYXpjTfeUHZ2dqFtd+3apStXrqhbt262ZUFBQapfv762bdtWHuHaTXp6unx8fIptt2DBAvn6+iokJEQTJ07UxYsXyyG6G3P58mXt2rUrz/VycnJSt27dCr1e27Zty9Neknr06OEQ11dSsdf4woULatCggQICAvSnP/1Jv/zyS3mEV+YOHjwoPz8/NWrUSI8++qiOHTtWaFtHveaXL1/W/PnzNWLECJlMpkLbOco1v15iYqJ+++23PNfVy8tLbdq0KfS63sjfF1VFenq6TCaTatWqVWS70vzeVGabNm1S3bp1dffdd+vPf/6zzp49W2hbR77utwJyuKvI4a5y1H/PyeHI4QrjKNf8euRweZHDVZ4czqXMt2hnY8aM0T333CMfHx9t3bpVEydO1MmTJzVjxowC2//222+qVq1avh+222+/Xb/99ls5RGwfhw4d0jvvvKPp06cX2e6RRx5RgwYN5Ofnp7179yomJkYHDhzQsmXLyinS0jlz5oxycnJ0++2351l+++23a//+/QX2+e233wpsX5Wvb25ursaOHasOHTooJCSk0HZ33323PvroI4WGhio9PV3Tp09X+/bt9csvv8jf378cI745bdq00ccff6y7775bJ0+e1OTJk9WxY0f9/PPPqlmzZr72jnjNJWnFihVKS0vTsGHDCm3jKNf8j65du9Jc1xv5+6IquHTpkmJiYjRkyBB5enoW2q60vzeVVc+ePdWvXz81bNhQhw8f1vPPP68HHnhA27Ztk7Ozc772jnrdbwXkcFeRw/2PI/57Tg5HDlcYR7nmf0QO9z/kcJUrh6sUxa4JEyZo2rRpRbbZt2+fgoKC9Oyzz9qWhYaGqlq1anrqqac0depUubm52TvUMvf/27u/kKb6MA7gz2ttk25ctelWsbFpmoRSDRrzwv4sIguKLkpvqhdC6Y8XgUXdhFQQXURdeBEFsS66CG9CqAtpzhFYCdpG9gdpYymzWhBUhpal3/fiZSenczqtPB6+HxjMc347nmeP55wvv6Mzm9qTBgYGZMeOHbJv3z6pra3N+Nq6ujrleVlZmVitVvF6vRKNRqWwsHBuO09/zPHjx+X58+fT/u22x+MRj8ejfF1RUSGlpaVy/fp1uXDhwp/ezd+mqqpKeV5eXi5ut1vsdrs0NzfL4cOH53HP/q6bN29KVVWVrFixYsoxWuk5pffjxw/Zv3+/AJBr165lHKuV46ampkZ5XlZWJuXl5VJYWCjBYFC8Xu887hnNBDMcMxylYoZbmNeiuWKGI2Y49WU4VUx2NTQ0ZJwFFxFxOp1pl7vdbvn586e8efNGSkpKJq23WCwyMjIinz59SrkzmEgkxGKxzGW3f4tsa3/79q1s2bJFKioq5MaNG1l/P7fbLSL/31VUY1AymUyyaNGiSf9pKVO/LBZLVuPVrr6+Xu7duycPHz7M+i6PTqeT9evXSyQS+UN793cYjUYpLi6esg6t9VxEpK+vT/x+f9Z37LXS82TvEomEWK1WZXkikZB169alfc1szhdqlgxJfX19EggEMt4RTGe642ahcDqdYjKZJBKJpA1KWuv7QscM92/GMcxwzHAzpZXrOTPczGml58xwzHBJastwqvjMLrPZLGvWrMn40Ov1aV8bDoclJydH8vPz0653uVyi0+mkra1NWdbb2yv9/f0pM+vzJZvaBwYGZPPmzeJyucTn80lOTvbtC4fDIiIpJyI10ev14nK5Uvo1NjYmbW1tU/bL4/GkjBcRefDggSr6mw0AUl9fL3fv3pVAICAOhyPrbYyOjkpPT49q+ztTX79+lWg0OmUdWun5eD6fT/Lz82XXrl1ZvU4rPXc4HGKxWFL6+uXLF+ns7Jyyr7M5X6hVMiS9fv1a/H6/LF++POttTHfcLBTxeFw+fvw4ZR1a6rsWMMMxwyUxwzHDiTDDZUMrPWeGY4ZLUl2G++0fef8HPXr0CFevXkU4HEY0GsXt27dhNptx8OBBZUw8HkdJSQk6OzuVZUeOHIHNZkMgEEBXVxc8Hg88Hs98lDBr8XgcRUVF8Hq9iMfjePfunfIYP2Z87ZFIBOfPn0dXVxdisRhaWlrgdDpRWVk5X2XMyJ07d2AwGHDr1i28fPkSdXV1MBqNeP/+PQDgwIEDOHPmjDK+o6MDixcvxuXLl/Hq1Ss0NjZCp9Ohp6dnvkqYlaNHjyIvLw/BYDClv0NDQ8qYibWfO3cOra2tiEaj6O7uRk1NDXJzc/HixYv5KGHWGhoaEAwGEYvF0NHRgW3btsFkMuHDhw8AtNvzpNHRUdhsNpw+fXrSOi31fHBwEKFQCKFQCCKCK1euIBQKKf+t5tKlSzAajWhpacGzZ8+wZ88eOBwODA8PK9vYunUrmpqalK+nO1+oRabaR0ZGsHv3bqxatQrhcDjl+P/+/buyjYm1T3fcqEWm2gcHB3Hy5Ek8fvwYsVgMfr8fGzZswOrVq/Ht2zdlGwu17/QLMxwzHKDd6zkzHDMcMxwzHDOc+jLcgprs6u7uhtvtRl5eHnJzc1FaWoqLFy+mvJmxWAwigvb2dmXZ8PAwjh07hqVLl2LJkiXYu3dvSsBYCHw+H0Qk7SNpYu39/f2orKzEsmXLYDAYUFRUhFOnTuHz58/zVMXMNTU1wWazQa/XY+PGjXjy5ImybtOmTTh06FDK+ObmZhQXF0Ov12Pt2rW4f//+X97juZuqvz6fTxkzsfYTJ04o71NBQQF27tyJp0+f/v2dn6Pq6mpYrVbo9XqsXLkS1dXViEQiynqt9jyptbUVIoLe3t5J67TU8/b29rQ/48n6xsbGcPbsWRQUFMBgMMDr9U56T+x2OxobG1OWZTpfqEWm2pPn7nSP8deyibVPd9yoRabah4aGsH37dpjNZuh0OtjtdtTW1k4KPAu17/QLMxwzHKDd6zkzHDMcMxwzHDOc+jLcPwAwm98IIyIiIiIiIiIiUhtVfGYXERERERERERHR78DJLiIiIiIiIiIi0gxOdhERERERERERkWZwsouIiIiIiIiIiDSDk11ERERERERERKQZnOwiIiIiIiIiIiLN4GQXERERERERERFpBie7iIiIiIiIiIhIMzjZRUREREREREREmsHJLiIiIiIiIiIi0gxOdhERERERERERkWb8B5t6PbXdnop8AAAAAElFTkSuQmCC",
            "text/plain": [
              "<Figure size 1200x500 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "we = model.get_input_embeddings()\n",
        "emb_batch = we(batch[\"input_ids\"])\n",
        "specials = {\"[PAD]\", \"[CLS]\", \"[SEP]\"}\n",
        "X_static, X_context, labels = [], [], []\n",
        "\n",
        "B, L = batch[\"input_ids\"].shape\n",
        "for i in range(B):\n",
        "    ids_i = batch[\"input_ids\"][i].numpy()\n",
        "    toks_i = tok.convert_ids_to_tokens(ids_i)\n",
        "    for j, tj in enumerate(toks_i):\n",
        "        if tj in specials:\n",
        "            continue\n",
        "        X_static.append(emb_batch[i, j, :].numpy())\n",
        "        X_context.append(out.last_hidden_state[i, j, :].numpy())\n",
        "        labels.append(f\"s{i}:{tj}\")\n",
        "\n",
        "X_static = np.vstack(X_static)\n",
        "X_context = np.vstack(X_context)\n",
        "\n",
        "pca = PCA(n_components=2, random_state=42)\n",
        "X_all_2d = pca.fit_transform(np.vstack([X_static, X_context]))\n",
        "n = X_static.shape[0]\n",
        "X_static_2d = X_all_2d[:n]\n",
        "X_context_2d = X_all_2d[n:]\n",
        "\n",
        "\n",
        "xmin = np.min(np.vstack([X_static_2d[:,0], X_context_2d[:,0]]))\n",
        "xmax = np.max(np.vstack([X_static_2d[:,0], X_context_2d[:,0]]))\n",
        "ymin = np.min(np.vstack([X_static_2d[:,1], X_context_2d[:,1]]))\n",
        "ymax = np.max(np.vstack([X_static_2d[:,1], X_context_2d[:,1]]))\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(12, 5), constrained_layout=True)\n",
        "\n",
        "axes[0].scatter(X_static_2d[:, 0], X_static_2d[:, 1], s=25)\n",
        "axes[0].set_title(\"Embeddings statiques (PCA)\")\n",
        "axes[0].set_xlim(xmin, xmax); axes[0].set_ylim(ymin, ymax)\n",
        "for (x, y), lab in zip(X_static_2d, labels):\n",
        "    axes[0].annotate(lab, (x, y), fontsize=8, xytext=(3, 3), textcoords=\"offset points\")\n",
        "\n",
        "axes[1].scatter(X_context_2d[:, 0], X_context_2d[:, 1], s=25)\n",
        "axes[1].set_title(\"Embeddings contextuels (PCA)\")\n",
        "axes[1].set_xlim(xmin, xmax); axes[1].set_ylim(ymin, ymax)\n",
        "for (x, y), lab in zip(X_context_2d, labels):\n",
        "    axes[1].annotate(lab, (x, y), fontsize=8, xytext=(3, 3), textcoords=\"offset points\")\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O9jNj6FMuOGi"
      },
      "source": [
        "La cellule suivante illustre, pour le token 'alice', la distribution d'attention sur tous les tokens de la phrase, couche par couche, pour la phrase 1 à gauche et la phrase 2 à droite. Bien sûr les phrases sont courtes et assez proches et on a vu que la similarité cosinus est à peu près 0.904 la similarité des vecteurs reste très proche au fur et à mesure des couches. Par contre si on regarde attentivement les plots on pourra constater une très légère différence et notamment sur la dernière couche."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0pFxTAhjxFNQ"
      },
      "outputs": [],
      "source": [
        "out_att = model(batch, output_attentions=True)\n",
        "atts = out_att.attentions\n",
        "num_layers = len(atts)\n",
        "\n",
        "tokens0 = tok.convert_ids_to_tokens(batch[\"input_ids\"][0].numpy())\n",
        "tokens1 = tok.convert_ids_to_tokens(batch[\"input_ids\"][1].numpy())\n",
        "a0 = tokens0.index('alice')\n",
        "a1 = tokens1.index('alice')\n",
        "\n",
        "mats0, mats1 = [], []\n",
        "for l in range(num_layers):\n",
        "    A0 = atts[l][0].numpy().mean(axis=0)\n",
        "    A1 = atts[l][1].numpy().mean(axis=0)\n",
        "    mats0.append(A0); mats1.append(A1)\n",
        "\n",
        "vmax = np.quantile(np.concatenate([m.ravel() for m in (mats0+mats1)]), 0.95)\n",
        "fig, axes = plt.subplots(num_layers, 2, figsize=(10, 2.8*num_layers),\n",
        "                         constrained_layout=True)\n",
        "\n",
        "for l in range(num_layers):\n",
        "    for col, (A, tokens, a_idx, title) in enumerate([\n",
        "        (mats0[l], tokens0, a0, \"Phrase 1\"),\n",
        "        (mats1[l], tokens1, a1, \"Phrase 2\"),\n",
        "    ]):\n",
        "        ax = axes[l, col] if num_layers > 1 else axes[col]\n",
        "        im = ax.imshow(A, vmin=0, vmax=vmax, interpolation=\"nearest\")\n",
        "        ax.set_title(f\"Couche {l} — {title}\")\n",
        "        ax.set_xticks(range(len(tokens))); ax.set_xticklabels(tokens,\n",
        "                                                              rotation=90,\n",
        "                                                              fontsize=8)\n",
        "        ax.set_yticks(range(len(tokens))); ax.set_yticklabels(tokens,\n",
        "                                                              fontsize=8)\n",
        "        ax.set_xlabel(\"clé (key)\"); ax.set_ylabel(\"requête (query)\")\n",
        "        ax.axhline(a_idx-0.5, color='r'); ax.axhline(a_idx+0.5, color='r')\n",
        "        ax.axvline(a_idx-0.5, color='r'); ax.axvline(a_idx+0.5, color='r')\n",
        "\n",
        "cbar = fig.colorbar(im, ax=axes.ravel().tolist(), shrink=0.85)\n",
        "cbar.set_label(\"poids d'attention (softmax par ligne)\")\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eYriVLKAyhNm"
      },
      "source": [
        "## Et si on revenait sur les tokens ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6zfa0QgCym86"
      },
      "source": [
        "Si vous avez bien essayé de changer de phrases précédemment vous avez constaté que le texte n'est pas découpé en mots entiers mais en sous-mots. En plus, un mot entier peut devenir plusieurs sous-tokens.  Si par exemple vous revenez en arrière et que vous essayez  \"Emmanuel Macron\" vous obtiendrez :\n",
        "```python\n",
        "['[CLS]', 'emmanuel', 'macro', '##n', '[SEP]']  \n",
        "```\n",
        "le préfixe `##` indique tout simplement qu'un sous-token est la suite d'un mot déjà commencé (ici 'macro', '##n' pour \"macron\"). On découpe les mots en morceaux fréquents pour limiter la taille du vocabulaire : ainsi, même un mot rare ou nouveau peut être représenté en combinant ces morceaux (par exemple 'macro' + '##n').\n",
        "\n",
        "BERT/DistilBERT utilisent bien entendu des tokens particuliers :\n",
        "\n",
        "- `[CLS]` : inséré au début d'une séquence. Ce token est très important car il est souvent utilisé comme un \"résumé\" de la séquence pour des tâches comme la classification.\n",
        "- `[SEP]` : séparateur de segments et marqueur de fin de séquence.\n",
        "- `[PAD]` : remplissage pour obtenir des lots de séquences de même longueur (ignoré par l'attention via le masque). Nous avons eu l'occasion de le voir précédemment\n",
        "- `[MASK]` : utilisé pendant le pré-entraînement (MLM) pour demander au modèle de prédire un token manquant. Pour l'instant nous ne l'avons pas encore vu ... mais cela va arrivé\n",
        "- `[UNK]` : token “inconnu” quand un symbole n'est pas dans le le vocabulaire. Par exemple si précédemment vous avez mis des emojis ou des mots peu utilisés, vous vous êtes peut être rendu compte que le modèle ne les connaissait pas.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gH_dD4lcLepe"
      },
      "source": [
        "## Et au final comment on résume la séquence si on veut faire de la classification ?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q-p8DB-sMhpD"
      },
      "source": [
        "Si on a envie de faire de la classification, par exemple dire que \"Alice sees the white rabbit\" est positive. Si on regarde en entrée après la tokenisation  on va avoir :   \n",
        "```python\n",
        "['[CLS]', 'alice', 'sees', 'the', 'white', 'rabbit', '[SEP]']\n",
        "ids: [101, 5650, 5927, 1996, 2317, 10442, 102]\n",
        "```   \n",
        "\n",
        "Nous avons vu précédemment que pour alice avec son id=5650 on obtenait en sortie un vecteur de dimension 768 qui représentait l'embedding contextuel d'alice. Maintenant qu'est ce qui se passe si je donne en entrée les tokens de la phrase."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "QmGHOz8jwHVs"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFDistilBertModel: ['vocab_transform.weight', 'vocab_projector.bias', 'vocab_transform.bias', 'vocab_projector.weight', 'vocab_layer_norm.bias', 'vocab_layer_norm.weight']\n",
            "- This IS expected if you are initializing TFDistilBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFDistilBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the weights of TFDistilBertModel were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertModel for predictions without further training.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "last_hidden_state shape: (1, 7, 768)\n",
            "H shape: (7, 768)\n"
          ]
        }
      ],
      "source": [
        "text = [\"Alice sees the white rabbit\"]\n",
        "b = tok(text, padding=False, truncation=True, return_tensors=\"tf\")\n",
        "\n",
        "model = TFDistilBertModel.from_pretrained(\"distilbert-base-uncased\",\n",
        "                                          from_pt=True)\n",
        "\n",
        "out = model(b)\n",
        "H = out.last_hidden_state[0]\n",
        "print(\"last_hidden_state shape:\", out.last_hidden_state.shape)\n",
        "print(\"H shape:\", H.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UDlm0OjJ0az7"
      },
      "source": [
        "Jusque là c'est cohérent par rapport à ce qu'on a vu précédemment. `last_hidden_state shape: (1, 7, 768)` indique bien qu'on a 1 batch. Le 7 c'est parce qu'on a enlevé le padding lors de la tokenization et donc on retrouve bien les 5 mots de la phrase plus les 2 tokens spéciaux. Le 768 indique la taille de l'embeddings. Mais de quel embedding parlons nous ?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "CZ6Vdj330bjy"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tokens et tailles des vecteurs (hors CLS/SEP) :\n",
            "position= 1  - token=' alice ' - shape = (768,)\n",
            "position= 2  - token=' sees ' - shape = (768,)\n",
            "position= 3  - token=' the ' - shape = (768,)\n",
            "position= 4  - token=' white ' - shape = (768,)\n",
            "position= 5  - token=' rabbit ' - shape = (768,)\n"
          ]
        }
      ],
      "source": [
        "tokens = tok.convert_ids_to_tokens(b[\"input_ids\"][0].numpy())\n",
        "\n",
        "print(\"Tokens et tailles des vecteurs (hors CLS/SEP) :\")\n",
        "for i, t in enumerate(tokens):\n",
        "    if t not in (\"[CLS]\", \"[SEP]\"):\n",
        "      print(\"position=\",i,\" - token='\", t, \"' - shape =\", H[i].shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "15hxhPeo1H-z"
      },
      "source": [
        "Le 768 indique bien la taille des vecteurs associés à chacun des tokens de la phrase. Donc jusque là c'est cohérent avec ce qu'on a vu. Mais qu'est-ce qu'il y a dans `CLS` et `SEP` ? qu'est ce qu'on devrait voir si on affiche le shape ?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "CNGRGas42Y1Z"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CLS shape: (768,)\n",
            "SEP shape: (768,)\n"
          ]
        }
      ],
      "source": [
        "print(\"CLS shape:\", H[0].shape)\n",
        "print(\"SEP shape:\", H[-1].shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "clXsw2Ne2i5q"
      },
      "source": [
        "Ce sont aussi des vecteurs de taille 768 ! ça ressemble quand même pas mal à des embeddings ...."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "KLRL4suk3Rxn"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Vecteur [CLS] en sortie (768 dim, les 16 premières composantes) :\n",
            "[-0.37423888 -0.11635411 -0.17278992 -0.13452822  0.0334477  -0.10951696\n",
            "  0.45915285  0.51172864 -0.47904927 -0.15388729 -0.07558388 -0.18886037\n",
            " -0.13793252  0.13869378 -0.03176897 -0.00916631]\n",
            "\n",
            "Vecteur [SEP] en sortie (768 dim, les 16 premières composantes) :\n",
            "[ 1.0868095   0.31373644 -0.3364039   0.43608862 -0.27049065 -0.66467243\n",
            "  0.47608978 -0.3583461   0.20755273  0.11485595  0.08928521 -0.29727733\n",
            "  0.30010533 -0.42660058 -0.82070196 -0.38893107]\n"
          ]
        }
      ],
      "source": [
        "cls_idx, sep_idx = 0, len(tokens)-1\n",
        "vec_cls = H[cls_idx].numpy()\n",
        "vec_sep = H[sep_idx].numpy()\n",
        "\n",
        "print(\"\\nVecteur [CLS] en sortie (768 dim, les 16 premières composantes) :\")\n",
        "print(vec_cls[:16])\n",
        "\n",
        "print(\"\\nVecteur [SEP] en sortie (768 dim, les 16 premières composantes) :\")\n",
        "print(vec_sep[:16])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s_QeD3_G37Bw"
      },
      "source": [
        "Mais on a des embeddings en entrée du modèles pour `CLS` et `SEP` ?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "sRYdsEii4BwR"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Vecteur [CLS] en entrée (768 dim, 16 premières composantes) :\n",
            "[ 0.34693524 -0.16263762 -0.23334563 -0.06168314 -0.14036657 -0.08204005\n",
            " -0.01083707 -0.08484276 -0.13732746 -0.28880566  0.17260072  0.02582683\n",
            " -0.08657839 -0.16488114 -0.46988603  0.18755344]\n",
            "\n",
            "Vecteur [SEP] en entrée (768 dim, 16 premières composantes) :\n",
            "[-0.17445761 -0.37202492 -0.40032977 -0.14501996 -0.64092773 -0.5473526\n",
            " -1.0121826   0.40292335 -0.09905099 -0.44566876 -0.11997008 -0.63533896\n",
            " -0.13592392  0.55962783 -0.21660006  0.35985246]\n"
          ]
        }
      ],
      "source": [
        "# Embeddings d'entrée (statiques)\n",
        "we = model.get_input_embeddings()\n",
        "E  = we(b[\"input_ids\"])[0]\n",
        "\n",
        "# Indices de [CLS] et [SEP]\n",
        "tokens = tok.convert_ids_to_tokens(b[\"input_ids\"][0].numpy())\n",
        "cls_idx = 0\n",
        "sep_idx = len(tokens) - 1\n",
        "\n",
        "# Vecteurs d'entrée pour [CLS] et [SEP]\n",
        "vec_cls_input = E[cls_idx].numpy()\n",
        "vec_sep_input = E[sep_idx].numpy()\n",
        "\n",
        "print(\"\\nVecteur [CLS] en entrée (768 dim, 16 premières composantes) :\")\n",
        "print(vec_cls_input[:16])\n",
        "\n",
        "print(\"\\nVecteur [SEP] en entrée (768 dim, 16 premières composantes) :\")\n",
        "print(vec_sep_input[:16])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OAssO1KG3VAi"
      },
      "source": [
        "Précédemment on a vu notamment avec 'alice' qu'on avait des embeddings statiques (ceux du début du modèle) et des embeddings contextuels (ceux à la sortie). Qu'est ce que ça donne pour `CLS` et `SEP` ? est-ce qu'ils sont égaux ?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "o6lqqV6p23px"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cosine([CLS] entrée vs sortie) : 0.289\n",
            "Cosine([SEP] entrée vs sortie)  : -0.022\n"
          ]
        }
      ],
      "source": [
        "def cosine(a, b):\n",
        "    return float(np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b) + 1e-9))\n",
        "\n",
        "\n",
        "cos_cls_in_out = cosine(vec_cls_input, vec_cls)\n",
        "cos_sep_in_out = cosine(vec_sep_input, vec_sep)\n",
        "\n",
        "print(\"Cosine([CLS] entrée vs sortie) :\", round(cos_cls_in_out, 3))\n",
        "print(\"Cosine([SEP] entrée vs sortie)  :\", round(cos_sep_in_out, 3))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7-ytUBsc7NOu"
      },
      "source": [
        "On constate que les embeddings statiques (ceux de l'entrée) sont bien différents des embeddings contextuels (ceux de sortie). Le modèle append donc dans ces différentes couches de nouveaux embeddings !!!     \n",
        "\n",
        "Comme on vient de le voir, au début, `[CLS]` et `[SEP]` sont des tokens comme les autres : chacun a un embedding de vocabulaire et un embedding de position. Après chaque couche du Transformer, leurs vecteurs sont mis à jour par l'auto-attention et les MLP, exactement comme pour les autres tokens.\n",
        "\n",
        "Ce qui rend `[CLS]` très particulier, c'est sa position et son rôle : Il est toujours placé en tout début de séquence (position 0), il 'reçoit' de l'information des autres tokens via l'auto-attention.    \n",
        "À chaque couche, une partie des poids d'attention des autres tokens pointe vers `[CLS]` (et réciproquement). Au fil des couches, le vecteur de `[CLS]` se remplit donc d'un mélange pondéré d'indices provenant de toute la phrase. En résumé, en sortie, le vecteur de `[CLS]` donne une vue globale de la phrase. C'est pourquoi on se sert de lui généralement via `last_hidden_state[:, 0, :]` (position de `[CLS]`) comme d'une représentation de la phrase (une sorte de résumé) que l'on peut brancher sur une petite tête de classification (une ou deux couches denses).\n",
        "\n",
        "`[SEP]` sert surtout de marqueur de fin (et de séparateur quand on a deux segments). Il a aussi un vecteur 768 en sortie, contextualisé, mais on l'utilise rarement comme résumé. Il est plutôt utilisé lorsque l'on a des tâches à deux phrases\n",
        "l'inférence textuelle (NLI) (décider si une phrase implique/contredit ou est neutre par rapport à une autre) ou bien dans les tâches de question-reponse extractive (trouver dans le texte le segment qui répond à la question).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dNSrF73nKiRG"
      },
      "source": [
        "## Au fait il y a quoi dans les modèles récupérés ?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DO0kkjC0KmXh"
      },
      "source": [
        "Précédemment, nous avons utilisé le modèle pré-entraîné : `TFDistilBertModel.from_pretrained(\"distilbert-base-uncased\", from_pt=True)`, nous avons un peu regardé les entrées et les sorties pour mieux comprendre et bien voir notamment les embeddings statiques et les embeddings contextuels. De manière générale, lorsque l'on utilise un modèle il est préférable de savoir également ce qu'il y a à l'intérieur. C'est une bonne habitude à prendre. On peut bien entendu regarder la doc mais on peut aussi afficher pas mal d'informations. Par exemple de nombreux modèles contiennent un `.config` qui décrit l'architecture du modèle."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "uNI_fdWcLhav"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFDistilBertModel: ['vocab_transform.weight', 'vocab_projector.bias', 'vocab_transform.bias', 'vocab_projector.weight', 'vocab_layer_norm.bias', 'vocab_layer_norm.weight']\n",
            "- This IS expected if you are initializing TFDistilBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFDistilBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the weights of TFDistilBertModel were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertModel for predictions without further training.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "vocab_size: 30522\n",
            "hidden_size (dim): 768\n"
          ]
        }
      ],
      "source": [
        "model_name = \"distilbert-base-uncased\"\n",
        "tok = DistilBertTokenizerFast.from_pretrained(model_name)\n",
        "m = TFDistilBertModel.from_pretrained(model_name, from_pt=True)\n",
        "\n",
        "# Utilisation de .config\n",
        "cfg = m.config\n",
        "print(\"vocab_size:\", cfg.vocab_size)\n",
        "print(\"hidden_size (dim):\", cfg.dim)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q04o6reQL-DF"
      },
      "source": [
        "On voit par exemple que la taille du vocabulaire est de 30522 et que que la dimension des vecteurs est de 768. Cela veut dire qu'on est capable de connaitre la taille de la matrice des embeddings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "4hYPT485MNgg"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Word embeddings matrix shape: (30522, 768)\n"
          ]
        }
      ],
      "source": [
        "we = m.get_input_embeddings()\n",
        "W  = we.weights[0].numpy()\n",
        "print(\"Word embeddings matrix shape:\", W.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "92pA-kmZOLF2"
      },
      "source": [
        "Il s'agit de la matrice des embeddings statiques. On peut voir par exemple que chaque ligne va correspondre à un token et que pour chaque token on a un vecteur de 768 dimensions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "b2RN64G8Oa4I"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Taille du vocabulaire  30522\n",
            "Le token CLS est normalement à la position 101  [CLS]\n",
            "Le token SEP est normalement à la position 102  [SEP]\n"
          ]
        }
      ],
      "source": [
        "vocab = tok.get_vocab()\n",
        "print (\"Taille du vocabulaire \",len(vocab) )\n",
        "\n",
        "id2tok = {i: t for t, i in vocab.items()}\n",
        "\n",
        "print (\"Le token CLS est normalement à la position 101 \", id2tok[101])\n",
        "print (\"Le token SEP est normalement à la position 102 \", id2tok[102])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pmrskbojPWZE"
      },
      "source": [
        "C'est intéressant de voir les 10 premiers tokens."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "APA0nUUqPXM8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Les 10 premiers tokens  ['[PAD]', '[unused0]', '[unused1]', '[unused2]', '[unused3]', '[unused4]', '[unused5]', '[unused6]', '[unused7]', '[unused8]']\n"
          ]
        }
      ],
      "source": [
        "print(\"Les 10 premiers tokens \",[id2tok[i] for i in range(10)])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yIT7omnuQEmh"
      },
      "source": [
        "Il est possible de voir le nombre de places réservées pour les unused. Elle dépend bien entendu du vocabulaire utilisé (ici `bert-base-uncased`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "geEC5CusQFrc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Nombre de [unusedX]: 994\n"
          ]
        }
      ],
      "source": [
        "vocab = tok.get_vocab()  # dict: token -> id\n",
        "unused_tokens = [t for t in vocab if t.startswith(\"[unused\")]\n",
        "print(\"Nombre de [unusedX]:\", len(unused_tokens))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7JxhrE7eR31i"
      },
      "source": [
        "En fait ces \"unused\" sont des emplacements vides prévus d'avance dans le vocabulaire (c'est un héritage historique de BERT). La tokenisation standard ne les produit jamais. Par contre à l'époque ils servaient à pouvoir définir facilement de nouveaux symboles propres à un domaine (par exemple \"<CHEM_DRUG>\" en biomédical) sans changer la taille du vocabulaire et en conservant la même taille des embeddings. Avant, on bricolait un peu : On avait une étape de prétraitement pendant laquelle on remplaçait le symbole par par exemple \"[unused123]\". Comme ce jeton existe dans le vocabulaire, le tokenizer le laissait tel quel et renvoyait son ID dédié. On avait donc une ligne d'embedding réservée qu'on affinait avec du fine tuning.    \n",
        "\n",
        "Maintenant c'est beaucoup plus simple. Il existe une fonction `add_tokens`:\n",
        "```python\n",
        "tok = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
        "tok.add_special_tokens({\"additional_special_tokens\": [\"<CHEM_DRUG>\"]})\n",
        "```\n",
        "qui va automatiquement ajouter le token au vocabulaire. Par contre il ne faut pas oublier de donner au modèle l'information qu'il y a une nouvelle ligne :\n",
        "```python\n",
        "model = TFDistilBertModel.from_pretrained(\"distilbert-base-uncased\", from_pt=True)\n",
        "model.resize_token_embeddings(len(tok))\n",
        "```\n",
        "\n",
        "Ensuite il suffit de remplacer dans le texte :\n",
        "```python\n",
        "text = text.replace(nom_de_molecule, \"<CHEM_DRUG>\")\n",
        "```\n",
        "et de fine tuner le modèle pour qu'il puisse apprendre les embeddings.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cnO-FY5BVvfh"
      },
      "source": [
        "Regardons, à présent plus en détail, l'architecture du modèle. Pour rappel tous les composants sont expliqués dans [Guide pratique de l'Apprentissage Profond de Données textuelles](https://gite.lirmm.fr/poncelet/deeplearning)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eSEKL0-KVwFl"
      },
      "outputs": [],
      "source": [
        "print(\"n_layers:\", cfg.n_layers)\n",
        "print(\"n_heads:\", cfg.n_heads)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "52GOhvbbWhH5"
      },
      "source": [
        "`n_layers: 6` signifie qu'il y a 6 blocs Transformer empilés les uns au-dessus des autres. Pour rappel, à chaque bloc, on applique une auto-attention multi-têtes, puis un petit réseau feed-forward (MLP) avec normalisations entre les deux.  \n",
        "\n",
        "`n_heads: 12` indique, dans chaque bloc, l'auto-attention est faite par 12 “têtes” en parallèle. Pour rappel, une tête d'attention est un sous-espace qui apprend son propre motif d'attention (qui regarde qui) et ses propres projections. Concrètement, le vecteur caché de taille 768 est découpé en 12 sous-vecteurs (768 / 12 = 64 dimensions par tête). Chaque tête calcule sa matrice d'attention (L x L) et produit sa sortie. On concatène ensuite les 12 sorties (12 x 64 = 768) et on repasse par une projection linéaire.    \n",
        "\n",
        "Enfin regardons ce que le modèle peut apprendre."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "26N9w0ULWl7o"
      },
      "outputs": [],
      "source": [
        "print(\"max_position_embeddings :\", cfg.max_position_embeddings)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BMYed5OJYncR"
      },
      "source": [
        "`max_position_embeddings : 512` indique que le modèle possède des embeddings de position appris pour les positions 0 à 511, donc en gros il ne sait traiter que des séquences jusqu'à 512 tokens (y compris les tokens spéciaux)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ulmFrTY_-uo5"
      },
      "source": [
        "## et donc au dessus de BERT/DistilBERT on peut réaliser différentes tâches"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QnMKy9sM_OF9"
      },
      "source": [
        "Maintenant nous connaissons bien les entrées du modèle, nous savons ce qu'il produit, il suffit de récupérer les sorties et de les spécialiser sur une tâche donnée. C'est d'ailleurs ce que nous allons faire juste après pour faire le tuning et la classification de nos tweets.   \n",
        "\n",
        "Comme dit précédemment il existe déjà de nombreuses extensions qui ont été définies pour différentes tâches. Nous illustrons ici un exemple de question-réponse. Vous pouvez trouver de plus amples informations à [DistilBertForQuestionAnswering](https://huggingface.co/docs/transformers/model_doc/distilbert).   \n",
        "\n",
        "Le principe général est le suivant : on donne un contexte d'une ou plusieurs phrases et on pose une question et le modèle doit trouver le segment de texte pour répondre à la question. Il s'agit question-réponse extractive (la réponse est dans le texte). A votre avis qu'elle va être la sortie du tokenizer ?\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "3jZu-iKJKV-W"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "All PyTorch model weights were used when initializing TFDistilBertForQuestionAnswering.\n",
            "\n",
            "All the weights of TFDistilBertForQuestionAnswering were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertForQuestionAnswering for predictions without further training.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "input_ids[0]: [101, 1130, 1134, 1331, 1110, 1103, 142, 11093, 1883, 5646, 136, 102, 1109, 142, 11093, 1883, 5646, 1110, 170, 20533, 118, 3926, 19843, 3590, 1113, 1103, 24705, 8223, 1260, 7403, 1107, 2123, 117, 1699, 119, 1135, 1110, 1417, 1170, 1103, 3806, 13829, 1162, 142, 11093, 1883, 117, 2133, 1419, 2011, 1105, 1434, 1103, 3590, 119, 102]\n",
            "attention_mask[0]: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "\n",
            "tokens: ['[CLS]', 'In', 'which', 'city', 'is', 'the', 'E', '##iff', '##el', 'Tower', '?', '[SEP]', 'The', 'E', '##iff', '##el', 'Tower', 'is', 'a', 'wrought', '-', 'iron', 'lattice', 'tower', 'on', 'the', 'Cha', '##mp', 'de', 'Mars', 'in', 'Paris', ',', 'France', '.', 'It', 'is', 'named', 'after', 'the', 'engineer', 'Gustav', '##e', 'E', '##iff', '##el', ',', 'whose', 'company', 'designed', 'and', 'built', 'the', 'tower', '.', '[SEP]']\n"
          ]
        }
      ],
      "source": [
        "model_id = \"distilbert-base-cased-distilled-squad\"\n",
        "tok = DistilBertTokenizerFast.from_pretrained(model_id)\n",
        "qa_model = TFDistilBertForQuestionAnswering.from_pretrained(model_id, from_pt=True)\n",
        "\n",
        "context = (\n",
        "    \"The Eiffel Tower is a wrought-iron lattice tower on the Champ de Mars in Paris, France. \"\n",
        "    \"It is named after the engineer Gustave Eiffel, whose company designed and built the tower.\"\n",
        ")\n",
        "question = \"In which city is the Eiffel Tower?\"\n",
        "\n",
        "# Attention il faut une tokenisation conjointe (question + contexte)\n",
        "# avec question en premier\n",
        "inputs = tok(question, context, return_tensors=\"tf\")\n",
        "\n",
        "print(\"\\ninput_ids[0]:\", inputs[\"input_ids\"][0].numpy().tolist())\n",
        "print(\"attention_mask[0]:\", inputs[\"attention_mask\"][0].numpy().tolist())\n",
        "\n",
        "tokens = tok.convert_ids_to_tokens(inputs[\"input_ids\"][0].numpy())\n",
        "print(\"\\ntokens:\", tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mo0ZwS28L1MP"
      },
      "source": [
        "Vérifiez bien que vous retrouvez l'ordre [CLS] question [SEP] contexte [SEP]. Vous pouvez constater qu'ici le `SEP` est important car il permet de séparer la question du contexte.   \n",
        "\n",
        "Maintenant examinons un peu à quoi ressemble le modèle `TFDistilBertForQuestionAnswering`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "ydMC6gsdMbgO"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"distilbert_qa_probe\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " attention_mask (InputLayer  [(None, 512)]                0         []                            \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " input_ids (InputLayer)      [(None, 512)]                0         []                            \n",
            "                                                                                                  \n",
            " distilbert (TFDistilBertMa  TFBaseModelOutput(last_hid   6519091   ['attention_mask[0][0]',      \n",
            " inLayer)                    den_state=(None, 512, 768)   2          'input_ids[0][0]']           \n",
            "                             , hidden_states=None, atte                                           \n",
            "                             ntions=None)                                                         \n",
            "                                                                                                  \n",
            " dropout_190 (Dropout)       (None, 512, 768)             0         ['distilbert[0][0]']          \n",
            "                                                                                                  \n",
            " qa_outputs (Dense)          (None, 512, 2)               1538      ['dropout_190[0][0]']         \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 65192450 (248.69 MB)\n",
            "Trainable params: 65192450 (248.69 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "max_len = int(qa_model.config.max_position_embeddings)\n",
        "ids  = layers.Input(shape=(max_len,), dtype=\"int32\", name=\"input_ids\")\n",
        "mask = layers.Input(shape=(max_len,), dtype=\"int32\", name=\"attention_mask\")\n",
        "\n",
        "\n",
        "hs = qa_model.distilbert({\"input_ids\": ids,\n",
        "                          \"attention_mask\": mask}).last_hidden_state\n",
        "x  = qa_model.dropout(hs, training=False)\n",
        "logits = qa_model.qa_outputs(x)\n",
        "\n",
        "probe = Model([ids, mask], logits, name=\"distilbert_qa_probe\")\n",
        "probe.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ejHCsUoRMoDW"
      },
      "source": [
        "Quelle est la taille max de la séquence ? est-ce que la sortie de DistilBERT est cohérente par rapport à ce qu'on a vu précédemment ? qu'est ce qui a été ajouté à DistilBERT comme couche ? A quoi peut bien correspondre ce 2 à la fin ... pourquoi 2 neurones dans une couche dense ? on voit bien qu'on n'est pas dans une classification binaire où un seul neurone aurait suffit. Un softmax ? exécutons le modèle et regardons le contenu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "lHS3SbtYPG5c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TFQuestionAnsweringModelOutput(loss=None, start_logits=<tf.Tensor: shape=(1, 56), dtype=float32, numpy=\n",
            "array([[-2.8800519 , -4.2360897 , -4.2209425 , -4.846825  , -6.8204527 ,\n",
            "        -6.676594  , -5.9700346 , -7.934163  , -8.052275  , -7.1487226 ,\n",
            "        -2.9255483 , -3.8886015 ,  0.03559253,  0.07242871, -5.716035  ,\n",
            "        -5.236798  , -3.629495  , -4.587263  , -4.1062455 , -4.3270593 ,\n",
            "        -7.523342  , -6.1801734 , -4.847396  , -4.6768737 , -1.099898  ,\n",
            "        -0.7151666 ,  1.7737529 , -3.3785446 , -2.3539171 , -0.52278095,\n",
            "         0.747377  ,  9.168143  , -2.160038  ,  6.6135597 , -2.133919  ,\n",
            "        -1.897194  , -5.8638268 , -4.3044233 , -6.132346  , -4.915492  ,\n",
            "        -4.211172  , -2.5242524 , -5.830143  , -4.639802  , -7.322645  ,\n",
            "        -6.379161  , -6.8103495 , -6.8268814 , -6.5157876 , -6.348951  ,\n",
            "        -8.367348  , -6.7516427 , -5.469288  , -5.7258496 , -5.615058  ,\n",
            "        -3.8886044 ]], dtype=float32)>, end_logits=<tf.Tensor: shape=(1, 56), dtype=float32, numpy=\n",
            "array([[-1.7244767, -5.7841787, -5.0008607, -4.5587792, -7.0597234,\n",
            "        -7.706837 , -7.444765 , -7.4021015, -7.1172595, -5.905372 ,\n",
            "        -3.6636355, -4.3909903, -5.312986 , -5.420287 , -5.3516765,\n",
            "        -3.5855622, -1.4898404, -5.579587 , -6.476933 , -6.136352 ,\n",
            "        -7.5604367, -5.170817 , -4.685433 , -3.1251729, -5.2864213,\n",
            "        -4.8077636, -3.5080962, -2.7685797, -3.4925978,  2.6742575,\n",
            "        -1.9619595,  9.281073 ,  0.9685456,  9.187542 ,  4.510574 ,\n",
            "        -4.1099916, -5.906549 , -4.973392 , -5.852061 , -6.2113633,\n",
            "        -4.448081 , -5.505874 , -5.234852 , -6.406042 , -5.6700234,\n",
            "        -2.6877549, -2.8457663, -6.0979323, -5.342715 , -6.2034483,\n",
            "        -7.6022973, -6.137686 , -6.7913156, -3.4656715, -2.018052 ,\n",
            "        -4.3909326]], dtype=float32)>, hidden_states=None, attentions=None)\n"
          ]
        }
      ],
      "source": [
        "outputs = qa_model(inputs)\n",
        "print (outputs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jeV5Fx1zPvzu"
      },
      "source": [
        "On voit que le modèle retourne deux vecteurs : `start_logits` et `end_logits`. Chacun d'eux a une dimension de 56. A quoi peuvent ils bien servir ? Le 56 c'est facile : le tokenizer a traduit la phrase en 56 tokens. Là ça veut donc dire que pour chaque token on a une valeur.     \n",
        "\n",
        "En fait, le modèle calcule, pour chaque position 0 .. 55, deux scores (non normalisés) :  \n",
        "- start_logits[i] : \"à quel point le token i est un début plausible de réponse ?\"\n",
        "- end_logits[i] : \"à quel point le token i est une fin plausible de réponse ?\"   \n",
        "\n",
        "Et comment on s'en sert ? tout simplement en transformant ces logits en probabilités (softmax)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "xuG6rMTCRbos"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Question : In which city is the Eiffel Tower?\n",
            "Réponse : Paris\n"
          ]
        }
      ],
      "source": [
        "outputs = qa_model(inputs)\n",
        "start_pos = int(tf.argmax(outputs.start_logits, axis=-1)[0])\n",
        "end_pos   = int(tf.argmax(outputs.end_logits,   axis=-1)[0])\n",
        "answer = tok.decode(inputs[\"input_ids\"][0][start_pos:end_pos+1])\n",
        "\n",
        "print (\"Question :\", question)\n",
        "print(\"Réponse :\", answer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HqDs5sgIPfIA"
      },
      "source": [
        "et comme on a des probabilités sur les positions on peut aussi calculer une sorte de degré de confiance dans la réponse. L'intuition est que la réponse n'est \"bonne\" que si LE DEBUT ET LA FIN sont plausibles en même temps :)   \n",
        "On peut donc combiner les deux probabilités (début/fin) en un score unique, par exemple la moyenne géométrique $(P_{debut} x P_{fin})^\\frac{1}{2}$.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "8nHrbCOx_y_c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Question : In which city is the Eiffel Tower?\n",
            "Réponse : Paris\n",
            "Confiance : 0.695\n"
          ]
        }
      ],
      "source": [
        "start_probs = tf.nn.softmax(outputs.start_logits, axis=-1)[0]\n",
        "end_probs   = tf.nn.softmax(outputs.end_logits,   axis=-1)[0]\n",
        "p_start = float(start_probs[start_pos].numpy())\n",
        "p_end   = float(end_probs[end_pos].numpy())\n",
        "conf = (p_start * p_end) ** 0.5\n",
        "\n",
        "print (\"Question :\", question)\n",
        "print(\"Réponse :\", answer)\n",
        "print(\"Confiance :\", round(conf, 3))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rbq3eoNiT5pu"
      },
      "source": [
        "Pour conclure vous voyez que ce n'est pas très compliqué. Il faut toujours bien regarder les entrées et les sorties de vos modèles. Prenez l'habitude d'afficher aussi les shape ça vous aidera à mieux comprendre ce qui se passe dans la boîte. Avec toutes les informations de cette section vous devriez facilement fine tuner les tweets sur une tâche de classification."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gvMiP1hcturk"
      },
      "source": [
        "# Récupérer les données"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FHoJL5Yvt4zl"
      },
      "outputs": [],
      "source": [
        "url = \"https://www.lirmm.fr/~poncelet/Ressources/scitweets_export.tsv.zip\"\n",
        "target_dir = \"scitweets\"\n",
        "\n",
        "# Vérifie si le dossier existe déjà\n",
        "if os.path.exists(target_dir) and os.path.isdir(target_dir):\n",
        "    print(\"Données déjà disponibles dans :\", target_dir)\n",
        "else:\n",
        "    print(\"Téléchargement de scitweets_export.tsv.zip...\")\n",
        "    response = requests.get(url)\n",
        "    if response.status_code == 200:\n",
        "        print(\"Téléchargement réussi. Extraction...\")\n",
        "        with zipfile.ZipFile(io.BytesIO(response.content)) as zip_ref:\n",
        "            # Extraire sans ajouter de sous-dossier supplémentaire\n",
        "            for member in zip_ref.namelist():\n",
        "                # Corrige les chemins pour ignorer un éventuel prefixe flickr_subset2/\n",
        "                member_path = member\n",
        "                if member.startswith(\"scitweets/\"):\n",
        "                    member_path = member[len(\"scitweets/\"):]\n",
        "                target_path = os.path.join(target_dir, member_path)\n",
        "\n",
        "                # Si c'est un répertoire, on le crée\n",
        "                if member.endswith(\"/\"):\n",
        "                    os.makedirs(target_path, exist_ok=True)\n",
        "                else:\n",
        "                    os.makedirs(os.path.dirname(target_path), exist_ok=True)\n",
        "                    with zip_ref.open(member) as source, open(target_path, \"wb\") as target:\n",
        "                        target.write(source.read())\n",
        "        print(f\"Données extraites dans : {target_dir}\")\n",
        "    else:\n",
        "        print(\"Échec du téléchargement. Code HTTP :\", response.status_code)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c4TVqZgtu_Q2"
      },
      "source": [
        "Pour vous éviter de perdre du temps nous vous donnons les parties concernant le chargement."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mpMRKZB0u_za"
      },
      "outputs": [],
      "source": [
        "tsv_path = image_dir = os.path.join(target_dir, \"scitweets_export.tsv\")\n",
        "df = pd.read_csv(\n",
        "    tsv_path,\n",
        "    sep=\"\\t\",\n",
        "    encoding=\"utf-8\",\n",
        "    dtype={\"tweet_id\": str},\n",
        "    on_bad_lines=\"error\"\n",
        ")\n",
        "\n",
        "# Colonnes\n",
        "expected_cols = {\n",
        "    \"tweet_id\", \"text\", \"science_related\",\n",
        "    \"scientific_claim\", \"scientific_reference\", \"scientific_context\"\n",
        "}\n",
        "\n",
        "# Nettoyage minimal (on laisse emojis et caractères spéciaux)\n",
        "df[\"text\"] = df[\"text\"].astype(str).fillna(\"\")\n",
        "\n",
        "df[\"science_related\"] = df[\"science_related\"].astype(int)\n",
        "\n",
        "print(df.head(3))\n",
        "print(df[\"science_related\"].value_counts(dropna=False))\n",
        "print(\"Nombre de tweets: \", len(df))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M8c6CGwTfo2r"
      },
      "source": [
        "# Analyse des données"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "192jkaHUvU4E"
      },
      "source": [
        "Même si vous avez déjà vu le jeu de données et même si notre objectif est de fine tuner un modèle, il est toujours utile de faire un peu d'analyse de nos données pour mieux les comprendre. Commençons par ajouter une colonne à notre dataframe contenant la longueur des tweets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sKMkveBjwDX8"
      },
      "outputs": [],
      "source": [
        "text_col = df.columns[2]\n",
        "df['tweet_length'] = df[text_col].astype(str).str.len()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uvHudDF7wHGk"
      },
      "source": [
        "Maintenant, à l'aide de la fonction plot de matplotlib, complétez la cellule suivante afin de proposer un histogramme des différentes longueurs des tweets :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kv-_fX5S400e"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(6,4))\n",
        "\n",
        "# Ligne suivante à compléter\n",
        "plt.hist(....)\n",
        "plt.title(\"Histogram of Tweet Lengths (All Tweets)\")\n",
        "plt.xlabel(\"Tweet length (characters)\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SZN2wOKS5AWu"
      },
      "source": [
        "Nous avons vu que les boxplot étaient très utiles pour mieux comprendre la distribution d'une valeur. Un boxplot montre la médiane, l'étendue interquartile (dispersion) et met en évidence les valeurs atypiques. Modifiez la cellule suivante pour utiliser la fonction `boxplot` de matplotlib et comparer les distributions de longueurs des tweets par classe."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DETCBO2Q7Olr"
      },
      "outputs": [],
      "source": [
        "non_science = df.loc[df[\"science_related\"] == 0, \"tweet_length\"].dropna().values\n",
        "science     = df.loc[df[\"science_related\"] == 1, \"tweet_length\"].dropna().values\n",
        "\n",
        "plt.figure(figsize=(6, 4))\n",
        "# Ligne suivante à compléter\n",
        "plt.boxplot(.....)\n",
        "\n",
        "plt.title(\"Boxplot of Tweet Length by Top-level Class\")\n",
        "plt.xlabel(\"Class\")\n",
        "plt.ylabel(\"Tweet length\")\n",
        "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.5)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tky19I1a74QK"
      },
      "source": [
        "Enfin pour terminer. Modifiez la cellule suivante pour afficher le nombre d'éléments dans chaque classe."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nx0z0NT78BJ3"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(6,4))\n",
        "# Ligne suivante à compléter\n",
        "...plot(kind='bar', color=[\"red\",\"blue\"])\n",
        "plt.xticks([0,1], [\"Non-science\",\"Science\"], rotation=0)\n",
        "plt.ylabel(\"Count\")\n",
        "plt.title(\"Top-level Class Balance\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HYzCWJE38NfL"
      },
      "source": [
        "Cette partie d'analyse est volontairement simplifiée pour ne pas vous faire perdre de temps sur le fine tuning. Il y aurait d'autres statistiques descriptives comme les mots les plus utilisés par une classe, faire des projections en 2D ou 3D, etc.    \n",
        "\n",
        "N'oubliez pas que c'est très important de faire cette analyse des données avant d'entreprendre quoi que ce soit. Par exemple si ici un T-SNE me montrait que tout était facilement séparable il est clair que nous n'aurions pas utilé un BERT :) ... Pensez à toujours analyser vos données avant de faire quelque chose cela vous permettra d'éviter d'utiliser une usine à gaz alors qu'un simple classifieur pourrait être suffisant !!! Il faut que vous preniez cette habitude car en même temps ça peut vous permettre de moins consommer de $CO_2$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ulZlHpUfuMh"
      },
      "source": [
        "# Fine tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W87qAYdLnaj_"
      },
      "source": [
        "Comme précédemment, pour vous faire gagner du temps nous allons vous fournir un peu de code. Vous savez déjà faire la création de jeu de données d'apprentissage, de test et de validation donc il est inutile de perdre du temps là dessus."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c1KjP91JxL4O"
      },
      "outputs": [],
      "source": [
        "X = df[\"text\"].values\n",
        "y = df[\"science_related\"].values\n",
        "\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "X_val, X_test, y_val, y_test = train_test_split(\n",
        "    X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp\n",
        ")\n",
        "\n",
        "print (len(X_train), len(X_val), len(X_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ARYCxF2qAKwM"
      },
      "source": [
        "Maintenant que nous avons nos jeux de données, il nous faut une fonction pour effectuer la tokenization. Pour nous faciliter la vie, comme précédemment nous allons utiliser `DistilBertTokenizerFast`. Si vous avez bien suivi la première partie la fonction, que nous vous donnons n'a aucune difficulté : on passe un ensemble de texte, on precise que `truncation=True` pour autoriser à couper, etc. La seule différence par rapport à ce qu'on a vu avant est `padding=\"max_length` c'est juste pour nous simplifier la vie lors de la création des batches. Vous remarquerez que la fonction retourne 2 valeurs : les id des tokens et les masques d'attention. Si pour vous ce n'est pas clair il faut vraiment que vous relisiez la première partie."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MSGLVOLExWpf"
      },
      "outputs": [],
      "source": [
        "tokenizer = DistilBertTokenizerFast.from_pretrained(\"distilbert-base-uncased\")\n",
        "max_len = 192\n",
        "def tokenize_texts(texts):\n",
        "    \"\"\"\n",
        "    Tokenize une liste/array de textes.\n",
        "    Retourne des tableaux NumPy int32 pour éviter tout souci de types,\n",
        "    parfaitement compatibles avec tf.data et tf.keras.\n",
        "    \"\"\"\n",
        "    enc = tokenizer(\n",
        "        list(texts),\n",
        "        truncation=True,\n",
        "        padding=\"max_length\",\n",
        "        max_length=max_len,\n",
        "        return_tensors=None\n",
        "    )\n",
        "    input_ids = np.array(enc[\"input_ids\"], dtype=np.int32)\n",
        "    attention_mask = np.array(enc[\"attention_mask\"], dtype=np.int32)\n",
        "    return input_ids, attention_mask"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lEzYsqPiChdv"
      },
      "source": [
        "Pour vous aider encore, nous vous fournissons la fonction qui permet de créer des batches. Là aussi aucune difficulté. Nous vous la fournissons car la seule difficulté est de convertir en tenseur vos entrées pour être compatible avec ce qu'attend BERT/DistilBERT. Donc pas de difficulté on lance la tokenization sur le texte (fonction précédente), on fait une petite conversion sur le y et on créé des batches avec en entrée (une combinaison input_id, attention_mask) et le y associé. Juste un petit coup de prefetch pour optimiser un peu en parallélisme."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HwLiDlVp-Hgw"
      },
      "outputs": [],
      "source": [
        "batch_size=16\n",
        "\n",
        "def make_ds(texts, labels, batch_size=16, shuffle=False):\n",
        "    \"\"\"\n",
        "    Construit un tf.data.Dataset à partir des textes et labels binaires (0/1).\n",
        "    \"\"\"\n",
        "    input_ids, attention_mask = tokenize_texts(texts)\n",
        "    y = np.asarray(labels, dtype=np.float32)\n",
        "\n",
        "    ds = tf.data.Dataset.from_tensor_slices((\n",
        "        {\"input_ids\": input_ids, \"attention_mask\": attention_mask},\n",
        "        y\n",
        "    ))\n",
        "    if shuffle:\n",
        "        ds = ds.shuffle(buffer_size=len(y), seed=42)\n",
        "    return ds.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "train_ds = make_ds(X_train, y_train, batch_size=batch_size, shuffle=True)\n",
        "val_ds   = make_ds(X_val,   y_val,   batch_size=batch_size, shuffle=False)\n",
        "test_ds  = make_ds(X_test,  y_test,  batch_size=batch_size, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZMZ72_3QDquY"
      },
      "source": [
        "Là on rentre dans le vif du sujet. Maintenant notre objectif est de construire un modèle qui prend les entrées que nous avons vu, utilise BERT/DistilBERT comme modèle au milieu et en sortie ajoute une ou plusieurs couches pour prendre en compte notre tâche.\n",
        "\n",
        "**Attention :** voilà ce qu'il faut savoir quand on fait du fine tuning. L'objectif est que le modèle qui a déjà été appris sur des données puisse maintenant prendre en compte nos données et puisse résoudre la tâche. **La difficulté est que la prise en compte de nos données ne doit surtout pas faire oublier au modèle ce qu'il a appris avant. Pour ça il faut faire très peu d'épochs (généralement entre 2 et 5 max) et utiliser un tout petit learning rate.**  \n",
        "Pourquoi ?  tout simplement parce que le modèle possède déjà des connaissances générales issues du pré-apprentissage et que le fine-tuning ne doit pas tout réapprendre, il doit juste ajuster ces représentations à la tâche cible. Le principal risque est ce qu'on appelle **l'oubli catastrophique** : si on essaye d'apprendre trop longtemps, les poids dérivent et le modèle perd ce qu'il connaissait.  \n",
        "\n",
        "**Remarque :** En fait, si on veut vraiment faire du fine-tuning, outre le fait d'avoir peu d'epochset un learning rate faible, il faut surtout contrôler comment on met à jour les poids pour ne pas “effacer” ce que le modèle a appris. Souvent on va appliquer un weight decay léger, il s'agit juste de mettr een place une petite “résistance” qui évite que certains poids deviennent énormes et surapprennent le bruit. En d'autres termes,  on pénalise un peu les poids trop grands pendant l'entraînement. Ensuite on applique un \"warmup\" du learning rate, en gros c'est un démarrage en douceur (on commence très bas puis on remonte à la valeur normale, éventuellement on redescend un peu après) qui implique forcément de bien suivre la progression lors de l'apprentissage. Pour réaliser ce \"warmup\", Keras dispose de ce que l'on appelle un scheduler (voir [SCHEDULER](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/schedules)).   \n",
        "Vous connaissez l'optimiser `Adam`,\n",
        "en fait pour les transformer on utilise plutôt `AdamW` : c'est simplement une version d'Adam qui applique le weight decay.   \n",
        "\n",
        "Pour le TP, étant donné qu'on a peu de données et que l'exercice est relativement simple, nous alons rester sur Adam (que vous connaissez) avec un LR bas et peu d'epochs. Souvenez vous juste  que dans la pratique on préfère souvent AdamW + warmup pour un fine-tuning plus stable et qui conserve bien le pré-apprentissage.     \n",
        "\n",
        "Jusqu'à présent, nous n'utilisions qu'une seule métrique dans `compile`, l'accuracy. En fait, rien ne nous empêche d'en suivre plusieurs :) ce ne sont pas des contraintes d'apprentissage (et oui c'est la loss qui entraîne le modèle et la loss ne tient pas compte des mesures). Il s'agit juste d'indicateurs pour observer le comportement du modèle pedant l'apprentissage. . Comme nos classes sont déséquilibrées, nous allons suivre à la fois l'accuracy, l'AUC ROC et l'aire sous la courbe Précision-Rappel (AUC PR) qui peut apporter plus d'information quand la classe positive est rare.\n",
        "```python\n",
        "model.compile(\n",
        "        optimizer=keras.optimizers.Adam(learning_rate=lr),   \n",
        "        loss=\"binary_crossentropy\",\n",
        "        metrics=[\n",
        "            keras.metrics.BinaryAccuracy(name=\"accuracy\"),   \n",
        "            keras.metrics.AUC(name=\"roc_auc\"),\n",
        "            keras.metrics.AUC(curve=\"PR\", name=\"pr_auc\"),\n",
        "        ],\n",
        "    )\n",
        "```   \n",
        "\n",
        "Maintenant il ne vous reste plus qu'à compléter les lignes en dessous pour créer votre modèle de classification au dessus de DistillBert."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OPg2_nXAxw6a"
      },
      "outputs": [],
      "source": [
        "def build_distilbert_classifier(model_name=\"distilbert-base-uncased\",\n",
        "                                max_len=192, lr=2e-5):\n",
        "    config = DistilBertConfig.from_pretrained(model_name)\n",
        "    bert_base = TFDistilBertModel.from_pretrained(model_name,\n",
        "                                                  from_pt=True, config=config)\n",
        "\n",
        "    input_ids      = layers.Input(shape=(max_len,),\n",
        "                                  dtype=\"int32\", name=\"input_ids\")\n",
        "    attention_mask = layers.Input(shape=(max_len,),\n",
        "                                  dtype=\"int32\", name=\"attention_mask\")\n",
        "\n",
        "    # A COMPLETER\n",
        "    .....\n",
        "\n",
        "\n",
        "    model = Model(inputs=[input_ids, attention_mask], outputs=out)\n",
        "    model.compile(\n",
        "        optimizer=keras.optimizers.Adam(learning_rate=lr),\n",
        "        loss=\"binary_crossentropy\",\n",
        "        metrics=[\n",
        "            keras.metrics.BinaryAccuracy(name=\"accuracy\"),\n",
        "            keras.metrics.AUC(name=\"roc_auc\"),\n",
        "            keras.metrics.AUC(curve=\"PR\", name=\"pr_auc\"),\n",
        "        ],\n",
        "    )\n",
        "    return model\n",
        "\n",
        "\n",
        "\n",
        "model = build_distilbert_classifier(model_name=\"distilbert-base-uncased\",\n",
        "                                    max_len=max_len)\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jMekn9zUYAhW"
      },
      "source": [
        "Comme les classes sont déséquilibrées nous avons mis dans `EarlyStopping` le suivi de `val_pr_auc`. Complétez la cellule suivante pour apprendre votre modèle."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "gZw4zfXvmJR6"
      },
      "outputs": [],
      "source": [
        "save_dir = \"./scitweets_models\"\n",
        "name_model = \"distilbert_science_related_best.keras\"\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "model_path = os.path.join(save_dir, name_model)\n",
        "\n",
        "\n",
        "callbacks = [\n",
        "    EarlyStopping(monitor=\"val_pr_auc\", mode=\"max\", patience=2,\n",
        "                  restore_best_weights=True),\n",
        "    ModelCheckpoint(model_path, monitor=\"val_pr_auc\", mode=\"max\",\n",
        "                    save_best_only=True)\n",
        "]\n",
        "\n",
        "epochs=5\n",
        "# A COMPLETER\n",
        "history = model.fit(\n",
        "    ...\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-QME6Cndp4KR"
      },
      "source": [
        "On peut à présent évaluer notre modèle sur le jeu de test et regarder un peu les résulats. Comme notre jeu est déséquilibré, nous montrons plutôt la ROC AUC et la PR-AUC."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BTdBO8a5mOZQ"
      },
      "outputs": [],
      "source": [
        "y_prob_test = model.predict(test_ds).ravel()\n",
        "print(\"ROC-AUC (test):\", roc_auc_score(y_test, y_prob_test))\n",
        "print(\"PR-AUC  (test):\", average_precision_score(y_test, y_prob_test))\n",
        "\n",
        "# Par défaut, seuil = 0.5\n",
        "y_pred_05 = (y_prob_test >= 0.5).astype(int)\n",
        "print(classification_report(y_test, y_pred_05, digits=3))\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred_05, labels=[0,1])\n",
        "print(\"Confusion matrix :\\n\", cm)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fstAVywIrPpw"
      },
      "source": [
        "Et bien sûr afficher les courbes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LWnt1sfmmRad"
      },
      "outputs": [],
      "source": [
        "# ROC\n",
        "fpr, tpr, _ = roc_curve(y_test, y_prob_test)\n",
        "plt.figure()\n",
        "plt.plot(fpr, tpr, label=\"ROC\")\n",
        "plt.plot([0,1],[0,1],\"--\")\n",
        "plt.xlabel(\"FPR\")\n",
        "plt.ylabel(\"TPR\")\n",
        "plt.title(\"ROC curve (test)\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# PR\n",
        "prec, rec, _ = precision_recall_curve(y_test, y_prob_test)\n",
        "plt.figure()\n",
        "plt.plot(rec, prec, label=\"PR\")\n",
        "plt.xlabel(\"Recall\")\n",
        "plt.ylabel(\"Precision\")\n",
        "plt.title(\"Precision–Recall curve (test)\")\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HHYYIDDCa938"
      },
      "source": [
        "On peut à présent charger le modèle et faire de la prédiction pour savoir si un tweet est scientifique ou non. Normalement vous ne devriez avoir aucune difficulté si vous avez bien compris comment charger un modèle. Essayez sur plusieurs exemples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dY4oL9YJtyK8"
      },
      "outputs": [],
      "source": [
        "import tf_keras as keras\n",
        "\n",
        "save_dir = \"./scitweets_models\"\n",
        "name_model = \"distilbert_science_related_best.keras\"\n",
        "model_path = os.path.join(save_dir, name_model)\n",
        "\n",
        "\n",
        "model = keras.models.load_model(\n",
        "    model_path,\n",
        "    custom_objects={\"TFDistilBertModel\": TFDistilBertModel}\n",
        ")\n",
        "model.summary()\n",
        "\n",
        "\n",
        "def predict_texts(texts, batch_size=16):\n",
        "    input_ids, attention_mask = tokenize_texts(texts)\n",
        "    ds = tf.data.Dataset.from_tensor_slices(({\"input_ids\": input_ids,\n",
        "                                              \"attention_mask\": attention_mask})\n",
        "    ).batch(batch_size)\n",
        "    probs = model.predict(ds).ravel()\n",
        "    return probs\n",
        "\n",
        "# A COMPLETER UTILISER LA FONCTION PREDICT_TEXTS POUR PREDIRE DES EXEMPLES\n",
        "...\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OSniX0jIcaOS"
      },
      "source": [
        "Si vous avez fini vous pouvez, par exemple, regarder l'utilisation de `compute_class_weight` pour donner un peu plus de poids à la classe minoritaire comme par exemple :\n",
        "```python\n",
        "Class weights (utile en cas de déséquilibre)\n",
        "classes = np.array([0, 1])\n",
        "cw = compute_class_weight(class_weight=\"balanced\", classes=classes, y=y_train)\n",
        "class_weight = {0: float(cw[0]), 1: float(cw[1])}\n",
        "print(\"Class weights:\", class_weight)\n",
        "```\n",
        "ou bien proposé un modèle qui soit capable de considérer les 4 classes."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "miniclip",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
